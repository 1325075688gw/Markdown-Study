[toc]

## Redis

### Go赋值操作

- Var people People = Student{} // 编译通不过
- Var people People = &Student{} // 编译通过，People为interface类型，就是指针类型
- Var people People = new(Student)

```go
package main

import (
	"fmt"
)

type People interface {
	Speak(string) string
}

type Stduent struct{}

func (stu *Stduent) Speak(think string) (talk string) {
	if think == "love" {
		talk = "You are a good boy"
	} else {
		talk = "hi"
	}
	return
}

func main() {
	var peo People = Stduent{}
	think := "love"
	fmt.Println(peo.Speak(think))
}
```

- var dogList = []Dog{d1, d2}

```go
type Dog interface {
  Hi()
}

type Dog1 struct{}
func (d Dog1) Hi() {}

type Dog2 struct{}
func (d Dog2) Hi() {}

var d1 Dog1
var d2 Dog2
var dogList = []Dog{d1, d2}
for _, v := range dogList {
  v.Hi()
}
```







### 1.make和new的区别

make用来初始化channel、slice、map。

make返回的还是三个引用类型本身；而new返回的是指向变量的指针。

1. new有以下几个特点：

   1. **分配内存**。内存里存的值是对应类型的[零值](https://zhuanlan.zhihu.com/lesson3)。**//重要**
   2. 只有一个参数。参数是分配的内存空间所存储的数据类型，Go语言里的任何类型都可以是new的参数，比如int， 数组，[结构体](https://www.zhihu.com/search?q=结构体&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2245768201})，甚至函数类型都可以。
   3. 返回的是指针。**// 重要**

   以下代码是等价的，可以认为new(T)是 var t T; &t 的[语法糖](https://www.zhihu.com/search?q=语法糖&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2245768201})。

   ```
   // 方式1
   ptr := new(T)
   
   // 方式2lhgj
   var t T
   ptr := &t
   ```

2. make有以下特点

   1. **分配和初始化内存。** 
   2. 只能用于slice, map和chan这3个类型，不能用于其它类型。 

   如果是用于slice类型，make函数的第2个参数表示slice的长度，这个参数必须给值。

   3. 返回的是原始类型，也就是slice, map和chan，不是返回指向slice, map和chan的指针。

3. 为什么针对slice, map和chan类型专门定义一个make函数？

   答案：这是因为[slice](https://www.zhihu.com/search?q=slice&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2245768201}), map和chan的底层结构上要求在使用slice，map和chan的时候必须初始化，如果不初始化，那slice，map和chan的值就是零值，也就是nil。我们知道：

   1. map如果是nil，是不能往map插入元素的，插入元素会引发panic
   2.  chan如果是nil，往chan发送数据或者从chan接收数据都会阻塞
   3.  slice会有点特殊，理论上slice如果是nil，也是没法用的。但是append函数处理了nil slice的情况，可以调用append函数对nil slice做扩容。但是我们使用slice，总是会希望可以自定义长度或者容量，这个时候就需要用到make。

4. 引用类型初始化

   ```
   var i *int
   *i = 10
   
   会报错，需要对引用类型分配内存
   既然我们知道了没有为其分配内存，那么我们使用new分配一个吧。
   
   var i *int
   i = new(int)
   *i = 10
   ```

5. `new(X)`和`&X{}`是等效的：

   ```
   goku := new(Saiyan)
   // 等效
   goku := &Saiyan{}
   
   
   用那种方式取决于你，但是你会发现，当需要去初始化结构体字段时，大多数人更喜欢使用后者，因为后者更易读：
   goku := new(Saiyan)
   goku.name = "goku"
   goku.power = 9001
   
   //对比
   
   goku := &Saiyan {
       name: "goku",
       power: 9000,
   }
   ```

### 2.Redis在你们项目中主要用来做什么

![image-20220919003037604](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003037604.png)



### 布隆过滤器原理

![img](https://img-blog.csdnimg.cn/20210225103955320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdHVzMzU=,size_16,color_FFFFFF,t_70)

这是一个长度为8，默认都是0的bit数组。如果我们想要映射一个值到布隆过滤器中，怎么操作呢？首先是使用多个不同的哈希函数生成多个哈希值，再把哈希值指向的bit位置1。例如：我们要将值“baidu”映射到布隆过滤器上，怎么操作呢？假如我们使用三个不同的哈希函数生成了三个哈希值分别是:1、3、6，那么上图就转变为下图这样：

![img](https://img-blog.csdnimg.cn/20210225105747809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdHVzMzU=,size_16,color_FFFFFF,t_70)

从图中看出，标有浅蓝色的bit位的值都被置为1，表示该数据已经映射上了。接着我们再把值“alibaba”和三个不同哈希函数生成的值：2、6、8映射到上面布隆过滤器中，它就会变为下图的样子：

![img](https://img-blog.csdnimg.cn/20210225110509587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdHVzMzU=,size_16,color_FFFFFF,t_70)

很显然，它把之前映射的哈希值6覆盖了，这就是布隆过滤器是有误报率的一个因素。如果这时候，我们想拿一个未插入映射的值“tencent”查询它是否在上面布隆过滤器中存在。该怎么操作呢？首先，把值“tencent”用上面三个不同哈希函数生成三个哈希值分别是：2、4、6；再去布隆过滤器上找这三个值对应的bit位的值是否都是1，我们发现2和6都返回了1，而4返回0，说明值“tencent”没有做过映射，即不存在。实际上我们并没有事先做过此值的插入映射操作。这当然是正确的。

### 2. Redis分布式锁

在我们的日常开发中，一个进程中当多线程的去竞争某一资源的时候，我们通常会用一把锁来保证只有一个线程获取到资源。如加上synchronize关键字或ReentrantLock锁等操作。

那么，如果是多个进程相互竞争一个资源，如何保证资源只会被一个操作者持有呢？

例如：微服务的架构下，多个应用服务要同时对同一条数据做修改，那么要确保数据的正确性，就只能有一个应用修改成功。

server1、server2、server3 这三个服务都要修改amount这个数据，每个服务更新的值不同，为了保证数据的正确性，三个服务都向lock server服务申请修改权限，最终server2拿到了修改权限，即server2将amount更新为2，其他服务由于没有获取到修改权限则返回更新失败。
![img](https://img-blog.csdnimg.cn/c81ff7e1b1334f1ba5959926fbb494dd.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA546E6YOt6YOt,size_20,color_FFFFFF,t_70,g_se,x_16)

#### 锁的获取

setnx命令：表示SET if Not Exists，即如果 key 不存在，才会设置它的值，否则什么也不做。

两个客户端同时向redis写入try_lock，客户端1写入成功，即获取分布式锁成功。客户端2写入失败，则获取分布式锁失败。

![img](https://img-blog.csdnimg.cn/61fddc151980422baad607642476d4b2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA546E6YOt6YOt,size_20,color_FFFFFF,t_70,g_se,x_16)

![img](https://img-blog.csdnimg.cn/3ea4315d28f3474a99573a1fd95c9a1e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA546E6YOt6YOt,size_20,color_FFFFFF,t_70,g_se,x_16)

#### 锁的释放

当客户端1操作完后，释放锁资源，即删除try_lock。那么此时客户端2再次尝试获取锁时，则会获取锁成功。

![img](https://img-blog.csdnimg.cn/954d442fc45f45a383549688f9a1ed65.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA546E6YOt6YOt,size_20,color_FFFFFF,t_70,g_se,x_16)

![img](https://img-blog.csdnimg.cn/b5620d33fc14416884c9f0d5cf835db0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA546E6YOt6YOt,size_20,color_FFFFFF,t_70,g_se,x_16)

那么这样分布式锁就这样结束了？不不不，现实往往有很多情况出现。

假如客户端1在获取到锁资源后，服务宕机了，那么这个try_lock会一直存在redis中，那么其他服务就永远无法获取到锁了。

如何解决这个问题呢？

#### 避免死锁

设置键过期时间，超过这个时间即给key删除掉。

这样的话，就算当前服务获取到锁后宕机了，这个key也会在一定时间后被删除，其他服务照样可以继续获取锁。

给serverLock键设置一个10秒的过期时间，10秒后会自动删除该键。

![img](https://img-blog.csdnimg.cn/afd28902dc4b4b88a0f966cb0ce2b63d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA546E6YOt6YOt,size_20,color_FFFFFF,t_70,g_se,x_16)

这样虽然解决了上面说的问题，但是又会引入新的问题。

假如服务A加锁成功，锁会在10s后自动释放，但由于业务复杂，执行时间过长，10s内还没执行完，此时锁已经被redis自动释放掉了。此时服务B就重新获取到了该锁，服务B开始执行他的业务，服务A在执行到第12s的时候执行完了，那么服务A会去释放锁，则此时释放的却是服务B刚获取到的锁。

**这会有锁过期和释放其他服务锁这种严重的问题**

#### 锁过期处理

那么锁过期这种问题该如何处理的？

虽然可以通过增加删除key时间来处理这个问题，但是并没有从根本上解决。假设设个100s，绝大多数都是1s后就会释放锁，但是由于服务宕机，则会导致100s内其他服务都无法获取到锁，这也是灾难性的。

我们可以这样做，在锁将要过期的时候，如果服务还没有处理完业务，那么将这个锁再续一段时间。比如设置key在10s后过期，那么再开启一个守护线程，在第8s的时候检测服务是否处理完，如果没有，则将这个key再续10s后过期。
在Redisson（Redis SDK客户端）中，就已经帮我们实现了这个功能，这个自动续时的我们称其为”看门狗”。

#### 释放其他服务的锁如何处理呢？

每个服务在设置key的时候，带上自己服务的唯一标识，如UUID，或者一些业务上的独特标识。这样在删除key的时候，只删除自己服务之前添加的key就可以了。

如果需要先查看锁是否是自己服务添加的，需要先get取出来判断，然后再进行del。这样的话就无法保证原子性了。

我们可以通过Lua脚本，将这两个操作合并成一个操作，就可以保证其原子性了。

Lua脚本的话，我也不会，用到的时候百度就完了。

如果是在单redis实例的情况下，上面的已经完全实现了分布式锁的功能了。

#### 那么redis宕机了呢？

这个时候就得引入redis集群了。

但是涉及到redis集群，就会有新的问题出现，假设是主从集群，且主从数据并不是强一致性。当主节点宕机后，主节点的数据还未来得及同步到从节点，进行主从切换后，新的主节点并没有老的主节点的全部数据，这就会导致刚写入到老的主节点的锁在新的主节点并没有，其他服务来获取锁时还是会加锁成功。此时则会有2个服务都可以操作公共资源，此时的分布式锁则是不安全的。

redis的作者也想到这个问题，于是他发明了RedLock。
https://blog.csdn.net/Me_xuan/article/details/124418176

#### Redis分布式锁的设计需要考虑哪些问题？

- 超时时间设置，
- 续期设置，
- 释放锁判断是否是自己的锁



### 3. Redis单线程为什么这么快？

1. Redis所有的读写操作都是内存操作，内存操作比磁盘操作快
2. Redis主从复制或者生成RDB文件，都会再启动一个新线程，所以主线程不会阻塞
3. 单线程少了上下文的切换，减少了性能损耗
4. 核心是非阻塞的IO多路复用机制。 采用 I/O 多路复用机制处理大量客户端的Socket请求，因为这是基于非阻塞的 I/O 模型，这就让Redis可以高效地进行网络通信，I/O的读写流程也不再阻塞。
5. 底层数据结构适合增删查改

### 3. Redis的主从复制

1. 为什么需要主从复制
   - 读写分离，提升读写性能
   - 单节点容易宕机，提高系统容错性

2. [复制流程](https://www.modb.pro/db/99431)

   参数介绍：

   ```
   runid
   ：每个 Redis 实例启动时都会自动生成的一个随机 ID(uuid算法)，用来唯一标记这个实例，每次Redis重启，uuid也会重新生成
   offset
   ：偏移量，slave需要从哪个位置开始同步数据。主从节点各自维护自己的offset，当主节点有写入命令时候，offset = offset + 命令的字节长度，从节点收到主节点发送的命令后，也会增加自己的offset，并会把自己的offset发送给主节点。主节点同时保存主从节点offset，通过对于offset来判断主从数据是否一致
   repl_backlog_size
   ：保存在主节点上的一个先入先出队列，大小1MB
   ```

   #### 全量复制，复制流程：

   1、slave执行命令向master建立连接
   2、master执行bgsave（后台存储），生成rdb快照（redis备份方式，data以二进制方式保存在本地），发送到slave上
   3、slave获取快照后读取，对data还原，保证初始化数据一致
   4、master接受命令发送到salve，salve执行保证后续数据一致
   
   
   
   ![img](https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210813_792a2244-fbe9-11eb-8856-00163e068ecd.png)
   
   ```
   1. 从节点执行slaveof masterIP masterPort命令，发起TCP连接，建立与主节点联系
   2. 主从节点建立好socket连接
   3. 然后发送psync ${runid} ${offset}，告知主节点开始同步数据
   4. 由于是第一次同步，Slave 节点不知道 Master节点的runid，所以 Slave 节点会发送psync ? -1，表示需要全量同步数据。
   5. Master 节点在收到 Slave 节点发来的psync后，会给slave回复+fullresync ${runid} ${offset}，这个runid就是master的唯一标识，slave会记录这个runid，用于后续断线重连同步请求
   6. Master 执行 bgsave 命令fork出子进程，即在后台保存数据到磁盘（rdb快照文件），接着将文件发给 Slave。Master同时将新收到的写入和修改数据集的命令存入缓冲区
   7. Slave 接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件（这是因为Slave在通过 replicaof 命令开始和 Master 同步前，可能保存了其他数据。为了避免之前数据的影响，Slave 需要先把当前数据库清空。）
   8. （在 Master 将数据同步给 Slave 的过程中，Master 不会被阻塞，仍然可以正常接收请求）但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主 Slave 的数据一致性，Master 会在内存中用 repl_backlog_buffer 记录 RDB 文件生成后收到的所有写操作
   9. 最后，Master 会把 repl_backlog_buffer数据再发送给从库。这样一来，主从库就实现同步了。
   ```
   
   增量复制：
   
   ![img](https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210813_79d508a8-fbe9-11eb-8856-00163e068ecd.png)
   
   在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，从库就会和主库重新进行一次全量复制，开销非常大。在Redis在这方面进行了改进，在2.8版本之后，Redis支持**增量同步**。
   
   ```
   1. 主从因为故障断开，故障恢复后，他们重新建立连接，Slave 节点向 Master 节点发送数据 同步请求：psync ${runid} ${offset}
   2. Master 收到psync命令之后，检查slave发来的runid与自身的runid一致，如果一致，说明之前已经同步过数据，这次只需要同步部分数据即可。如果不是，则说明主节点不是此前的节点，需要全量同步
   3. 这里分为两种情况：①如果offset在repl_backlog_buffer范围内，那么 Master 节点给 Slave 节点回复+continue，表示这次只同步部分数据。之后 Master 节点把复制缓冲区offset之后的数据给 Slave 节点，接下来 Slave 节点执行这些命令后就与 Master 数据一致了。
   4. ②如果offset不在repl_backlog_buffer范围内，说明断开连接很久了，此时只能触发全量数据同步。
   ```

### 哨兵模式如何选举新节点：

当节点被一个Sentinel节点记为主观下线时，并不意味着该节点肯定故障了，还需要Sentinel集群的其他Sentinel节点共同判断为主观下线才行。

该Sentinel节点会询问其他Sentinel节点，如果Sentinel集群中超过quorum数量的Sentinel节点认为该redis节点主观下线，则该redis客观下线。

如果客观下线的redis节点是从节点或者是Sentinel节点，则操作到此为止，没有后续的操作了；如果客观下线的redis节点为主节点，则开始故障转移，从从节点中选举一个节点升级为主节点。

#### Sentinel Leader决定新主节点

当Sentinel集群选举出Sentinel Leader后，由Sentinel Leader从redis从节点中选择一个redis节点作为主节点：

过滤故障的节点
选择优先级slave-priority最大的从节点作为主节点，如不存在则继续
选择复制偏移量（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）最大的从节点作为主节点，如不存在则继续
选择runid（redis每次启动的时候生成随机的runid作为redis的标识）最小的从节点作为主节点

#### 如果Sentinel挂了怎么办？如何保证Sentinel高可用

1.sentinel自动故障迁移使用raft算法来选举领头(leader) sentinel
2.超过半数投票选出leader, sentinel Leader用于下达故障转移的指令
3.如果某个Leader挂了，则使用Raft从剩余的Sentinel中选出leader

![在这里插入图片描述](https://img-blog.csdnimg.cn/6d9cfb759faa46378e9e1514b5e293d6.png)



### 4. Redis有哪些高可用（读写性能、存储容量）的方案

1. 主从复制

   使用slaveof masterIP masterPort进行主从复制，但是只能解决读性能问题，当主节点挂了之后，不能自动切换从节点，需要手动切换，所以使用频率不多

   缺点:

   1. 一旦 **主节点宕机**，**从节点** 晋升成 **主节点**，同时需要修改 **应用方** 的 **主节点地址**，还需要命令所有 **从节点**去 **复制** 新的主节点，整个过程需要 **人工干预**。
   2. **主节点** 的 **写能力** 受到 **单机的限制**。
   3. **主节点** 的 **存储能力** 受到 **单机的限制**。
   4. **原生复制** 的弊端在早期的版本中也会比较突出，比如：`Redis` **复制中断** 后，**从节点** 会发起 `psync`。此时如果 **同步不成功**，则会进行 **全量同步**，**主库** 执行 **全量备份** 的同时，可能会造成毫秒或秒级的 **卡顿**。

2. 哨兵模式（集群模式）

   Redis的哨兵机制就是解决我们以上主从复制存在缺陷**（选举问题）**，保证我们的Redis高可用，**实现自动化故障发现与故障转移**。

该系统执行以下三个任务：

- 集群监控：哨兵会不断检查你的主服务器和从服务器是否运作正常。

- 消息提醒：当被监控的某个Redis服务器出现问题时，哨兵可以通过API给程序员发送通知

- 自动故障转移：主服务器宕机，哨兵会开始一次自动故障转移操作，升级一个从服务器为主服务器，并让其他从服务器改为复制新的主服务器.
- 配置中心：如果故障转移发生了，通知client客户端新的master地址。

3. **你能说说Redis哨兵机制的原理吗？**
   通过sentinel模式启动redis后，自动监控master/slave的运行状态，基本原理是：心跳机制+投票裁决。每个sentinel会向其它sentinal、master、slave定时发送消息，以确认对方是否活着，如果发现对方在指定时间内未回应，则暂时认为对方宕机。若哨兵群中的多数sentinel都报告某一master没响应，系统才认为该master真正宕机，通过Raft投票算法，从剩下的slave节点中，选一台提升为master，然后自动修改相关配置。
4. **部署Redis哨兵要注意哪些问题？**
   哨兵至少需要3个实例，来保证自己的健壮性。

### 5.Redis Key的过期策略有哪些？

- 惰性删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key，返回空，很明显，这是被动的。
- 定期删除：由于惰性删除策略无法保证冷数据被及时删掉，所以 redis 会定期主动（随机）淘汰一批已过期的key。



### Redis内存淘汰机制

- 主动删除（内存淘汰机制）：当前已用内存超过maxMemory限定时，触发主动清理策略。主动设置的前提是设置了maxMemory的值-。

  - noeviction：报错，当内存不足以容纳新写入数据时，新写入操作会报错
  - allkeys-lru：在键空间中，移除最近最少使用的key
  - allkeys-random：在键空间中，随机移除某个key
  - volatile-lru：在设置了过期时间的键空间中，移除最近最少使用的key
  - volatile-random：在设置了过期时间的键空间中，随机移除某个key
  - volatile-ttl：在设置了过期时间的键空间中，有更早过期时间的key优先移除

  

  - 最经常用的是allkeys-lru。

### 6. Redis中常见的数据结构？

- String：字符串
- List：列表
- Hash：哈希
- Set：集合
- Zset：有序集合
- bitmap：布隆过滤器
- GeoHash：里面借助Zset进行实现
- HyperLogLog：统计不重复数据
- Streams：内存版的kafka



- String：字符串

  计数器：可以用来计数，通过 incr 操作，如统计网站的访问量、文章访问量等。

- Set：集合

   存储好友/粉丝：set 具有去重功能；还可以利用set并集功能得到共同好友之类的功能。

- Zset：有序集合

  排行榜：有序集合最常用的场景。如新闻网站对热点新闻排序，比如根据点击量、点赞量等。

- HyperLogLog：统计不重复数据

  网页统计UV （浏览用户数量，同一天同一个ip多次访问算一次访问，目的是计数，而不是保存用户）

### 7. Redis持久化机制

***RDB：把当前数据生成快照保存在硬盘上。
AOF：记录每次对数据的操作到硬盘上。***

RDB（Redis DataBase）持久化是把当前Redis中全部数据生成快照保存在硬盘上。RDB持久化可以手动触发，也可以自动触发。

#### 1. 手动触发

save和 bgsave命令都可以手动触发RDB持久化。

**save**
执行save命令会手动触发RDB持久化，但是save命令会阻塞Redis服务，直到RDB持久化完成。当Redis服务储存大量数据时，会造成较长时间的阻塞，不建议使用。
**bgsave**
执行bgsave命令也会手动触发RDB持久化，和save命令不同是：Redis服务一般不会阻塞。Redis进程会执行fork操作创建子进程，RDB持久化由子进程负责，不会阻塞Redis服务进程。Redis服务的阻塞只发生在fork阶段，一般情况时间很短。
bgsave命令的具体流程如下：

1. 执行bgsave命令，Redis进程先判断当前是否存在正在执行的RDB或AOF子线程，如果存在就是直接结束。
2. Redis进程执行fork操作创建子线程，在fork操作的过程中Redis进程会被阻塞。
3. Redis进程fork完成后，bgsave命令就结束了，自此Redis进程不会被阻塞，可以响应其他命令。
4. 子进程根据Redis进程的内存生成快照文件，并替换原有的RDB文件。
5. 同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence下的rdb_*相关选项）

#### 2. 自动触发

除了执行以上命令手动触发以外，Redis内部可以自动触发RDB持久化。自动触发的RDB持久化都是采用bgsave的方式，减少Redis进程的阻塞。那么，在什么场景下会自动触发呢？

1. 在配置文件中设置了save的相关配置，如sava m n，它表示在m秒内数据被修改过n次时，自动触发bgsave操作。如果设置多个，只要满足一个就会执行。
2. 当从节点做全量复制时，主节点会自动执行bgsave操作，并且把生成的RDB文件发送给从节点。
3. 执行debug reload命令时，也会自动触发bgsave操作。
4. 执行shutdown命令时，如果没有开启AOF持久化也会自动触发bgsave操作。

#### 3. RDB优点

RDB文件是一个紧凑的二进制压缩文件，是Redis在某个时间点的全部数据快照。所以使用RDB恢复数据的速度远远比AOF的快，非常适合备份、全量复制、灾难恢复等场景。

在Redis中只有一个RDB文件

#### 4. RDB缺点

1. 每次进行bgsave操作都要执行fork操作创建子经常，属于重量级操作，频繁执行成本过高，所以无法做到实时持久化，或者秒级持久化。因为fork子进程会占用CPU
2. **RDB**都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉





1. 另外，由于Redis版本的不断迭代，存在不同格式的RDB版本，有可能出现低版本的RDB格式无法兼容高版本RDB文件的问题。
2. 数据安全性低，RDB是间隔一段时间进行持久化，如果持久化期间Redis发生故障，就会发生数据丢失



**快照周期**：内存快照虽然可以通过技术人员手动执行`SAVE`或`BGSAVE`命令来进行，但生产环境下多数情况都会设置其周期性执行条件。

```
# 周期性执行条件的设置格式为
save <seconds> <changes>

# 默认的设置为：
save 900 1
save 300 10
save 60 10000

# 以下设置方式为关闭RDB快照功能
save ""


以上三项默认信息设置代表的意义是：

如果900秒内有1条Key信息发生变化，则进行快照；
如果300秒内有10条Key信息发生变化，则进行快照；
如果60秒内有10000条Key信息发生变化，则进行快照。读者可以按照这个规则，根据自己的实际请求压力进行设置调整。
```

#### 5. COW

##### [Copy On Write 机制](https://zhuanlan.zhihu.com/p/339437815)

> **核心思路**：fork一个子进程，只有在父进程发生写操作修改内存数据时，才会真正去分配内存空间，并复制内存数据，而且也只是复制被修改的内存页中的数据，并不是全部内存数据；

- Redis中执行BGSAVE命令生成RDB文件时，本质就是调用Linux中的fork()命令，Linux下的fork()系统调用实现了copy-on-write写时复制；

- fork()是类Unix操作系统上创建线程的主要方法，fork用于**创建子进程**（等同于当前进程的副本）；

- **传统的**普通进程复制，会直接将父进程的数据拷贝到子进程中，拷贝完成后，父进程和子进程之间的**数据段**和**堆栈**是相互独立的；

- copy-on-write技术，在fork出子进程后，与父进程共享内存空间，两者只是虚拟空间不同，但是其对应的物理空间是同一个；

  

1. 由于生产环境中我们为Redis开辟的内存区域都比较大（例如6GB），那么将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢？

   RDB中的核心思路是**Copy-on-Write**，来保证在进行快照操作的这段时间，需要压缩写入磁盘上的数据在内存中不会发生变化。在正常的快照操作中，一方面Redis主进程会fork一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应。另一方面这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域。

2. RDB的过程中是否会停止对外提供服务？

   RDB过程中会fork一个子进程，子进程做数据备份操作，主进程继续对外提供服务，所有Redis服务不会阻塞；

3. RDB的过程中数据修改了，备份的是修改前的还是修改后的？

   Copy On Write 机制，备份的是开始那个时刻内存中的数据；

4. RDB时是不是先把内容中的所有KV复制一份，保证数据不会被修改？

   Copy On Write 机制不需要把整个内存的数据都复制一份；

#### 6.在进行快照操作的这段时间，如果发生服务崩溃怎么办？

很简单，在没有将数据全部写入到磁盘前，这次快照操作都不算成功。如果出现了服务崩溃的情况，将以上一次完整的RDB快照文件作为恢复内存数据的参考。也就是说，在快照操作过程中不能影响上一次的备份数据。Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。

#### 7.AOF（Append Only File）

使用 AOF 做持久化，每一个写命令都通过 `write` 函数追加到 `appendonly.aof` 文件中。

推荐（并且也是默认）的措施为每秒 fsync 一次

Redis 支持同时开启 RDB 和 AOF,系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。

##### AOF操作步骤

- 所有的写命令追加到AOF缓冲区
- AOF缓存区根据对应的策略向磁盘同步
- 随着AOF文件越来越大，需要定期对AOF文件进行重写
- 当Redis重启时候，使用AOF文件进行恢复

##### AOF同步策略

- 每秒同步：异步修改，效率非常高。一旦出现宕机现象，那么这一秒的数据将丢失
- 每次修改就同步：同步修改，每次发生数据修改立即记录到磁盘中，最多丢失一条记录
- 不同步：由操作系统控制

AOF日志采用写后日志，即**先写内存，后写日志**。

###### 先写日志的缺点

- 数据可能会丢失：如果 Redis 刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险。
- 可能阻塞其他操作：AOF 日志其实也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。

![在这里插入图片描述](https://img-blog.csdnimg.cn/33b4946225b842d8853996093cff4659.png)

##### 为什么采用写后日志？

Redis要求高性能，采用写日志有两方面好处：

- 避免额外的检查开销：Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。
- 不会阻塞当前的写操作

##### AOF 优点：

- 我们通过一个场景再现来说明。某同学在操作Redis 时，不小心执行了FLUSHALL，导致Redis 内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要Redis 配置了AOF 持久化方式，且AOF文件还没有被重写(rewrite)，我们就可以用最快的速度暂停Redis 并编辑AOF文件，将最后一行的FLUSHALL 命令删除，然后重启Redis，就可以恢复Redis的所有数据到FLUSHALL 之前的状态了。是不是很神奇，这就是AOF 持久化方式的好处之一。但是如果AOF 文件已经被重写了，那就无法通过这种方法来恢复数据了。

- 定期对AOF文件进行重写，以达到压缩的目的

##### AOF缺点：

​		比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF 方式的恢复速度也要慢于RDB 方式。

#### 重启恢复：

**两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。**



持久化：https://blog.csdn.net/hanjinjuan/article/details/124674800

### 缓存一致性

https://www.jianshu.com/p/1a14fcc22204

更新时候，不要去重新更新缓存

![image-20220805135521201](/Users/gongwei/Library/Application Support/typora-user-images/image-20220805135521201.png)

#### Cache Aside Pattern - 旁路缓存模式

尽可能保证缓存和数据库数据一致

!(/Users/gongwei/Library/Application Support/typora-user-images/image-20220805135317376.png)



#### 延迟双删（推荐）

1、先删除缓存
2、更新数据库
3、休眠一会儿（比如1s），之后再删一次缓存数据

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220809235058382.png" alt="image-20220809235058382" style="zoom:50%;" />

**1、引入MQ重试机制。**假设更完库后删除失败，则把失败的key丢到MQ中，由mq消费端拉出来进行删除重试。这种方案的弊端是对于删除失败的处理逻辑需要基于业务代码的 trigger 来触发，对业务代码侵入性较为严重。

**2、基于数据库binlog的方式增量解析、订阅和消费。**为了保证删除成功，可以利用阿里巴巴开源中间件canal订阅binlog发送到MQ中，再利用MQ的ACK机制来保证删除成功，最终保证数据缓存一致性（比如更新了uid=2这个用户信息，那么可以读取binlog中uid=2的log，然后删除缓存中key={user:2}这个key）



### 缓存穿透、缓存击穿、缓存雪崩

哔站使用视频（代码）：https://www.bilibili.com/video/BV19u411Q7f2/?spm_id_from=333.788&vd_source=58acbf449edd771737ee43a78ffdabf4

![image-20220918175243016](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918175243016.png)



#### 缓存穿透

![image-20221011234157768](/Users/gongwei/Library/Application Support/typora-user-images/image-20221011234157768.png)

1. 验证拦截

   ![image-20220918180041016](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918180041016.png)

   1. 用户权限验证
   2. id验证，比如id < 0的就进行拦截

2. 设置空值

   ![image-20220918180155401](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918180155401.png)

   

3. 布隆过滤器

   当指定一个数据存在时，他不一定存在；当指定一个数据不存在时，那么它一定不存在

![image-20220918180657763](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918180657763.png)



#### 缓存击穿

![image-20221011233052232](/Users/gongwei/Library/Application Support/typora-user-images/image-20221011233052232.png)

1. 将热点数据设置为永不过期或者进行数据访问时候对数据过期时间进行续期
2. 加同步锁或者分布式锁，都可以。因为redis集群最多10台，我们即使用同步锁，也最多10个线程会击穿redis到达mysql。所以不一定用分布式锁
3. ![image-20221011233244116](/Users/gongwei/Library/Application Support/typora-user-images/image-20221011233244116.png)
3. ![image-20220918181132360](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918181132360.png)
4. 利用集群解决

#### 缓存雪崩

![image-20221011233514348](/Users/gongwei/Library/Application Support/typora-user-images/image-20221011233514348.png)

1. 给缓存设置上不同的过期时间，避免同一时间失效

2. ![image-20221011233836590](/Users/gongwei/Library/Application Support/typora-user-images/image-20221011233836590.png)

   

2. redis高可用（集群部署）

### 什么是跳表

#### 有序集合的底层数据结构就是跳表

![image-20220919003110152](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003110152.png)



![image-20220919003141571](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003141571.png)



同时满足：

![image-20220919003158204](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003158204.png)

![image-20220919003257314](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003257314.png)

![image-20220919003313756](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003313756.png)

时间复杂度logn

![image-20220919003334784](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003334784.png)

- 在实现方面，红黑树实现更加复杂，跳跃表实现比较简单，也更加直观，更加灵活。
- 跳表区间查找数据的效率更高一些。
- 红黑树/平衡二叉树这种树形结构，每次每隔两个节点建一个索引，而跳跃表可以多个节点，不限于两个节点。
- 跳跃表插入或删除操作只需要修改节点前后的指针，而不需要对多个节点都进行调整，而平衡二叉树则需要左旋或者右旋实现平衡。

https://www.bilibili.com/video/BV1yT4y1a7tD/?spm_id_from=333.788&vd_source=58acbf449edd771737ee43a78ffdabf4

![image-20220918181909448](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918181909448.png)



![image-20220918181923244](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918181923244.png)

![image-20220918181948540](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918181948540.png)



![image-20220918182130045](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918182130045.png)





## MySQL

### MySQL慢查询如何优化：

![image-20221020235354260](/Users/gongwei/Library/Application Support/typora-user-images/image-20221020235354260.png)



### 1. InnoDB和MyISAM数据引擎的区别

- InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； 

- InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败；

- InnoDB是聚集索引，使用B+Tree作为索引结构，MyISAM使用非聚焦索引。

-  InnoDB不保存表的具体行数，执行select count(\*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快（注意不能加有任何WHERE条件）；

  - 那么为什么InnoDB没有了这个变量呢？

        因为InnoDB的事务特性，在同一时刻表中的行数对于不同的事务而言是不一样的，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。InnoDB会尝试遍历一个尽可能小的索引除非优化器提示使用别的索引。如果二级索引不存在，InnoDB还会尝试去遍历其他聚簇索引。
        如果索引并没有完全处于InnoDB维护的缓冲区（Buffer Pool）中，count操作会比较费时。可以建立一个记录总行数的表并让你的程序在INSERT/DELETE时更新对应的数据。和上面提到的问题一样，如果此时存在多个事务的话这种方案也不太好用。如果得到大致的行数值已经足够满足需求可以尝试SHOW TABLE STATUS

- Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了
- InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁
- 执行大量select，myisam是最好的选择；执行大量的update和insert最好用innodb。

**InnoDB**

![img](https://img-blog.csdnimg.cn/20190619172620687.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzA2Njcw,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdn.net/20180923094753230?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjQyMDM2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**MyISAM**

![img](https://img-blog.csdnimg.cn/20190619172229827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzA2Njcw,size_16,color_FFFFFF,t_70)

### 2. 如何选择存储引擎

    1. 是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM；
    
    2. 如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读也有写，请使用InnoDB。
    
    3. 系统奔溃后，MyISAM恢复起来更困难，能否接受；
    
    4. MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。
### 3. **InnoDB为什么推荐使用自增ID作为主键？**

  **答：自增ID可以保证每次插入时B+索引是从右边扩展的，可以避免B+树和频繁合并和分裂（对比使用UUID）。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差。**

### 4. VarChar最多存储多少个字节？

最多可以存储65535个字节

### 5. InnoDB中一棵B+树可以存放多少行数据？

我们都知道计算机在存储数据的时候，有最小存储单元，这就好比我们今天进行现金的流通最小单位是一毛。在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。

![image-20220726202946975](/Users/gongwei/Library/Application Support/typora-user-images/image-20220726202946975.png)

数据表中的数据都是存储在页中的，所以一个页中能存储多少行数据呢？假设一行数据的大小是1k，那么一个页可以存放16行这样的数据。

这里我们先假设B+树高为2，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。

上文我们已经说明单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k，实际上现在很多互联网业务数据记录大小通常就是1K左右）。

那么现在我们需要计算出非叶子节点能存放多少指针，其实这也很好算，**我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16384/14=1170。那么可以算出一棵高度为2的B+树，能存放1170*16=18720条这样的数据记录。**

根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170*1170*16=**21902400条这样的记录**。所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。

### 6.  为什么MySQL的索引要使用B+树而不是其它树形结构?比如B树

因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低

### B树和B+树的区别

1、B树的叶子节点没有指针，B+树有，有指针可以更加方便范围查询，同一种范围查询，b树可能得多次从头节点开始遍历；

2、因为B树不管叶子节点还是非叶子节点，都会保存数据

![image-20220924211027971](/Users/gongwei/Library/Application Support/typora-user-images/image-20220924211027971.png)

### 7. 索引覆盖是什么？

在索引[数据结构](https://so.csdn.net/so/search?q=数据结构&spm=1001.2101.3001.7020)中，通过索引值可以直接找到要查询字段的值，而不需要通过主键值回表查询，那么就叫覆盖索引

如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称 之为“覆盖索引”。

### 8.非聚簇索引一定会回表查询吗?

不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。

举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age < 20的查询时，在索引的

的叶子节点上，已经包含了age信息，不会再次进行回表查询。

### 9. 联合索引

创建a,b,c的联合索引，等于创建a,(a,b),(a,b,c)索引

### 10. 不可重复读和幻读的区别

不可重复读的重点是修改（读出来的数据不一致），幻读的重点在于新增或者删除（读出来的条数不一致）。

例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导致A再读自己的工资时工资变为 2000；这就是不可重复读。

例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：≥≥≥假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记 录就变为了5条，这样就导致了幻读。

### 11.最左前缀匹配

### 12.B树和B+树有什么区别

### 13.MySQL主从复制原理

#### 主从复制可以分为：[链接](https://blog.csdn.net/summer_fish/article/details/120075634)

- **主从同步：**当用户写数据主服务器必须和从服务器**同步**了才告诉用户写入成功，等待时间比较长。
- **主从半同步：**当用户访问写数据主服务器写入并同步**其中一个从服务器**就返回给用户成功。
- **主从异步：**只要用户**访问**写数据主服务器，立即返回给用户。

##### 异步复制

一个主库，一个或多个从库，数据**异步同步**到从库。

![img](https://img-blog.csdnimg.cn/2021090310371999.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc3VtbWVyX3dlc3RfZmlzaA==,size_18,color_FFFFFF,t_70,g_se,x_16)

这种模式下，主节点不会主动推送数据到从节点，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理。

这样就会有一个问题，主节点如果崩溃掉了，此时主节点上已经提交的事务可能并没有传到从节点上，如果此时，强行将从提升为主，可能导致新主节点上的数据不完整。

##### 半同步复制（也叫 `semi-sync` 复制）

在异步复制的基础上，确保任何一个主库上的事物在提交之前**至少有一个从库**已经收到该事物并日志记录下来。

![img](https://img-blog.csdnimg.cn/20210903104121302.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc3VtbWVyX3dlc3RfZmlzaA==,size_18,color_FFFFFF,t_70,g_se,x_16)

介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是**等待至少一个从库接收到并写到 relay log 中才返回成功信息给客户端(只能保证主库的 Binlog 至少传输到了一个从节点上)**，否则需要等待直到超时时间然后切换成异步模式再提交。

相对于异步复制，半同步复制提高了数据的安全性，一定程度的保证了数据能成功备份到从库，同时它也造成了一定程度的延迟，但是比全同步模式延迟要低，这个延迟最少是一个 TCP/IP 往返的时间。所以，半同步复制最好在低延时的网络中使用。

半同步模式不是 MySQL 内置的，从 MySQL 5.5 开始集成，需要 master 和 slave 安装插件开启半同步模式。


##### 同步复制

在 MySQL cluster 中特有的复制方式。

当主库执行完一个事务，然后所有的从库都复制了该事务并**成功执行完**才返回成功信息给客户端。

因为需要等待所有从库执行完该事务才能返回成功信息，所以全同步复制的性能必然会收到严重的影响。

#### MySQL 的主从复制工作过程大致如下：

- 从库生成两个线程，一个 I/O 线程（**Slave_IO_Running**），一个 SQL 线程（**Slave_SQL_Running**）；（slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，）

- I/O 线程去请求主库的 binlog，并将得到的 binlog 日志写到 relay log(中继日志) 文件中；

- 主库会生成一个 log dump 线程，用来给从库 I/O 线程传 binlog；
  - 该线程连接到Master，Master 的 bin-log dump线程会将binlog内容发送给I/O线程，I/O线程接受到binlog 再将内容写到本地的 relay log。
  - （主节点为每个I/O线程启动一个log dump线程【因为多台从机，所以多个I/O线程】，用于向其发送二进制事件，并保存至从节点本地的中继日志中）
  - （master机器上的binlog dump 线程会将binlog的内容发送给该I\O线程。该I/O线程接收到binlog内容后，再将内容写入到本地的relay log）
  - 当Master的 binlog 发生变化，binlog dump会通知Slave，并将相应binlog发送给Slave。

- SQL 线程会读取 relay log 文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致
  - mysql的从库数据目录下存在大量mysql-relay-log日志，该日志同步完成之后就会被系统自动删除，存在大量日志，说明主从同步延迟很厉害

![img](https://img-blog.csdnimg.cn/20210903103213559.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc3VtbWVyX3dlc3RfZmlzaA==,size_20,color_FFFFFF,t_70,g_se,x_16)



#### 主从复制方式

MySQL 主从复制支持两种不同的日志格式，这两种日志格式也对应了各自的复制方式。当然也有二者相结合的混合类型复制。

##### 语句复制

基于语句的复制相当于**逻辑复制**，**即二进制日志中记录了操作的语句，通过这些语句在从数据库中重放来实现复制**。

这种方式简单，**二进制文件小，传输带宽占用小**。但是基于语句更新依赖于其它因素，比如插入数据时利用了时间戳。

因此在开发当中，我们应该尽量将业务逻辑逻辑放在代码层，而不应该放在 MySQL 中，不易拓展。

特点：

- 传输效率高，减少延迟。

- 在从库更新不存在的记录时，语句赋值不会失败。而行复制会导致失败，从而更早发现主从之间的不一致。

- 设表里有一百万条数据，一条sql更新了所有表，基于语句的复制仅需要发送一条sql，而基于行的复制需要发送一百万条更新记录

##### 行数据复制

基于行的复制相当于**物理复制，即二进制日志中记录的实际更新数据的每一行**。

这样导致复制的压力比较大，日志占用的空间大，传输带宽占用大。但是这种方式比基于语句的复制要更加精确。

特点：

- 不需要执行查询计划。

- 不知道执行的到底是什么语句。

- 例如一条更新用户总积分的语句，需要统计用户的所有积分再写入用户表。如果是基于语句复制的话，从库需要再一次统计用户的积分，而基于行复制就直接更新记录，无需再统计用户积分。
- 在从库更新不存在的记录时，语句赋值不会失败。而行复制会导致失败，从而更早发现主从之间的不一致。

##### 混合类型的复制

一般情况下，默认采用**基于语句**的复制，一旦发现基于语句无法精确复制时，就会采用基于行的复制。（MySQL自己决定）

### 15.MySQL主从延迟怎么产生的，怎么解决

[链接](https://www.jianshu.com/p/634c661227d4)

这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，**由于从库从主库拷贝日志以及串行执行 SQL 的特点**，在高并发场景下，从库的数据一定会比主库慢一些，是**有延时**的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

由于Slave_Sql_Running是单线程的，所以一个DDL卡住了，需要10分钟，那么之后的DDL都需要等这个DDL执行完了才会执行，所以导致了主从延时

而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。

所以 MySQL 实际上在这一块有两个机制，一个是**半同步复制**，用来解决主库数据丢失问题；一个是**并行复制**，用来解决主从同步延时问题。

这个所谓**半同步复制**，也叫 `semi-sync` 复制，指的就是主库写入 binlog 日志之后，就会将**强制**此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 之后才会认为写操作完成了。

所谓**并行复制**，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后**并行重放不同库的日志**，这是库级别的并行。



以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。

是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。

我们通过 MySQL 命令：

```
show slave status
```

查看 `Seconds_Behind_Master` ，可以看到从库复制主库的数据落后了几 ms。

一般来说，如果主从延迟较为严重，有以下解决方案：

- 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
- 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
- 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。
- 大表DDL在业务低峰期操作
  - **DDL（Data Definition Languages）语句：**数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象的定义。常用的语句关键字主要包括 create、drop、alter等。
  - **DML（Data Manipulation Language）语句：**数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性，常用的语句关键字主要包括 insert、delete、udpate 和select 等。(增添改查）

- 强制走主库方案；
  - 对于必须要拿到最新结果的请求，强制将其发到主库上。比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结果，就必须走主库。>对于可以读到旧数据的请求，才将其发到从库上。在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。

- sleep 方案；
  - 主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令。
     这个方案的假设是，大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据。
- 判断主备无延迟方案；
  - 第一种方法，show slave status 结果里的 seconds_behind_master 参数的值，可以用来衡量主备延迟时间的长短。
     所以第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。
  - 第二种方法，对比位点确保主备无延迟：Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成
- 打开半同步复制，确保主库接收到**至少一个从库**的 ack 之后才会认为写操作完成了。
- 大事务拆分

#### 相关参数

首先在服务器上执行show slave satus;可以看到很多同步的参数：

**Master_Log_File**：                      SLAVE中的I/O线程当前正在读取的主服务器二进制日志文件的名称
 **Read_Master_Log_Pos**：        在当前的主服务器二进制日志中，SLAVE中的I/O线程已经读取的位置
 **Relay_Log_File**：                        SQL线程当前正在读取和执行的中继日志文件的名称
 **Relay_Log_Pos**：                        在当前的中继日志中，SQL线程已读取和执行的位置
 **Relay_Master_Log_File**：      由SQL线程执行的包含多数近期事件的主服务器二进制日志文件的名称
 **Slave_IO_Running**：                 I/O线程是否被启动并成功地连接到主服务器上
 **Slave_SQL_Running**：              SQL线程是否被启动
 **Seconds_Behind_Master**：     从属服务器SQL线程和从属服务器I/O线程之间的时间差距，单位以秒计。

**从库同步延迟情况出现的表现**

- show slave status显示参数Seconds_Behind_Master不为0，这个数值可能会很大

- show slave status显示参数Relay_Master_Log_File和Master_Log_File显示bin-log的编号相差很大，说明bin-log在从库上没有及时同步，所以近期执行的bin-log和当前IO线程所读的bin-log相差很大

- mysql的从库数据目录下存在大量mysql-relay-log日志，该日志同步完成之后就会被系统自动删除，存在大量日志，说明主从同步延迟很厉害

### 16.双1策略

### 17.MySQL表和库的并发数

### 18.大表变更有什么影响

### 19.建立数据库索引需要考虑哪些问题？

1. 经常出现在where子句中的字段，尤其是大表，应创建索引

2. 查询中排序的字段，应该创建索引（ B + tree 有顺序）

3. 统计或者分组字段，应该创建索引

4. 频繁修改的字段应该避免创建索引

5. 索引应创建在选择性高，重复度低的字段上，如员工表，姓名和性别都作为查询条件，姓名更适合建立索引。如果两个同时建立了索引，MySQL也会自动选择以姓名作为索引查询

   - 索引的意义是帮助尽可能快的降低待查数据规模。如果使用一个用完之后数据规模没咋减少的，反而还要费心维护索引列就得不偿失了。

6. 索引应该建立在小字段上，对于大的文本甚至超长字段，尽量不建立索引

7. 考虑最左前缀匹配

8. 不能建立过多索引（不能每个字段都建立索引），会影响数据增删改效率，因为每次增删改都会修改索引

9. 建立索引时，应该尽量扩展已有索引而不是一来就新建索引

   - 扩展：CREATE INDEX ON table(one, two); → CREATE INDEX ON table(one, two, three)
     新建：CREATE INDEX ON table(one) ; CREATE INDEX ON table(three)
     查询：
     SELECT ~ FROM ~ WHERE three> 1024; (扩展后满足最左索引，新建满足索引)
     SELECT ~ FROM ~ WHERE one AND two AND three;(扩展后满足索引，新建后部分索引可能用不上)
   - 复用索引

10. 索引不能参与计算

    举个例子：

    ```
    SELECT ~ FROM ~ WHERE uid + 1 = 2000;
    SELECT ~ FROM ~ WHERE add_one(uid) = 2000;
    ```

    讲个鬼故事：带函数的条件项无法使用索引。

11. 索引不存储null值

    - 更准确的说，单列索引不存储null值，[复合索引](https://so.csdn.net/so/search?q=复合索引&spm=1001.2101.3001.7020)不存储全为null的值。索引不能存储Null，所以对这列采用is null条件时，因为索引上根本没Null值，不能利用到索引，只能全表扫描。（null值不会像其他取值一样出现在索引树的叶子节点上。）

    - 最好在设计数据表的时候就将字段设置为 NOT NULL 约束，比如可以将 INT 类型的字段，默认值设置为 0。将字符类型的默认值设置为空字符串 '' 。同理，在查询中使用 not like 也无法使用索引，导致全表扫描

12. **尽量避免大事务操作，提高系统并发能力。**

### 20.数据库索引失效的集中情况

1. 使用索引时候需要满足最左前缀匹配

   - 过滤条件要使用索引，必须按照索引建立的顺序，依次满足，一旦跳过某个字段，索引后面的字段都无法被使用。

   - 如果组合索引为：(name,email)

     name and email -- 使用索引
     name -- 使用索引
     email -- 不使用索引

2. 计算、函数、类型转换（自动或手动）导致索引失效

3. 范围条件右边的列索引失效

   应用开发中范围查询，例如：金额查询，日期查询往往都是范围查询。应将查询条件放置 WHERE 语句最后。（创建的联合索引中，务必把范围涉及到的字段写在最后）

4. 不等于（ != 或者 <> ）、not in 、not exist、 not like 会导致索引失效

5. 索引不存储null值

   - 更准确的说，单列索引不存储null值，[复合索引](https://so.csdn.net/so/search?q=复合索引&spm=1001.2101.3001.7020)不存储全为null的值。索引不能存储Null，所以对这列采用is null条件时，因为索引上根本没Null值，不能利用到索引，只能全表扫描。（null值不会像其他取值一样出现在索引树的叶子节点上。）

   - 最好在设计数据表的时候就将字段设置为 NOT NULL 约束，比如可以将 INT 类型的字段，默认值设置为 0。将字符类型的默认值设置为空字符串 '' 。同理，在查询中使用 not like 也无法使用索引，导致全表扫描
   - 任何在where子句中使用is null或is not null的语句优化器是不允许使用索引的。

6. like 以通配符 % 开头索引失效

7. OR 前后存在非索引的列，索引失效

   - 要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引

8. 数据表和表的字符集统一使用 utf8mb4

   - 统一使用 utf8mb4 （5.5.3版本以上支持）兼容性更好，统一字符集可以避免由于字符集转换产生的乱码。不同的字符集进行比较前需要进行转换会造成索引失效。

9. 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引

   ```
   select * from tb1 where email = 999; 不走索引
   ```

### 21.MySQL主要提供2种方式的索引：B-Tree索引，Hash索引

B树索引具有范围查找和前缀查找的能力，对于有N节点的B树，检索一条记录的复杂度为O(LogN)。相当于二分查找。

哈希索引只能做等于查找，但是无论多大的Hash表，查找复杂度都是O(1)。

显然，如果值的差异性大，并且以等值查找(=、 、in)为主，Hash索引是更高效的选择，它有O(1)的查找复杂度。

如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找。

### 22.MySQL中当前读和快照读的区别？

1、快照读，读取的是快照数据，不加锁的简单select都属于快照读。
2、当前读，读取的是最新版本, 并且对读取的记录加锁, 阻塞其他事务同时改动相同记录，避免出现安全问题（加锁的select 或者对数据进行增删改都会进行当前读）

- select … lock in share mode 、

  select … for update、

  update 、delete 、insert

### 23.MySQL中的事务隔离级别

MySQL默认隔离级别：可重复读

https://www.bilibili.com/video/BV1VZ4y1T7dE/?spm_id_from=333.788.recommend_more_video.1&vd_source=58acbf449edd771737ee43a78ffdabf4

![image-20220924202654277](/Users/gongwei/Library/Application Support/typora-user-images/image-20220924202654277.png)

![image-20220924203413110](/Users/gongwei/Library/Application Support/typora-user-images/image-20220924203413110.png)

### 24.MySQL有没有遇到过慢SQL，如果定位和排查慢SQL？慢查询

-explain执行计划，是否走索引，索引是否合理

https://blog.csdn.net/chenshilan3014/article/details/100920029?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-100920029-blog-124397103.pc_relevant_layerdownloadsortv1&spm=1001.2101.3001.4242.1&utm_relevant_index=3



https://www.jianshu.com/p/e5b1063a62fe

有以下字段：

![在这里插入图片描述](https://img-blog.csdnimg.cn/8d93fcfb29be439490e29ddb8a8e8a79.png)



**id列**
id列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的顺序增长的。
id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。

![在这里插入图片描述](https://img-blog.csdnimg.cn/4c584b4aa8b94ab991d39fdd698f9eea.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5aSp6buR6K-36Zet55y85Li26aOO,size_20,color_FFFFFF,t_70,g_se,x_16)

光从sql上分析，先是执行 select * from film where id = 1 ，在是执行 select 1 from actor where id = 1，最后在执行最外层的select。
所以根据执行完的结果来看，id列 数值越大执行的优先级越高。

**select_type列**
select_type 表示对应行是简单还是复杂的查询。

- simple：简单查询。查询不包含子查询和union
- primary：复杂查询中最外层的 select
- subquery：包含在 select 中的子查询（不在 from 子句中）
- derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含 义）
- union：在 union 中的第二个和随后的 select

**type列**
这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。 依次从最优到最差分别为：system > const > eq_ref > ref > range > index > ALL 一般来说，得保证查询达到range级别，最好达到ref。
![image-20221008021818077](/Users/gongwei/Library/Application Support/typora-user-images/image-20221008021818077.png)

- ALL：即全表扫描，扫描你的聚集索引的所有叶子节点。通常情况下这需要增加索引来进行优化了。

**rows列**
这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数。

**filtered 列**
是一个半分比的值，rows * filtered/100 可以估算出将要和 explain 中前一个表进行连接的行数（前一个表指 explain 中的id值比当前表id值小的 表。
并没有很重要。

**Extra**

![image-20221008021327562](/Users/gongwei/Library/Application Support/typora-user-images/image-20221008021327562.png)



**综上所述，可以得出如下结论：**

- 
- 、对需要查询和排序的字段要加索引



### MySQL事务

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220919012358757.png" alt="image-20220919012358757" style="zoom:50%;" />

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220919012426267.png" alt="image-20220919012426267" style="zoom:50%;" />

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220919012502899.png" alt="image-20220919012502899" style="zoom:50%;" />

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220919012552129.png" alt="image-20220919012552129" style="zoom:50%;" />

### 最左前缀匹配

![image-20220920185556641](/Users/gongwei/Library/Application Support/typora-user-images/image-20220920185556641.png)

![image-20220920185616801](/Users/gongwei/Library/Application Support/typora-user-images/image-20220920185616801.png)

建立a,b 或者a,c的联合索引。至于是ac还是ab，根据区分度来决定

## kafka基础知识

### 1.kafka

注册中心zookeeper（非kafka内部），2.8.0后kafka版本抛弃了zookeeper
**Producer：** 消息生产者，向kafka集群写入数据
**Consumer**： 消息消费者，获取kafka集群数据
**Consumer Group：** 消费者组，由多个consumer组成；消费者组内每个消费者消费不同分区数据，1个分区只能由1个组内的1个消费者消费；消费者之间互不影响；消费者组是逻辑上的一个订阅者
**Broker：** kafka一台服务器就是1个Broker，1个集群由多个broker组成；1个borker中容纳多个topic
**Topic：** 消息主题，将消息进行分类，可以理解为1个队列
**Partition：** 为了实现扩展性，1个topic可以分为多个partition，每个partition都是一个有序队列
**Replica**： 副本，1个topic的每个分区都有若干副本，一个leader和若干follower
**Leader**： 多个分区中有1个为主副本，即leader，生产者和消费者交流数据的对象，其余均为follower
**Follower**： 多个分区除了Leader外的其余副本，会实时从leader中同步数据，保持于leader数据的同步，Leader发生故障市，Follower会选举成为新的Leader，leader不对外服务
**Coordinator**： 协调者，为了消费者组分配分区以及冲平衡Rebalance操作

[kafka](https://so.csdn.net/so/search?q=kafka&spm=1001.2101.3001.7020)是一个分布式消息队列。具有高性能、持久化、多副本备份、横向扩展能力。生产者往队列里push消息，消费者从队列里pull消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。

kafka对外使用topic的概念，生产者往topic里写消息，消费者从读消息。为了做到水平扩展，一个topic实际是由多个partition组成的，遇到瓶颈时，可以通过增加partition的数量来进行横向扩容。单个parition内是保证消息有序。

![704507fc755a75024fa2fa89d83bc3a5.png](https://img-blog.csdnimg.cn/img_convert/704507fc755a75024fa2fa89d83bc3a5.png)

大概用法就是，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉去指定Topic的消息，然后进行业务处理。

图中有两个topic，topic 0有两个partition，topic 1有一个partition，三副本备份。可以看到consumer gourp 1中的consumer 2没有分到partition处理，这是有可能出现的，下面会讲到。

创建一条记录，记录中一个要指定对应的topic和value，**key和partition可选**。 先序列化，**然后按照topic和partition，放进对应的发送[队列](https://so.csdn.net/so/search?q=队列&spm=1001.2101.3001.7020)中**。kafka produce**都是批量请求，会积攒一批，然后一起发送，不是调send就进行立刻进行网络发包**。

如果partition没填，那么情况会是这样的：

1. **key有填**

   按照key进行哈希，相同key去一个partition。(如果扩展了partition的数量那么就不能保证了)

2. **key没填**

   round-robin（轮循）来选partition

3. 这些要发往同一个partition的请求按照配置，攒一波，然后由一个单独的线程一次性发过去。

### partition

当存在多副本的情况下，会尽量把多个副本，分配到不同的broker上。kafka会为partition选出一个leader，之后所有该partition的请求，实际操作的都是leader，然后再同步到其他的follower。当一个broker歇菜后，所有leader在该broker上的partition都会重新选举，选出一个leader。

关于partition的分配，还有leader的选举，总得有个执行者。在kafka中，这个执行者就叫controller。kafka使用zk在broker中选出一个controller，用于partition分配和leader选举。

### 消费

订阅topic是以一个消费组来订阅的，一个消费组里面可以有多个消费者。同一个消费组中的两个消费者，不会同时消费一个partition。换句话来说，就是一个partition，只能被消费组里的一个消费者消费，但是可以同时被多个消费组消费。因此，如果消费组内的消费者如果比partition多的话，那么就会有个别消费者一直空闲。

### offset的保存

一个消费组消费partition，需要保存offset记录消费到哪，以前保存在zk中，由于zk的写性能不好，以前的解决方法都是consumer每隔一分钟上报一次。这里zk的性能严重影响了消费的速度，而且很容易出现重复消费。

在0.10版本后，kafka把这个offset的保存，从zk总剥离，保存在一个名叫**__consumer_offsets topic的topic中。写进消息的key由groupid、topic、partition组成，value是偏移量offset。topic配置的清理策略是compact。总是保留最新的key，其余删掉。一般情况下，每个key的offset都是缓存在内存中，查询的**

### 2.消息传递语义

在业务中，常常都是使用At least once的模型，如果需要可重入的话，往往是业务自己实现。

#### At least once（最少一次）

先获取数据，再进行业务处理，业务处理成功后commit offset。

1、生产者生产消息异常，消息是否成功写入不确定，重做，可能写入重复的消息

2、消费者处理消息，业务处理成功后，更新offset失败，消费者重启的话，会重复消费

#### At most once（最多一次）

先获取数据，再commit offset，最后进行业务处理。

1、生产者生产消息异常，不管，生产下一个消息，消息就丢了

2、消费者处理消息，先更新offset，再做业务处理，做业务处理失败，消费者重启，消息就丢了

### 精确一次（消息幂等）

#### 生产者：

enable.idempotence = true

在某些情况下，实际上已将消息提交给了所有同步副本，但是由于网络问题，Broker无法向Producer发送确认ack。由于我们设置retries=3，所以producer将重新发送消息3次，这可能会导致topic中消息重复。

比如有一个producer向该topic发送1M消息，并且在提交消息之后但在生产者收到所有确认ack之前，broker失败了。在这种情况下，由于重试机制，最终可能在该topic上收到超过1M的消息，这也称为**at-lease-once**语义。

**当然，我们想要实现的是exactly-once语义，即：即便生产者重新发送消息，消费者也应该只收到一次相同的消息**。

此时需要进行**幂等**操作，所谓**幂等**，即指一次执行一个操作或多次执行一个操作具有相同的效果。配置**幂等**很简单，通过配置enable.idempotence=true即可,默认为false。

那么，**幂等**是如何实现的呢？由于消息是分**batch(批次)\**发送的，每个batch都有一个序列号。在Broker端，会追踪每个分区的最大序列号。如果出现序列号较小或相等的\**batch(批次)**，broker将不会将该batch写入topic。这样，除了保证了幂等性，还可以确保batch的顺序。



#### 消费者如何精确一次

通常在消息中加入唯一id（例如订单id，），在处理业务时，通过判断id来防止重复消费



### ack	确认机制

ack = 0:消息发送到缓冲区立即返回，不用等待后台线程将数据发送到正真的partion

ack = 1:消息发送到缓冲区后，同时等待后台线程将数据发送到正真的partion，但是不用等待leader将数据同步给fllower

Ack = -1 or all:消息发送到缓冲区后，同时等待后台线程将数据发送到正真的partion，还等待leader将数据同步给fllower，才给生产者回复ack

![image-20220803125728714](/Users/gongwei/Library/Application Support/typora-user-images/image-20220803125728714.png)



### 3.kafka如何保证顺序

1. 设置一个分区，这样就可以保证所有消息的顺序，但是失去了扩展性和性能

2. Kafka 中发送1条消息的时候，可以指定(topic, partition, key) 3个参数。partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同1个 partition，就是有序的。并且在消费端，Kafka 保证，1个 partition 只能被1个 consumer 消费。或者你指定 key（比如 order id），具有同1个 key 的所有消息，会发往同1个 partition。也是有序的。

### 4.kafka怎么保证消息不被重复消费

Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，**每隔一段时间**（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。

但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。

举个栗子。

有这么个场景。数据 1/2/3 依次进入 Kafka，Kafka 会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152/153/154。消费者从 Kafka 去消费的时候，也是按照这个顺序去消费。假如当消费者消费了 `offset=153` 的这条数据，刚准备去提交 offset 到 Zookeeper，此时消费者进程被重启了。那么此时消费过的数据 1/2 的 offset 并没有提交，Kafka 也就不知道你已经消费了 `offset=153` 这条数据。那么重启之后，消费者会找 Kafka 说，嘿，哥儿们，你给我接着把上次我消费到的那个地方后面的数据继续给我传递过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费。

注意：新版的 Kafka 已经将 offset 的存储从 Zookeeper 转移至 Kafka brokers，并使用内部位移主题 `__consumer_offsets` 进行存储。

其实还是得结合业务来思考，我这里给几个思路：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

### 5.如果让你写一个消息队列，该如何进行架构设计？说一下你的思路。

比如说这个消息队列系统，我们从以下几个角度来考虑一下：

- 首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？
- 其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。
- 其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
- 能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。

### 6.如何提高kafka的消费速率

1. 增加分区数量
2. 关闭autocommit（偏移量手工提交可以按需减少分区偏移量的更新，有利于提升消费速度）
3. 增加单次拉取消息的大小（大量消息的场景下可减少拉取消息的次数）
4. 如果不考虑数据一致性，可以将key值平均一下，这样每个分区的消息大小都差不多，有利于负载均衡
5. 如果没有开启压缩，最好开启压缩（需要重启集群），可大大提高通信效率，有得消费速度提升

### kafka零拷贝和顺序读写

#### 零拷贝

1、第一次：将磁盘文件，读取到操作系统内核缓冲区；
2、第二次：将内核缓冲区的数据，copy到application应用程序的buffer；
3、第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)；
4、第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。

![img](https://img-blog.csdnimg.cn/img_convert/fcb171bcfc630771275fdebe3994819c.png)

重新思考传统IO方式，会注意到实际上并不需要第二个和第三个数据副本。应用程序除了缓存数据并将其传输回套接字缓冲区之外什么都不做。相反，数据可以直接从读缓冲区传输到套接字缓冲区。

显然，第二次和第三次数据copy 其实在这种场景下没有什么帮助反而带来开销，这也正是零拷贝出现的意义。



#### 顺序读写

磁盘顺序读或写的速度400M/s，能够发挥磁盘最大的速度。
随机读写，磁盘速度慢的时候十几到几百K/s。这就看出了差距。
kafka将来自Producer的数据，顺序追加在partition，partition就是一个文件，以此实现顺序写入。
Consumer从broker读取数据时，因为自带了偏移量，接着上次读取的位置继续读，以此实现顺序读。
顺序读写，是kafka利用磁盘特性的一个重要体现。
![img](https://img-blog.csdnimg.cn/img_convert/0abe49153c56fc5c73326829c687e758.png)



### 7.Kafka为什么吞吐量比较高

　　1）Zero Copy机制，内核copy数据直接copy到网络设备，不必经过内核到用户再到内核的copy，减小了copy次数和上下文切换次数，大大提高了效率。
　　2）磁盘顺序读写，减少了寻道等待的时间。

​		5）分区机制，有助于提高吞吐量。

　　3）批量处理机制，服务端批量存储，客户端主动批量pull数据，消息处理效率高。





　　4）存储具有O(1)的复杂度，读物因为分区和segment，是O(log(n))的复杂度。
　　5）分区机制，有助于提高吞吐量。

### 为什么用kafka，有什么优点

1、性能卓越，单机写入TPS（每秒事务处理量）约在百万条/秒，最大的优点，就是吞吐量高；

2、可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用

### 产生数据积压，如何快速处理

1、增加分区Partitions数，一般不能大于kafka的broker数；如果大于，会出现无法消费数据的情况
2、提高消费者的速度，增大每次拉取的缓冲区数据的最大值（batch.size），或者加大每次拉取的数据条数

### kafka怎么避免重复消费

1. 如果发送的key是订单号、流水号这些，可以用数据库唯一索引保证不被重复消费
2. 可以针对消息生成md5然后保存到mysql或者redis里面，在处理消息之前先去mysql或者redis里面判断是否已经消费过。这个方案其实就是利用幂等性的思想。
3. 对于状态流转的业务，如果状态已经处于下一个状态，这时候来了一个上一状态的消息，这个消息可以不用处理

### kafka如何保证消息不丢失

![image-20221017001542979](/Users/gongwei/Library/Application Support/typora-user-images/image-20221017001542979.png)

1. `producer`端使用`producer.send(msg, callback)`带有回调的`send`方法。
2. 设置`replication.factor >= 3`。这也是`Broker`端的参数。保存多份消息冗余，不多解释了。
3. 设置`min.insync.replicas > 1`。`Broker`端参数，控制消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在生产环境中不要使用默认值 1。确保`replication.factor > min.insync.replicas`。如果两者相等，那么只要有一个副本离线，整个分区就无法正常工作了。推荐设置成`replication.factor = min.insync.replicas + 1`。



### kafka rebalance

如下情况可能会触发消费者rebalance

- 消费组里的consumer增加或减少了
- 动态给topic增加了分区
- 消费组订阅了更多的topic

主要有三种rebalance的策略：**range()、round-robin(轮询)、sticky(粘性)**。

Kafka 提供了消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。默认情况为range分配策略。

假设一个主题有10个分区(0-9)，现在有三个consumer消费：

（1）range策略就是按照分区序号排序(范围分配)，假设 n＝分区数／消费者数量 = 3， m＝分区数%消费者数量 = 1，那么前 m 个消费者每个分配 n+1 个分区，后面的（消费者数量－m ）个消费者每个分配 n 个分区。

比如分区0~3给一个consumer，分区4~6给一个consumer，分区7~9给一个consumer。

（2）round-robin策略就是轮询分配

比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer

（3）sticky策略初始时分配策略与round-robin类似，但是在rebalance的时候，需要保证如下两个原则。

分区的分配要尽可能均匀 。
分区的分配尽可能与上次分配的保持相同。
当两者发生冲突时，第一个目标优先于第二个目标 。这样可以最大程度维持原来的分区分配的策略。比如对于第一种range情况的分配，如果第三个consumer挂了，那么重新用sticky策略分配的结果如下：

consumer1除了原有的0~3，会再分配一个7
consumer2除了原有的4~6，会再分配8和9



1、可能重复消费: Consumer被踢出消费组，可能还没有提交offset，Rebalance时会Partition重新分配其它Consumer,会造成重复消费，虽有幂等操作但耗费消费资源，亦增加集群压力

2、集群不稳定：Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大

3、影响消费速度：频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance

## Go面试题

### go内存逃逸

内存逃逸：go中从栈内存逃逸到堆内存。

#### 为什么要尽量避免内存逃逸？

因为如果变量的内存发生逃逸，它的生命周期就是不可知的，其会被分配到堆上，而堆上分配内存不能像栈一样会自动释放，为了解放程序员双手，专注于业务的实现，go实现了gc垃圾回收机制，但gc会影响程序运行性能，所以要尽量减少程序的gc操作。

#### 三、引发内存逃逸的常见情况

1. 在方法内把局部变量指针返回，被外部引用，其生命周期大于栈，则溢出。
2. 发送指针或带有指针的值到channel，因为编译时候无法知道那个goroutine会在channel接受数据，编译器无法知道什么时候释放。
3. 在一个切片上存储指针或带指针的值。比如[]*string，导致切片内容逃逸，其引用值一直在堆上。
4. 因为切片的append导致超出容量，切片重新分配地址，切片背后的存储基于运行时的数据进行扩充，就会在堆上分配。
5. 在interface类型上调用方法，在Interface调用方法是动态调度的，只有在运行时才知道。（fmt.println）

#### 四、如何避免内存逃逸

1. 不要盲目使用变量指针作为参数，虽然减少了复制，但变量逃逸的开销更大。
2. 预先设定好slice长度，避免频繁超出容量，重新分配。
3. 一个经验是，指针指向的数据大部分在堆上分配的，请注意。

### go中 = 和 ：= 区别

= 是赋值， := 是声明变量并赋值。

### go中指针的作用

1、函数参数传递时，如果结构体较大，那么可以节省空间

2、函数内修改，函数外也能感知

### go中如何拼接字符串

#### 原生拼接方式"+"

Go语言原生支持使用+操作符直接对两个字符串进行拼接，使用例子如下：

```
var s string
s += "wz"
s += "真帅"
```

这种方式使用起来最简单，基本所有语言都有提供这种方式，使用+操作符进行拼接时，会对字符串进行遍历，计算并开辟一个新的空间来存储原来的两个字符串。

#### 字符串格式化函数fmt.Sprintf

Go语言中默认使用函数fmt.Sprintf进行字符串格式化，所以也可使用这种方式进行字符串拼接：

```
str := "wz"
str2 := "真帅"
str = fmt.Sprintf("%s%s", str, str2)

```

#### strings.join

Strings.join方法可以将一个string类型的切片拼接成一个字符串，可以定义连接操作符，使用如下：

```

baseSlice := []string{"wz", "真帅"}
strings.Join(baseSlice, "")
```

#### Strings.builder

Go语言提供了一个专门操作字符串的库strings，使用strings.Builder可以进行字符串拼接，提供了writeString方法拼接字符串，使用方式如下：

```
s1 := "hello"
s2 := "word"
var build strings.Builder
build.WriteString(s1)
build.WriteString(s2)
s3 := build.String()
fmt.Println(s3)
```

#### bytes.[Buffer](https://so.csdn.net/so/search?q=Buffer&spm=1001.2101.3001.7020)

因为string类型底层就是一个byte数组，所以我们就可以Go语言的bytes.Buffer进行字符串拼接。bytes.Buffer是一个一个缓冲byte类型的缓冲器，这个缓冲器里存放着都是byte。使用方式如下：

```
s1 := "hello"
s2 := "word"
var bt bytes.Buffer
bt.WriteString(s1)
bt.WriteString(s2)
s3 := bt.String()
fmt.Println(s3)
```

#### 综合对比性能排序：

```
strings.join` ≈ `strings.builder` > `bytes.buffer` > `[]byte`转换`string` > "+" > `fmt.sprintf
```

- 当进行少量字符串拼接时，直接使用+操作符进行拼接字符串，效率还是挺高的，但是当要拼接的字符串数量上来时，+操作符的性能就比较低了；
- 函数fmt.Sprintf还是不适合进行字符串拼接，无论拼接字符串数量多少，性能损耗都很大，还是老老实实做他的字符串格式化就好了；
- strings.Builder无论是少量字符串的拼接还是大量的字符串拼接，性能一直都能稳定，这也是为什么Go语言官方推荐使用strings.builder进行字符串拼接的原因，在使用strings.builder时最好使用Grow方法进行初步的容量分配，观察strings.join方法的benchmark就可以发现，因为使用了grow方法，提前分配好内存，在字符串拼接的过程中，不需要进行字符串的拷贝，也不需要分配新的内存，这样使用strings.builder性能最好，且内存消耗最小。
- bytes.Buffer方法性能是低于strings.builder的，bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，不像strings.buidler这样直接将底层的 []byte 转换成了字符串类型返回，这就占用了更多的空间。

### go 如何判断 map 中是否包含某个 key ？

```
import "fmt"

func main() {
    dict := map[string]int{"key1": 1, "key2": 2}
    value, ok := dict["key1"]
    if ok {
        fmt.Printf(value)
    } else {
        fmt.Println("key1 不存在")
    }
}
```

以上就是golang中判断map中key是否存在的方法

还有一种简化的写法是

```
import "fmt"

func main() {
    dict := map[string]int{"key1": 1, "key2": 2}
    if value, ok := dict["key1"]; ok {
        fmt.Printf(value)
    } else {
        fmt.Println("key1 不存在")
    }
}
```

之所以能这么写是因为，这是if判断的一种高级用法

上面这种写法的意思是，在 if 里先运行表达式

```
value, ok := dict["key1"]
```

，得到变量后，再对这个变量进行判断



### Go可变参数

可以将可选参数作为可变参数以…interface{}切片的形式传入函数，有两种方案：

- 固定可选参数顺序
  方法内部通过args[0]，args[1]的形式获取可选参数，如果只想传后面的可选参数前面所有的可选参数都要传
- 不固定可选参数顺序
  方法内部通过遍历args切片中的元素，根据元素类型判断属于哪个可选参数，如果有同类型的可选参数必须自定义参数类型将它们区分开来

固定可选参数顺序的方案不具备可操作性，这里不进行介绍，下面介绍第二种方案

```
func NewConn(url string, args ...interface{}) *Conn {
   timeOut := defaultTimeOut
   failFast := defaultFailFast
   for _, arg := range args {
      switch arg.(type) {
      case time.Duration:
         timeOut = arg.(time.Duration)
      case bool:
         failFast = arg.(bool)
      }
   }
   return &Conn{
      url:      url,
      timeOut:  timeOut,
      failFast: failFast,
   }
}

// 调用
NewConn("http://www.peachesTao.com", time.Second, false)

// 只传failFast
NewConn("http://www.peachesTao.com", false)
```

#### 可选参数类型有重复的情况：

Conn结构体中增加一个security bool 可选参数，因其也是bool类型，跟failFast相同，所以必须自定义两种type为bool的类型来区分，代码如下：

```go
var (
   defaultTimeOut  = time.Second * 5
   defaultFailFast = FailFast(true)
   defaultSecurity = Security(true)
)

// 自定义FailFast类型，为bool类型的别称
type FailFast bool
// 自定义Security类型，为bool类型的别称
type Security bool

type Conn struct {
   url      string
   timeOut  time.Duration
   failFast FailFast
   security Security
}
func NewConn(url string, args ...interface{}) *Conn {
   timeOut := defaultTimeOut
   failFast := defaultFailFast
   security := defaultSecurity
   for _, arg := range args { //遍历切片，根据不同的类型获取可选参数值
      switch arg.(type) {
      case time.Duration:
         timeOut = arg.(time.Duration)
      case FailFast:
         failFast = arg.(FailFast)
      case Security:
         security = arg.(Security)
      }
   }
   return &Conn{
      url:      url,
      timeOut:  timeOut,
      failFast: failFast,
      security: security,
   }
}

// 调用
NewConn("http://www.peachesTao.com", time.Second)
NewConn("http://www.peachesTao.com",FailFast(true), Security(false))
NewConn("http://www.peachesTao.com",Security(false)
```

### go 判断slice是否相等

#### reflect.DeepEqual

go 的官方包提供了相应的处理函数 reflect.DeepEqual(x, y interface{}) bool。当不知道切片类型时，推荐使用此方法，因为其要去做反射判断，相对而言会比较耗时。

```go
func ReflectEqual(x, y interface{}) bool {
	return reflect.DeepEqual(x, y)
}

```

#### 循环切片进行比较

可以自己写个比较方法，这里我以 `[]byte` 的比较作为例子：

```go
// 需要明确知道切片的类型，例如：
func ForEqual(x, y []byte) bool {
	if len(x) != len(y) {
		return false
	}

	if (x == nil) != (y == nil) {
		return false
	}

	for i, v := range x {
		if v != y[i] {
			return false
		}
	}

	return true
}
————————————————
版权声明：本文为CSDN博主「Grassto」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/DisMisPres/article/details/113699714
```

#### 两种方法的Benchmark对比

```go
func BenchmarkForEqual(b *testing.B) {
	x := []byte("awsl")
	y := []byte("awxsl")
	b.ResetTimer()
	for n := 0; n < b.N; n++ {
		ForEqual(x, y)
	}
}

func BenchmarkReflectEqual(b *testing.B) {
	x := []byte("awsl")
	y := []byte("awxsl")
	b.ResetTimer()
	for n := 0; n < b.N; n++ {
		ReflectEqual(x, y)
	}
}

```

由此可见，反射付出了很惊人的性能代价。

#### 总结

当明确知道需要比较的切片类型时，建议自己写比较方法。由于 `reflect` 包的比较方法会耗费更多的时间，当然了，你如果不需要关心代码的运行效率，也可以使用 `reflect` 的方法，毕竟一行就搞定了。

### slice是线程安全的

不是

### go泛型

- 在比较两个数的大小时，没有泛型的时候，仅仅只是传入类型不一样，我们就要再写一份一模一样的函数，如果有了泛型就可以减少这类代码

```
// int
func GetMaxNumInt(a, b int) int {
	if a > b {
		return a
	}

	return b
}

// int8
func GetMaxNumInt8(a, b int8) int8 {
	if a > b {
		return a
	}

	return b
}

```

使用泛型：

```
// 使用泛型
func GetMaxNum[T int | int8](a, b T) T {
	if a > b {
		return a
	}

	return b
}

```

使用泛型2:

```
// 像声明接口一样声明
type MyInt interface {
	int | int8 | int16 | int32 | int64
}

// T的类型为声明的MyInt
func GetMaxNum[T MyInt](a, b T) T {
	if a > b {
		return a
	}

	return b
}

```

调用泛型：

```
var a int = 10
var b int = 20

// 方法1，正常调用，编译器会自动推断出传入类型是int
GetMaxNum(a, b)

// 方法2，显式告诉函数传入的类型是int
GetMaxNum[int](a, b)

```

### Go中的格式化打印：“%+v”和“%v”的区别：

```go
package main
 
import (
	"fmt"
)
 
type user struct {
	Name string
	Age  int
}
 
func main() {
	userInfo := user{
		Name: "Bill",
		Age:  25,
	}
    // 结构体打印(json格式等...)
	fmt.Printf("%+v\n", userInfo)    // {Name:Bill Age:25} 
	fmt.Printf("%v\n", userInfo)     // {Bill 25}
 
}
```

### Go 语言中如何表示枚举值(enums)？

```
通常使用常量(const) 来表示枚举值。

type StuType int32

const (

Type1 StuType = iota

Type2

Type3

Type4

)

func main() {

fmt.Println(Type1, Type2, Type3, Type4) // 0, 1, 2, 3

}
```



### [go语言的局部变量在堆上还是栈上？](https://www.cnblogs.com/howo/p/9417927.html)

```go
 1 type treeNode struct {
 2     value int
 3     left, right *treeNode
 4 }
 5 
 6 func createNode(value int) *treeNode {
 7     return &treeNode{value:value}
 8 }
 9 
10 func main() {
11     root := createNode(10)
12     fmt.Println(root)
13 }
```

上面这段代码createNode函数返回了一个局部变量的地址给main函数中的root，但是fmt.Println正常打印出来了新建的node的内容。这要是在C++中这么写，是个很典型的错误：返回局部变量的地址，该地址的内容在函数退出后会被自动释放，因为是在栈上的。

那么go语言的局部变量到底是在栈上还是堆上呢？go语言编译器会做逃逸分析（escape analysis），分析局部变量的作用域是否逃出函数的作用域，要是没有，那么就放在栈上；要是变量的作用域超出了函数的作用域，那么就自动放在堆上。所以不用担心会不会memory leak，因为go语言有强大的垃圾回收机制。这样可以释放程序员的内存使用限制，让程序员关注程序逻辑本身。

 

对于new出来的局部变量，也不是一定就放在堆上，而是根据其是否超出了函数作用域来判断是否放在堆上还是栈上。这点和C语言很不一样。

### go slice扩展

```go
func main() {
	s1 := []int{1, 2, 3, 4, 5}
	s2 := s1[:3]
	s2[2] = 9
	fmt.Println(s1)
	fmt.Println(s2)

  // 如果扩容，则不会影响到底层
	s3 := []int{1, 2, 3, 4, 5}
	s4 := s3[:3]
	s4 = append(s4, 6, 7, 8)
	s4[2] = 9
	fmt.Println(s3)
	fmt.Println(s4)
}
```

```
[1 2 9 4 5]
[1 2 9]
[1 2 3 4 5]
[1 2 9 6 7 8]

```

#### copy则不会影响底层

```go
	slice1 := []int{1, 2, 3, 4, 5}
	slice2 := []int{5, 4, 3}
	copy(slice2, slice1) // 只会复制slice1的前3个元素到slice2中
	fmt.Println(slice2)
	slice2[2] = 9
	fmt.Println(slice1)
	fmt.Println(slice2)

	slice3 := []int{1, 2, 3, 4, 5}
	slice4 := []int{5, 4, 3}
	copy(slice3, slice4) // 只会复制slice2的3个元素到slice1的前3个位置
	fmt.Println(slice3)
	slice3 = append(slice3, 6, 7, 8)
	fmt.Println(slice3)
	fmt.Println(slice4)
```

```
[1 2 3]
[1 2 3 4 5]
[1 2 9]

[5 4 3 4 5]
[5 4 3 4 5 6 7 8]
[5 4 3]

```



```
	array1 := [3]int{1, 2, 3}
	ss1 := array1
	ss1[0] = 9
	fmt.Println(ss1)
	fmt.Println(array1)
```

```
[9 2 3]
[1 2 3]

```



当切片作为参数传递时，其实就是一个结构体的传递，因为Go语言参数传递只有值传递，传递一个切片就会浅拷贝原切片，但因为底层数据的地址没有变，所以在函数内对切片的修改，也将会影响到函数外的切片，举例：

```go


func modifySlice(s []string) {
	s[0] = "song"
	s[1] = "Golang"
	fmt.Println("out slice: ", s)
}

func main() {
	s := []string{"asong", "Golang梦工厂"}
	modifySlice(s)
	fmt.Println("inner slice: ", s)
}
// 运行结果
out slice:  [song Golang]
inner slice:  [song Golang]
```

不过这也有一个特例，先看一个例子：

```go
func appendSlice(s []string) {
	s = append(s, "快关注！！")
	fmt.Println("out slice: ", s)
}

func main() {
	s := []string{"asong", "Golang梦工厂"}
	appendSlice(s)
	fmt.Println("inner slice: ", s)
}
// 运行结果
out slice:  [asong Golang梦工厂 快关注！！]
inner slice:  [asong Golang梦工厂]
```

因为切片发生了扩容，函数外的切片指向了一个新的底层数组，所以函数内外不会相互影响，因此可以得出一个结论，当参数直接传递切片时，**如果指向底层数组的指针被覆盖或者修改（copy、重分配、append触发扩容），此时函数内部对数据的修改将不再影响到外部的切片，代表长度的len和容量cap也均不会被修改。**

参数传递切片指针就很容易理解了，如果你想修改切片中元素的值，并且更改切片的容量和底层数组，则应该按指针传递。

### range[遍历](https://so.csdn.net/so/search?q=遍历&spm=1001.2101.3001.7020)切片有什么要注意的？

```go
package main

import (
	"fmt"
)

type user struct {
	name string
	age  uint64
}

func main() {
	u := []user{
		{"asong", 23},
		{"song", 19},
		{"asong2020", 18},
	}
	for _, v := range u {
		if v.age != 18 {
			v.age = 20
		}
	}
	fmt.Println(u)
}

// 运行结果
[{asong 23} {song 19} {asong2020 18}]
```

这种可以

```go
package main

import (
 "fmt"
)

type user struct {
 name string
 age uint64
}

func main()  {
 u := []user{
  {"asong",23},
  {"song",19},
  {"asong2020",18},
 }
 for k,v := range u{
  if v.age != 18{
   u[k].age = 18
  }
 }
 fmt.Println(u)
}
```

因为使用range遍历切片u，变量v是拷贝切片中的数据，修改拷贝数据不会对原切片有影响。

```go
package main

import (
 "fmt"
)

type user struct {
 name string
 age uint64
}

func main()  {
 u := []user{
  {"asong",23},
  {"song",19},
  {"asong2020",18},
 }
 n := make([]*user,0,len(u))
 for _,v := range u{
  n = append(n, &v)
 }
 fmt.Println(n)
 for _,v := range n{
  fmt.Println(v)
 }
}
```

```go
[0xc0000a6040 0xc0000a6040 0xc0000a6040]
&{asong2020 18}
&{asong2020 18}
&{asong2020 18}
```





```go
package main

import (
 "fmt"
)

type user struct {
 name string
 age uint64
}

func main()  {
 u := []user{
  {"asong",23},
  {"song",19},
  {"asong2020",18},
 }
 n := make([]*user,0,len(u))
 for _,v := range u{
  o := v
  n = append(n, &o)
 }
 fmt.Println(n)
 for _,v := range n{
  fmt.Println(v)
 }
}
```



细心的你们看到，我改动了哪一部分代码了嘛？对，没错，我就加了一句话，他就成功了，我在`for range`里面引入了一个中间变量，每次迭代都重新声明一个变量`o`，赋值后再将`v`的地址添加`n`切片中，这样成功解决了刚才的问题。

现在来解释一下原因：在`for range`中，变量`v`是用来保存迭代切片所得的值，因为`v`只被声明了一次，每次迭代的值都是赋值给`v`，该变量的内存地址始终未变，这样讲他的地址追加到新的切片中，该切片保存的都是同一个地址，这肯定无法达到预期效果的。这里还需要注意一点，变量`v`的地址也并不是指向原来切片`u[2]`的，因我在使用`range`迭代的时候，变量`v`的数据是切片的拷贝数据，所以直接`copy`了结构体数据。

上面的问题还有一种解决方法，直接引用数据的内存，这个方法比较好，不需要开辟新的内存空间，看代码：

```
......略
for k,_ := range u{
  n = append(n, &u[k])
 }
......略
```



### Go语言中的iota

iota 是go语言中的常量计数器

属性：

- 遇到 const 会初始化为0。
- const中每新增一行常量（不管是否出现iota关键字）iota的值都会加一，只与行数有关
- 使用iota进行常量初始化时，会保存于iota相关的表达式，并用该表达式，初始化以后的常量。

`const`同时声明多个常量时，如果省略了值，**则表示和上一行的值相同**

`<<`左移运算符 乘以2的n次方 `>>`右移运算符 除以2 的n次方

```go
// 笔试真题
package main

import "fmt"

const (
	_ = iota
	a = 1 << iota // itoa = 1  a = 1 * 2的一次方 = 2
	b // b = 1 << iota = 1 * 2 的2 次方 = 4
)

const (
	c = iota  // iota 遇见const 即初始化为 0 c = iota = 1
	d // d = iota = 1
)

func main() {
	fmt.Println(a, b, c, d) // 2 4 0 1
}

```



### GoLang之Go中两个Nil可能不相等吗

Go中两个Nil可能不相等。

接口(interface) 是对非接口值(例如指针，struct等)的封装，内部实现包含 2 个字段，类型 T 和 值 V。一个接口等于 nil，当且仅当 T 和 V 处于 unset 状态（T=nil，V is unset）。
两个接口值比较时，会先比较 T，再比较 V。 接口值与非接口值比较时，会先将非接口值尝试转换为接口值，再比较。

这个例子中，将一个nil非接口值p赋值给接口i，此时,i的内部字段为(T=*int, V=nil)，i与p作比较时，将 p 转换为接口后再比较，因此 i == p，p 与 nil 比较，直接比较值，所以 p == nil。
但是当 i 与nil比较时，会将nil转换为接口(T=nil, V=nil),与i(T=*int, V=nil)不相等，因此 i != nil。因此 V 为 nil ，但 T 不为 nil 的接口不等于 nil。

```go
func main() {
	var p *int = nil
	var i interface{} = p
	fmt.Println(i == p) // true
	fmt.Println(p == nil) // true
	fmt.Println(i == nil) // false
}

```



### golang：空struct作用

```go
struct{}可作为占位符,不占用内存.

1.利用map实现set:
mp:=make(map[string]struct{}）
原理是不用value,用占位符即可.

2.channel控制并发,用struct{}作为信号量:
ch:=make(chan strcuct{},1)
通过往ch丢入struct{}控制并发量.

3.只包含方法的空结构体也会用到struct{}

```

### go实现set

```go
package main

import "fmt"

/**
以空结构体作为map的value来实现，空结构体不占内存
*/

type Empty struct{}

var empty Empty

// Set类型
type Set struct {
	m map[int]Empty
}

// 添加元素
func (s *Set) Add(val int) {
	s.m[val] = empty // 使用一个empty单例作为所有键的值
}

// 删除元素
func (s *Set) Remove(val int) {
	delete(s.m, val)
}

// 获取长度
func (s *Set) Size() int {
	return len(s.m)
}

// 清空set
func (s *Set) Clear() {
	s.m = make(map[int]Empty)
}

// 查看某个元素是否存在
func (s *Set) Exist(val int) (ok bool) {
	_, ok = s.m[val]
	return
}

// 遍历set
func (s *Set) Traverse() {
	for v := range s.m {
		fmt.Println(v)
	}
}

```





### 1. 切片和数组的区别

●　切片是指针类型，数组是值类型

●　数组的长度是固定的，而切片不是（切片是动态的数组）

●　切片比数组多一个属性：容量（cap)

●　切片的底层是数组

- 切片扩容机制

### 2. 一个goroutine默认占用内存:2KB,而线程默认占用为8MB

### 3.了解过golang的内存管理吗?

### 4.调用函数传入结构体时，应该传值还是指针﹖说出你的理由?

#### 传指针的好处

1.传指针使得多个函数能操作同一个对象。

2.传指针比较轻量级 (8bytes),只是传内存地址，我们可以用指针传递体积大的结构体。如果用参数值传递的话, 在每次copy上面就会花费相对较多的系统开销（内存和时间）。所以当你要传递大的结构体的时候，用指针是一个明智的选择。

3.[Go语言](https://so.csdn.net/so/search?q=Go语言&spm=1001.2101.3001.7020)中channel，slice，map这三种类型的实现机制类似指针，所以可以直接传递，而不用取地址后传递指针。（注：若函数需改变slice的长度，则仍需要取地址传递指针）

### 5.线程的三种模型

1.一对一模型
 一般直接使用API或系统调用创建的线程均为一对一的线程。一个用户使用的线程就唯一对应一个内核使用的线程。

优点：用户线程具有了和内核线程一致的有点

缺点：

1、由于许多操作系统箱子了内核线程数量，因此一对一线程会让用户的线程数量受到限制

2、许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降。 

![img](https://img-blog.csdnimg.cn/20190328084043349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpaGFpZG9uZzE5OTE=,size_16,color_FFFFFF,t_70)                        

​                        


2.多对一模型
 多对一模型将多个用户线程映射到一个内核线程上，线程之间的切换由用户的代码来进行。

优点：因此相对于一对一模型，多对一模型的线程切换要快速许多。
缺点：多对一模型一大问题是，如果其中一个用户线程阻塞，那么所有的线程将都无法执行，因为此时内核里的线程也会随之阻塞。另外，在多处理器系统上，处理器的增多线程性能也不会有明显的帮助。但同时，多对一模型得到的好处是高效的上下文切换和几乎无限制的线程数量。

![img](https://img-blog.csdnimg.cn/20190328084104848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpaGFpZG9uZzE5OTE=,size_16,color_FFFFFF,t_70)

​                            

3.多对多模型
 结合了多对一模型和一对一模型的特点，将多个用户线程映射到少数但不止一个内核线程上。               

![img](https://img-blog.csdnimg.cn/2019032808412941.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpaGFpZG9uZzE5OTE=,size_16,color_FFFFFF,t_70)



### 6.模型（goroutine原理）GMP

哔站：https://www.bilibili.com/video/BV19r4y1w7Nx/?p=18&vd_source=58acbf449edd771737ee43a78ffdabf4

博文：https://www.yuque.com/aceld/golang/srxd6d



优先从 P 的本地队列获取 goroutine 来执行；如果本地队列没有，从全局队列获取，如果全局队列也没有，会从其他的 P 上偷取 goroutine。

Goroutine的并发编程模型基于GMP模型，简要解释一下GMP的含义：

**G:**表示goroutine，每个goroutine都有自己的栈空间，定时器，初始化的栈空间在2k左右，空间会随着需求增长。

**M:**抽象化代表内核线程，记录内核线程栈信息，当goroutine调度到线程时，使用该goroutine自己的栈信息。

**P:**代表调度器，负责调度goroutine，维护一个本地goroutine队列，M从P上获得goroutine并执行，同时还负责部分内存的管理。



***\*P的数目\**默认是\**CPU核心的数量\**。\**M和P的数目差不多\**，但运行时会根据当前的状态动态地创建M，\**M有一个最大值上限：10000\**；\**G与P是M:N的关系\**，M可以成千上万，远远大于N.**



- 某个线程尝试创建一个新的G，那么这个G就会被安排到这个线程的G本地队列LRQ中，如果LRQ满了，就会分配到全局队列GRQ中；
- 尝试获取当前线程的M，如果无法获取，就会从空闲的M列表中找一个，如果空闲列表也没有，那么就创建一个M，然后绑定G与P运行



1.全局队列：存放等待运行的G。

2.P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G的时候，G优先加入到P的本地队列，如果队列满了，则会把本地队列一半的G移动到全局队列。

3.P列表：所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS(可配置)个。

4.M：线程想运行任务就需要获得P，从P的本地队列获取G，P队列为空时，M会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复。

协程调度器和OS调度器通过M结合起来，每个M都代表了一个内核线程，OS调度器负责把内核线程分配到CPU的核上执行。

P的数量：由启动时环境变量GOMAXPROCS或者runtime方法GOMAXPROCS()决定。意味着在程序执行的任意时刻都只有GOMAXPROCS个协程同时运行。

M的数量：go程序启动时，会设置M的最大数量，默认10000.但内核很难支持这么多的线程数，所以这限制可以忽略。一个M阻塞了，会创建新的M。

![img](https://pic1.zhimg.com/80/v2-8e653b564583bdcc8dad669af16396c4_1440w.jpg)

M代表一个工作线程，在M上有一个P和G，P是绑定到M上的，G是通过P的调度获取的，在某一时刻，一个M上只有一个G（g0除外）。在P上拥有一个G队列，里面是已经就绪的G，是可以被调度到线程栈上执行的协程，称为运行队列。

![img](https://pic1.zhimg.com/80/v2-d9d8dadcdaf2d3119b5f488d9da7bf2c_1440w.jpg)

每个进程都有一个全局的G队列，也拥有P的本地执行队列，同时也有不在运行队列中的G。如正处于channel的阻塞状态的G，还有脱离P绑定在M的(系统调用)G，还有执行结束后进入P的gFree列表中的G等等，接下来列举一下常见的几种状态。

#### **状态汇总**

#### **G状态**

G的主要几种状态：

本文基于Go1.13，具体代码见（<GOROOT>/src/runtime/runtime2.go）

**_Gidle**：刚刚被分配并且还没有被初始化，值为0，为创建goroutine后的默认值


**_Grunnable**： 没有执行代码，没有栈的所有权，存储在运行队列中，可能在某个P的本地队列或全局队列中(如上图)。


**_Grunning**： 正在执行代码的goroutine，拥有栈的所有权(如上图)。


**_Gsyscall**：正在执行系统调用，拥有栈的所有权，与P脱离，但是与某个M绑定，会在调用结束后被分配到运行队列(如上图)。

**_Gwaiting**：被阻塞的goroutine，阻塞在某个channel的发送或者接收队列(如上图)。


**_Gdead**： 当前goroutine未被使用，没有执行代码，可能有分配的栈，分布在空闲列表gFree，可能是一个刚刚初始化的goroutine，也可能是执行了goexit退出的goroutine(如上图)。


**_Gcopystac**：栈正在被拷贝，没有执行代码，不在运行队列上，执行权在


**_Gscan** ： GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在



#### **P的状态**

**_Pidle** ：处理器没有运行用户代码或者调度器，被空闲队列或者改变其状态的结构持有，运行队列为空


**_Prunning** ：被线程 M 持有，并且正在执行用户代码或者调度器(如上图)


**_Psyscall**：没有执行用户代码，当前线程陷入系统调用(如上图)


**_Pgcstop** ：被线程 M 持有，当前处理器由于垃圾回收被停止


**_Pdead** ：当前处理器已经不被使用



#### **M的状态**

**自旋线程**：处于运行状态但是没有可执行goroutine的线程(如下图)，数量最多为GOMAXPROC，若是数量大于GOMAXPROC就会进入休眠。





![img](https://pic3.zhimg.com/80/v2-53e3e137e367b6bd2702905408282322_1440w.png)

**非自旋线程**：处于运行状态有可执行goroutine的线程。



**Channel阻塞**：当goroutine读写channel发生阻塞时候，会调用gopark函数，该G会脱离当前的M与P，调度器会执行schedule函数调度新的G到当前M。可参考上一篇文章[channel探秘](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkzMTE1NTE2MA%3D%3D%26mid%3D2247483770%26idx%3D1%26sn%3Dff4f52604f37b80095fee72e60b23373%26chksm%3Dc26e1ccdf51995db7f8f8b529cf1fc5298fd2c4eb16df75356fd71988326fbfb4134a437c91b%26scene%3D21%23wechat_redirect)。

### 6.Goroutine什么时候会发生阻塞?

阻塞在某个channel的发送或者接收队列

### 7.如果Goroutine—直占用资源怎么办,GMP模型怎么解决的这个问题?

goroutine里面有正常模式和饥饿模式，如果一个goroutine一直占用资源，那么会转饥饿模式，让排在最前面的goroutine去强行使用。是通过信号协作通知

### 8. 相比较于其他语言, Go 有什么优势或者特点？

- Go 允许跨平台编译，编译出来的是二进制的可执行文件，直接部署在对应系统上即可运行。
- Go 在语言层次上天生支持高并发，通过 goroutine 和 channel 实现。channel 的理论依据是 CSP 并发模型， 即所谓的`通过通信来共享内存`；Go 在 runtime 运行时里实现了属于自己的调度机制：GMP，降低了内核态和用户态的切换成本。
- Go 的代码风格是强制性的统一，如果没有按照规定来，会编译不通过。

### 9. goroutine 的协程有什么特点，和线程相比？

goroutine 非常的**轻量**，初始分配只有 2KB，当栈空间不够用时，会自动扩容。同时，自身存储了执行 stack 信息，用于在调度时能恢复上下文信息。

而线程比较重，一般初始大小有几 MB(不同系统分配不同)，线程是由操作系统调度，是操作系统的调度基本单位。而 golang 实现了自己的调度机制，goroutine 是它的调度基本单位。

### 10. Go 的垃圾回收机制？

Go 采用的是三色标记法，将内存里的对象分为了三种：

- 白色对象：未被使用的对象；
- 灰色对象：当前对象有引用对象，但是还没有对引用对象继续扫描过；
- 黑色对象，对上面提到的灰色对象的引用对象已经全部扫描过了，下次不用再扫描它了。

当垃圾回收开始时，Go 会把根对象标记为灰色，其他对象标记为白色，然后从根对象遍历搜索，按照上面的定义去不断的对灰色对象进行扫描标记。当没有灰色对象时，表示所有对象已扫描过，然后就可以开始清除白色对象了。

### 11. 对已经关闭的 channel 进行读写，会怎么样？

当 channel 被关闭后，如果继续往里面写数据，程序会直接 **panic** 退出。如果是读取关闭后的 channel，不会产生 pannic，还可以读到数据。但关闭后的 channel 没有数据可读取时，将得到零值，即对应类型的默认值。

为了能知道当前 channel 是否被关闭，可以使用下面的写法来判断。



```go
    if v, ok := <-ch; !ok {
        fmt.Println("channel 已关闭，读取不到数据")
    }
```

还可以使用下面的写法不断的获取 channel 里的数据：



```go
    for data := range ch {
        // get data dosomething
    }
```

这种用法会在读取完 channel 里的数据后就结束 for 循环，执行后面的代码。

### 12. map 为什么是不安全的？

map 在扩缩容时，需要进行数据迁移，迁移的过程并没有采用锁机制防止并发操作，而是会对某个标识位标记为 1，表示此时正在迁移数据。如果有其他 goroutine 对 map 也进行写操作，当它检测到标识位为 1 时，将会直接 panic。

如果我们想要并发安全的 map，则需要使用 sync.map。

### 13. gorouinte 泄漏有哪些场景

gorouinte 里有关于 channel 的操作，如果没有正确处理 channel 的读取，会导致 channel 一直阻塞住, goroutine 不能正常结束

### 14.多线程并发安全

#### **什么是线程安全**

[线程安全](https://so.csdn.net/so/search?q=线程安全&spm=1001.2101.3001.7020)是指在多线程环境下，每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的。

举一个线程不安全的例子

```
public class Test {
     private  static  int count;
    private static class Thread1 extends Thread {
        public void run() {
            for (int i = 0; i < 1000; i++) {
                count ++;
                try {
                    Thread.sleep(1);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }
 
    public static void main(String[] args) throws InterruptedException {
        Thread1  t1 = new Thread1();
        Thread1  t2 = new Thread1();
        t1.start();
        t2.start();
        //main主线程内调用join()方法：休眠主线程，等待t1、t2线程执行完毕主线程再继续，即最后输出count值
        t1.join();
        t2.join();
        System.out.println(count);
    }
}

```

 这段代码实现的逻辑很简单，首先定义了一个int型的count变量，然后开启了两个线程，每个线程执行1000次循环，循环中对count进行加1操作。等待两个线程都执行完成后，打印count的值。

 那么这段代码的输出结果是多少呢？可能很多人会说是2000。但是程序运行后却发现结果大概率不是2000，而是一个比2000略小的数，比如1998这样，而且每次运行的结果可能都不相同。

那么这是为什么呢？这就是线程不安全。线程安全是指在多线程环境下，程序可以始终执行正确的行为，符合预期的逻辑。比如我们刚刚的程序，共两个线程，每个线程对count变量累加1000次，预期的逻辑是count被累加了2000次，而代码执行的结果却不是2000，所以它是线程不安全的。

为什么是不安全的呢？因为count++的指令在实际执行的过程中不是原子性的，而是要分为读、改、写三步来进行；即先从内存中读出count的值，然后执行+1操作，再将结果写回内存中，如下图所示。
![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi02Y2I3YTUzMjVjODJjZjkxNGJmMjgwYjRkMTNjNjAxMF83MjB3LmpwZw?x-oss-process=image/format,png)



这就是线程在计算机中真实的执行过程，看起来好像没问题啊，别急，再看一张图

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMzLnpoaW1nLmNvbS84MC92Mi04ZjRlMDE3MjFkYzRlNThhOTA3YzY2M2ZlMGUwMWMyZV83MjB3LmpwZw?x-oss-process=image/format,png)

看出来问题了么？上图中线程1执行了两次自加操作，而线程2执行了一次自加操作，但是count却从6变成了8，只加了2。

我们看一下为什么会出现这种情况。当线程1读取count的值为6完成后，此时切换到了线程2执行，线程2同样读取到了count的值为6，而后进行改和写操作，count的值变为了7；此时线程又切回了线程1，但是线程1中count的值依然是线程2修改前的6，这就是问题所在！即线程2修改了count的值，但是这种修改对线程1不可见，导致了程序出现了线程不安全的问题，没有符合我们预期的逻辑

#### 通过加锁实现线程安全

https://blog.csdn.net/qq_21561501/article/details/90637859

```
package com.bpan.spring.beans.thread;

import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class ThreadLockSecurity {
    
    static int tickets = 10;
    
    class SellTickets implements Runnable{
        
        Lock lock = new ReentrantLock();

        @Override
        public void run() {
            // Lock锁机制
            while(tickets > 0) {
                
                try {
                    lock.lock();
                    
                    if (tickets <= 0) {
                        
                        return;
                    }
                        
                    System.out.println(Thread.currentThread().getName()+"--->售出第：  "+tickets+" 票");
                    tickets--;
                } catch (Exception e1) {
                    // TODO Auto-generated catch block
                    e1.printStackTrace();
                }finally {
                    
                    lock.unlock();
                    try {
                        Thread.sleep(100);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
                
            if (tickets <= 0) {
                
                System.out.println(Thread.currentThread().getName()+"--->售票结束！");
            }
            
        }
    }
    
    
    public static void main(String[] args) {
        
        
        SellTickets sell = new ThreadLockSecurity().new SellTickets();
        
        Thread thread1 = new Thread(sell, "1号窗口");
        Thread thread2 = new Thread(sell, "2号窗口");
        Thread thread3 = new Thread(sell, "3号窗口");
        Thread thread4 = new Thread(sell, "4号窗口");
        
        thread1.start();
        thread2.start();
        thread3.start();
        thread4.start();
        
        
    }
    

}

```

![在这里插入图片描述](https://img-blog.csdnimg.cn/c04c0509d8984557b1c8861dd239c20d.png)



### 15.sync.mutex

是悲观锁

悲观锁：当要对[数据库](https://cloud.tencent.com/solution/database?from=10680)中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制，在修改数据之前先锁定，再修改的方式被称之为悲观并发控制【Pessimistic Concurrency Control，缩写“PCC”，又名“悲观锁”】。

高并发写，适用于悲观锁

 乐观锁：乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果冲突，则返回给用户异常信息，让用户决定如何去做。乐观锁适用于读多写少的场景，这样可以提高程序的吞吐量。

```
package main
import (
    "fmt"
    "sync"
)
var (
    // 逻辑中使用的某个变量
    count int
    // 与变量对应的使用互斥锁
    countGuard sync.Mutex
)
func GetCount() int {
    // 锁定
    countGuard.Lock()
    // 在函数退出时解除锁定
    defer countGuard.Unlock()
    return count
}
func SetCount(c int) {
    countGuard.Lock()
    count = c
    countGuard.Unlock()
}
func main() {
    // 可以进行并发安全的设置
    SetCount(1)
    // 可以进行并发安全的获取
    fmt.Println(GetCount())
}
```

代码说明如下：

- 第 10 行是某个逻辑步骤中使用到的变量，无论是包级的变量还是结构体成员字段，都可以。

- 第 13 行，一般情况下，建议将互斥锁的粒度设置得越小越好，降低因为共享访问时等待的时间。这里笔者习惯性地将互斥锁的变量命名为以下格式：

  变量名+Guard

  以表示这个互斥锁用于保护这个变量。

- 第 16 行是一个获取 count 值的函数封装，通过这个函数可以并发安全的访问变量 count。

- 第 19 行，尝试对 countGuard 互斥量进行加锁。一旦 countGuard 发生加锁，如果另外一个 goroutine 尝试继续加锁时将会发生阻塞，直到这个 countGuard 被解锁。

- 第 22 行使用 defer 将 countGuard 的解锁进行延迟调用，解锁操作将会发生在 GetCount() 函数返回时。

- 第 27 行在设置 count 值时，同样使用 countGuard 进行加锁、解锁操作，保证修改 count 值的过程是一个原子过程，不会发生并发访问冲突。



#### 正常模式（非公平锁）：[链接](https://mp.weixin.qq.com/s?__biz=MzAwMTI1OTc2NA==&mid=2247484511&idx=1&sn=73e8a13a06b6d9ed4646a7ff84d632f6&chksm=9add25c4adaaacd2e1fa0af5b4615fe242ced251556f57f89a56a96701f20fc81d288f501325#rd)

### mutex有两种模式：**normal** 和 **starvation**

正常模式

所有goroutine按照FIFO的顺序进行锁获取，被唤醒的goroutine和新请求锁的goroutine同时进行锁获取，通常**新请求锁的goroutine更容易获取锁**(持续占有cpu)，被唤醒的goroutine则不容易获取到锁。公平性：否。

饥饿模式

所有尝试获取锁的goroutine进行等待排队，**新请求锁的goroutine不会进行锁获取**(禁用自旋)，而是加入队列尾部等待获取锁。公平性：是。

[重要连接](https://www.modb.pro/db/247756)

[重要连接](https://blog.csdn.net/weixin_52690231/article/details/125267207)

```
type Mutex struct {
 state int32
 sema  uint32
}
```

mutex 的 state 有 32 位，它的低 3 位分别表示 3 种状态：**唤醒状态**、**上锁状态**、**饥饿状态**，剩下的位数则表示当前阻塞等待的 goroutine 数量。

我们可以看到有一个字段 sema，它表示信号量标记位。所谓的信号量是用于 Goroutine 之间阻塞或唤醒的。

![在这里插入图片描述](https://img-blog.csdnimg.cn/636c1faff8a746e3a9852941719d5b1d.png)

Mutex有两种模式，在正常模式下，一个尝试加锁的goroutine会先自旋几次，尝试通过原子操作获得锁，

![在这里插入图片描述](https://img-blog.csdnimg.cn/a9bef50e6cfd46d3814a8830bc123fb9.png)

若几次自旋之后仍不能获得锁，则通过信号量排队等待。
所有等待者会按照先入先出FIFO的顺序排队。

![在这里插入图片描述](https://img-blog.csdnimg.cn/b5390345adb244d597a8cdaadfc32936.png)

但是当锁被释放，第一个等待者被唤醒后并不会直接拥有锁，而是需要和后来者竞争，也就是那些处于自旋阶段，尚未排队等待的goroutine。这种情况下后来者更有优势，一方面，它们正在CPU上运行，自然比刚被唤醒的goroutine更有优势，另一方面处于自旋状态的goroutine可以有很多，而被唤醒的goroutine每次只有一个，所以被唤醒的goroutine有很大概率拿不到锁。这种情况下它会被重新插入到队列的头部，而不是尾部。
![在这里插入图片描述](https://img-blog.csdnimg.cn/a2d94ba63b8b4dad9e936e860877aeb2.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/f2b8ad546f4a4d7893ce397967a1b35f.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/1196dfc556924fc19ff046b82fba769c.png)

而当一个goroutine本次加锁等待时间超过了1ms后，它会把当前Mutex从正常模式切换至“饥饿模式”。
在饥饿模式下，Mutex的所有权从执行Unlock的goroutine，直接传递给等待队列头部的goroutine，后来者不会自旋，也不会尝试获得锁，即使Mutex处于Unlocked的状态。它们会直接到队列的尾部排队等待。
![在这里插入图片描述](https://img-blog.csdnimg.cn/2087919f564345d6ab24c353f6d34726.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/647e96cec23947719e9a50fe497dc08b.png)

当一个等待者获得锁之后，它会在以下两种情况时，将Mutex由饥饿模式切换回正常模式。
另一种情况是它的等待时间小于1ms，也就是它刚来不久

![在这里插入图片描述](https://img-blog.csdnimg.cn/5c51c0e9862647409f8f4ebd4db3d02b.png)

第二种情况是它是最后一个等待者，等待队列已经空了，后面自然就没有饥饿的goroutine了

![在这里插入图片描述](https://img-blog.csdnimg.cn/082ed17494d34436950f663feb3efd58.png)

综上所述，在正常模式下自旋和排队是同时存在的，执行lock的goroutine会先一边自旋，尝试几次后如果还没拿到锁，就需要去排队等待了，这种排队之前先让大家来抢的模式，**能够有更高的吞吐量，因为频繁的挂起（饥饿模式下，所有goroutine都需要从队列中获取），唤醒goroutine会带来较多的开销**。但是又不能无限制的自旋，要把自旋的开销控制在较小的范围内，所以在正常模式下，Mutex有更好的性能。 但是可能会出现队列尾端的goroutine迟迟抢不到锁(尾端延迟)的情况。
而饥饿模式不再尝试自旋，所有goroutine都要排队，严格的FIFO，对于防止出现尾端延迟来讲特别重要。
![在这里插入图片描述](https://img-blog.csdnimg.cn/653df9e2959b49baa941a714f7531137.png)





所有等待锁的goroutine按先进先出的顺序等待，唤醒的goroutine不会直接拥有锁，而是回合新请求锁的goroutine竞争锁的拥有权，新请求锁的goroutine有优势（1、正在CPU上执行；2、可能同时拥有好几个锁），所以刚刚唤醒的goroutine很大可能在竞争锁时失败，此时，这个刚唤醒的goroutine会加入到等待队列的前面，如等待的goroutine等待时间超过1ms没获取到锁，则会将`Mutex`切换为饥饿模式



#### 饥饿模式（公平锁）：

是为了解决等待goroutine队列过长问题，此模式下，直接由unlock将锁交给队列中排在第一位的goroutine，同时，新进来的goroutine不会参与抢锁，也不会进入自旋状态，会直接进入队列尾部，如此就解决了老goroutine一直抢不到锁的场景。

**后面如果有新来的 Goroutine 发现是饥饿模式时， 则会直接添加到等待队列的队尾。**



饥饿模式的触发条件：（由正常模式切换为饥饿模式）

1. goroutine等待锁时间超过1ms。
2. 当前队列只剩下一个goroutine。

如果一个`goroutine`获得了锁，并且他在等待队列队尾 或者 他等待小于`1ms`，则会将`Mutex`的模式切换回正常模式



总结来看的话，正常模式下的性能是最好的，goroutine可连续多次获取锁，饥饿模式解决了取锁公平的问题，但是性能会下降，是性能和公平性的一个平衡模式。



上面可以看到`Mutex`对`goroutine`的阻塞和唤醒操作是利用`semaphore`来实现的，大致的思路是：Go runtime维护了一个全局的变量`semtable`,它保持了所有的信号量。

### 16.如果若干个Goroutine,其中有一个panic，会发生什么?

[连接](https://studygolang.com/articles/14232)

goroutine发生panic，只有自身能够recover，其它goroutine是抓不到的

先要明确一点，`panic`会停止整个进程，不仅仅是当前`goroutine`，也就是说整个程序都会凉凉

`goroutine`发生`panic`时，只会调用自身的`defer`（只有在自身的defer中写上recover才能捕获异常），所以即便主`goroutine`里写了`recover`逻辑，也无法拯救到其它`goroutine`里的`panic`。

```
go func() {
    defer func() {
        if r := recover(); r != nil {
            fmt.Println("don't worry, I can take care of myself")
        }
    }()
    cache.Set(prefix+strCityIDs, &ret, 12*time.Hour) //存入缓存
}()
```



```
package goroutine

import (
	"fmt"
	"git.garena.com/shopee/bg-logistics/go/gocommon/logger"
	"sync"
)

type GLimit struct {
	jobQueue   chan struct{}
	wg         *sync.WaitGroup
	cutShort   bool
	errorQueue chan error
}

type Job func()

func NewGLimit(jobNumber, goRoutineNumber int, cutShort ...bool) *GLimit {
	gLimit := &GLimit{
		jobQueue:   make(chan struct{}, goRoutineNumber),
		cutShort:   false,
		wg:         new(sync.WaitGroup),
		errorQueue: make(chan error, jobNumber),
	}
	if len(cutShort) != 0 && cutShort[0] == true {
		gLimit.cutShort = true
	}

	return gLimit
}

// job() 和 <-jobQueue的顺序不能调换，否则就失去了协程数量的限制作用
func (g *GLimit) RunV0(job Job) {
	g.jobQueue <- struct{}{}
	go func() {
		defer func() {
			if e := recover(); e != nil {
				err := ""
				if errInPanic, ok := e.(error); ok {
					err = errInPanic.Error()
				} else {
					err = fmt.Sprintf("PAINC: %v", e)
				}
				logger.LogErrorf("GLimit run error,%s", err)
			}
			<-g.jobQueue
		}()
		if g.cutShort && len(g.errorQueue) > 0 {
			g.wg.Done()
		} else {
			job()
		}
		return
	}()
}

func (g *GLimit) WaitCount(count int) {
	g.wg.Add(count)
}

func (g *GLimit) WaitDone() {
	g.wg.Done()
}

func (g *GLimit) WaitAll() {
	g.wg.Wait()
}

```

### 17.开发用Gin框架吗?Gin怎么做参数校验?

定义一个结构体，结构体里面的validate tag进行参数校验

```
type UpdateCompanyReq struct {
	CompanyId   uint64 `json:"company_id" validate:"required"`
	CompanyName string `json:"company_name" validate:"required,Str64NonEmptySchema"`
}
```

可以自定义校验规则

```
func Str64Schema(fl validator.FieldLevel) bool {
	if str, ok := fl.Field().Interface().(string); ok {
		strLen := utf8.RuneCountInString(str)
		if 0 <= strLen && strLen <= 64 {
			return true
		}
	}
	return false
}
```

### 18.中间件

### 19. waitgroup 原理

waitgroup 内部维护了一个计数器，当调用 `wg.Add(1)` 方法时，就会增加对应的数量；当调用 `wg.Done()` 时，计数器就会减一。直到计数器的数量减到 0 时，就会调用
 runtime_Semrelease 唤起之前因为 `wg.Wait()` 而阻塞住的 goroutine

### 20.负载均衡算法

#### 随机[负载均衡](https://so.csdn.net/so/search?q=负载均衡&spm=1001.2101.3001.7020)

功能和名字一样，随机从一堆服务器中选择一个服务器，那么实现也很简单，不做过多说明。使用了rand方法随机取一个服务器。

```
package main

import (
	"errors"
	"fmt"
	"math/rand"
)

type RandomBalance struct {
	curIndex 	int
	res		 	[]string
}

func (r *RandomBalance)Add(params ...string) error{
	if len(params) == 0{
		return errors.New("params need more than 0")
	}
	addr := params[0]
	r.res = append(r.res,addr)
	return nil
}
func (r *RandomBalance)Next() string{
	if len(r.res) == 0{
		return ""
	}
	r.curIndex = rand.Intn(len(r.res))
	return r.res[r.curIndex]
}

func (r *RandomBalance)Get() (string,error){
	return r.Next(),nil
}

func main() {
	r := new(RandomBalance)
	r.Add("localhost:8080")
	r.Add("localhost:8081")
	r.Add("localhost:8082")
	r.Add("localhost:8083")
	r.Add("localhost:8084")
	r.Add("localhost:8085")
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
}

```

#### [轮询](https://so.csdn.net/so/search?q=轮询&spm=1001.2101.3001.7020)负载均衡

这个就要注意轮询到了结尾（0-1-2-3），如果后面没有服务器要重新轮询回到0。这个就直接用取模就可以完成了。

````
package main

import (
	"errors"
	"fmt"
)

type RoundRobinBalance struct {
	curIndex 	int
	res		 	[]string
}

func (r *RoundRobinBalance)Add(params ...string) error{
	if len(params) == 0{
		return errors.New("params need more than 0")
	}
	addr := params[0]
	r.res = append(r.res,addr)
	return nil
}
func (r *RoundRobinBalance)Next() string{
	if len(r.res) == 0{
		return ""
	}
	res := r.res[r.curIndex]
	r.curIndex = (r.curIndex + 1) % len(r.res)
	return res
}

func (r *RoundRobinBalance)Get() (string,error){
	return r.Next(),nil
}

func main() {
	r := new(RoundRobinBalance)
	r.Add("localhost:8080")
	r.Add("localhost:8081")
	r.Add("localhost:8082")
	r.Add("localhost:8083")
	r.Add("localhost:8084")
	r.Add("localhost:8085")
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
	fmt.Println(r.Get())
}

````

### 21.通过反射调用方法

```
import(
"fmt"
"reflect"
)

type Animal struct {

}

func (a *Animal) Eat() {
	fmt.PrintLn("Eat")
}
func main(){
animal := Animal{}
v = reflect.ValueOf(&animal)
v.MethodByName("Eat")
v.Call([]reflect.Value{})

}
```

### 22.channel跟mutex哪个性能高啊

肯定是channel啊，使用mutex 意味着通信使用共享内存的方式了，golang 的通信模型通信原理就是 Don't communicate by sharing memory; share memory by communicating（不要通过共享内存来通信，要通过通信来共享内存）



#### 不要通过共享内存来通信，要通过通信来共享内存

1、使用共享内存的话在多线程的场景下为了处理竞态，需要加锁，使用起来比较麻烦。另外使用过多的锁，容易使得程序的代码逻辑艰涩难懂，并且容易使程序死锁，死锁了以后排查问题相当困难，特别是很多锁同时存在的时候。

2、go语言的channel保证同一个时间只有一个goroutine能够访问里面的数据，为开发者提供了一种优雅简单的工具，所以go原生的做法就是使用channle来通信，而不是使用共享内存来通信。

### 23.部署服务后，如何发现内存泄漏，如何解决内存泄漏

#### 什么是内存泄露？

内存泄露指的是程序运行过程中已不再使用的内存，没有被释放掉，导致这些内存无法被使用，直到程序结束这些内存才被释放的问题。



如果你启动了1个goroutine，但并没有符合预期的退出，直到程序结束，此goroutine才退出，这种情况就是goroutine泄露。

#### goroutine有两种内存泄露

每个goroutine占用2KB内存，泄露1百万goroutine至少泄露`2KB * 1000000 = 2GB`内存，为什么说至少呢？

goroutine执行过程中还存在一些变量，如果这些变量指向堆内存中的内存，GC会认为这些内存仍在使用，不会对其进行回收，这些内存谁都无法使用，造成了内存泄露。

1. goroutine本身的栈所占用的空间造成内存泄露。
2. goroutine中的变量所占用的堆内存导致堆内存泄露，这一部分是能通过heap profile体现出来的。

#### goroutine泄露的本质

goroutine泄露的本质是channel阻塞，无法继续向下执行，导致此goroutine关联的内存都无法释放，进一步造成内存泄露。

除了channel阻塞，也有可能是死循环导致goroutine无法退出

#### goroutine泄露的发现和定位

利用好go pprof获取goroutine profile文件，然后利用3个命令top、traces、list定位内存泄露的原因。

判断依据：在节点正常运行的情况下，隔一段时间获取goroutine的数量，如果后面获取的那次，某些goroutine比前一次多，如果多获取几次，是持续增长的，就极有可能是goroutine泄露。



### channel

### 有缓存通道和无缓存通道区别

- 给一个 nil channel 发送数据，造成永远阻塞 
-  从一个 nil channel 接收数据，造成永远阻塞 
-  给一个已经关闭的 channel 发送数据，引起 panic 
- 给一个已经关闭的 channel 重新关闭，引起 panic 
-  从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 



### 24.channel什么情况下会阻塞

channel作为传递消息的通道，对他的操作无非有三种，向channel发送值、从channel中取值，关闭channel。

对一个已经关闭的channel取值，如果里面有值会先取值，当值完后会取到该channel类型的零值

向一个已近关闭的channel发送至，会panic: send on closed channel

关闭一个已经关闭的channel，会panic: close of closed channel

**无缓冲例子**

无缓冲例子1

```go
func test1()  {
    /** 编译错误 deadlock，阻死 main 进程 */
    /** 演示 无缓冲在同一个main里面的 死锁例子 */
    done := make(chan bool)
    done<-true      /** 这句是输入值，它会一直阻塞，等待读取 */
    <-done          /** 这句是读取，但是在上面已经阻死了，永远走不到这里 */
    println("完成")
}
```

无缓冲例子2 (有输入 没读取的死锁)

```go
func test2()  {
    /** 编译错误 deadlock，阻死 main 进程 */
    /** 演示仅有 输入 语句，但没 读取语句 的死锁例子 */
    done := make(chan bool)
    done<-true  /** 输入，一直等待读取，哪怕没读取语句 */
    println("完成")
}
```

无缓冲例子3 (有读取 但没输的死锁)

```go
func test3()  {
    /** 编译错误 deadlock，阻死 main 进程 */
    /** 演示仅有 读取 语句，但没 输入语句 的死锁例子 */
    done := make(chan bool)
    <-done    /** 读取输出，前面没有输入语句，done 是 empty 的，所以一直等待输入 */

    println("完成")
}
```

无缓冲例子4 (协程的阻塞，不会影响 main)

```go
func test4()  {
    /** 编译通过 */
    /** 演示，协程的阻死，不会影响 main */
    done := make(chan bool)
    go func() {
        <-done /** 一直等待 */
    }()
    println("完成")
    /**
     * 控制台输出：
     *       完成
     */
}
```

无缓冲例子5 (使用 close 后，不会阻塞)

```go
func test9()  {
    /** 编译通过 */
    /** 演示，没缓存的 channel 使用 close 后，不会阻塞 */
    done := make(chan bool)
    close(done)
    //done<-true  /** 关闭了的，不能再往里面输入值 */
    <-done        /** 这句是读取，但是在上面已经关闭 channel 了，不会阻死 */
    println("完成")
}
```

**有缓冲**

有缓冲例子1 (有输入读取)

```go
func test11()  {
    /** 编译通过 */
    /** 有缓冲的 channel 不会阻塞的例子 */
    done := make(chan bool,1)
    done<-true
    <-done
    println("完成")
}
```

有缓冲例子2 (仅有输入)

```go
func test14()  {
    /** 编译通过 */
    /** 有缓冲的 channel 不会阻塞的例子 */
    done := make(chan bool,1)
    done<-true   /** 不会阻塞在这里，等待读取 */

    println("完成")
}
```

有缓冲例子3 (无输入读取阻塞)

```go
func test12()  {
    /** 编译通过 */
    /** 有缓冲的 channel 会阻塞的例子 */
    done := make(chan bool,1)
    // done<-true /** 注释这句 */
    <-done /** 虽然是有缓冲的，但是在没输入的情况下，读取，会阻塞 */
    println("完成")
}
```

有缓冲例子4 (超过缓冲值未被接受)

```go
func test13()  {
    /** 编译不通过 */
    /** 有缓冲的 channel 会阻塞的例子 */
    done := make(chan bool,1)
    done<-true
    done<-false /** 放第二个值的时候，第一个还没被人拿走，这时候才会阻塞，根据缓冲值而定 */
    println("完成")
}
```

### 25.channel是线程安全的吗

是线程安全的，通过互斥锁实现

### 26.Go语言中是如何实现继承的?

在Go语言中，可以通过结构体组合来实现继承，示例如下：

```go
// 这里Student继承了People，具有People的属性
type People struct {
    Name string
}

type Student struct{
    People
    Grade int
}
```

### 27.defer  执行顺序

#### 一、一个函数中多个defer的执行顺序

defer 的作用就是把defer关键字之后的函数执行压入一个栈中延迟执行，多个`defer`的执行顺序是后进先出LIFO，也就是先执行最后一个defer，最后执行第一个defer

**eg：**

![img](https://img2020.cnblogs.com/blog/1258817/202111/1258817-20211102170254104-470153957.png)

 **输出：**

![img](https://img2020.cnblogs.com/blog/1258817/202111/1258817-20211102170352876-129644382.png)

 

#### 二、defer、return、返回值的执行返回值顺序

在此之前，先理解一下return返回值的运行机制：return并非原子操作，共分为赋值、返回值两步操作。

defer、return、返回值三者的执行是：return最先执行，先将结果写入返回值中（即赋值）；接着defer开始执行一些收尾工作；最后函数携带当前返回值退出（即返回值）。



#### 1、不带命名返回值

如果函数的返回值是无名的（不带命名返回值），则go语言会在执行return的时候会执行一个类似创建一个临时变量作为保存return值的动作。

**eg：**

![img](https://img2020.cnblogs.com/blog/1258817/202111/1258817-20211102171157227-725023586.png)

 **输出：**

![img](https://img2020.cnblogs.com/blog/1258817/202111/1258817-20211102171249975-415269343.png)

**解释：**

如上例子，实际上一共执行了3步操作，

1）赋值，因为返回值没有命名，所以return 默认指定了一个返回值（假设为s），首先将i赋值给s，i初始值是0，所以s也是0

2）后续的defer操作因为是针对i,进行的，所以不会影响s, 此后因为s不会更新，所以s不会变还是0

3）返回值，return s，也就是return 0
相当于：
var i int
s := i
return s

#### 2、有名返回值

有名返回值的函数，由于返回值在函数定义的时候已经将该变量进行定义，在执行return的时候会先执行返回值保存操作，而后续的defer函数会改变这个返回值(虽然defer是在return之后执行的，但是由于使用的函数定义的变量，所以执行defer操作后对该变量的修改会影响到return的值。

**eg:**

![img](https://img2020.cnblogs.com/blog/1258817/202111/1258817-20211102191818830-520704873.png)

**输出：**

**![img](https://img2020.cnblogs.com/blog/1258817/202111/1258817-20211102191857382-1129366137.png)**

**解释：**

s 就相当于命名的变量i，因为所有的操作都是基于命名变量i(s)，返回值也是i，所以每一次defer操作，都会更新返回值，执行完defer后，会返回最终i的值。



https://mp.weixin.qq.com/s?__biz=MzkyNzI1NzM5NQ==&mid=2247484778&idx=1&sn=7ceb16f634b3d479a8d5b0b8c4d50b27&source=41#wechat_redirect

聪明的你一定会说："这也太简单了，答案就是num1等于2，num2等于3"。很遗憾的告诉你，错了，正确的答案是`num1`为`1`,`num2`为2，这两个变量并不受`num1++、num2++`的影响，因为`defer`将语句放入到栈中时，也会将相关的值拷贝同时入栈。

```go
func main() {
 fmt.Println(Sum(1, 2)) //5
}

func Sum(num1, num2 int) int {
 defer fmt.Println("num1:", num1) //1
 defer fmt.Println("num2:", num2) //2
 num1++
 num2++
 return num1 + num2
}

```





### 28.init执行顺序

1. 每个源文件中可以包含多个init函数
2. init不需要手动调用
3. init函数不需要传入参数，也不会返回任何值

#### 执行顺序

1. 初始化导入的包（递归导入）
2. 对包块中声明的变量进行计算和分配初始值（var or const）
3. 执行包中的init函数
4. 执行main函数

![递归导入包](https://img-blog.csdn.net/20180308161418275?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYmVuYmVuXzIwMTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

```go
package main

import "fmt"

var _ int64=s()

func init(){
    fmt.Println("init function --->")
}

func s() int64{
    fmt.Println("function s() --->")
    return 1
}

func main(){
    fmt.Println("main --->")
}

```

执行结果

```go
function s() --->
init function --->
main --->
```

```
package main

import "fmt"

func init(){
    fmt.Println("init 1")
}

func init(){
    fmt.Println("init2")
}

func main(){
    fmt.Println("main")
}

/*执行结果：
init1
init2
main */
```



### sync.map和加锁map谁的性能好

读多写少场景：sync.map更优秀，因为我们可以直接读取read

#### sync.Map的原理介绍：

sync.Map里有两个map一个是专门用于读的read map，另一个是提供读写的dirty map；优先读read map，若不存在则加锁穿透读dirty map，同时记录一个未从read map读到的计数，当计数到达一定值，就将read map用dirty map进行覆盖


### 29. map是线程安全的吗

map 在扩缩容时，需要进行数据迁移，迁移的过程并没有采用锁机制防止并发操作，而是会对某个标识位标记为 1，表示此时正在迁移数据。如果有其他 goroutine 对 map 也进行写操作，当它检测到标识位为 1 时，将会直接 panic。

**并发读写可能引发的问题**a

```go
func runWithPanic() {
    s := make(map[int]int)
    n := 100 // 如果这个数比较小，就不会出现扩容，此时就是线程安全的
    for i := 0; i < n; i++ {
        go func(i int) {
            s[i] = i
        }(i)
    }
    for i := 0; i <= n; i++ {
        go func(i int) {
            fmt.Printf("第 %d 个元素是 %v", i, s[i])
        }(i)
    }
    time.Sleep(time.Second)
    // fatal error: concurrent map writes
}
```

**使用 `sync.RWMutex` 解决并发读写的问题**

```go
func runWithSyncRWMutex() {
    var lock sync.RWMutex
    s := make(map[int]int)
    n := 100
    for i := 0; i < n; i++ {
        go func(i int) {
            lock.Lock()
            s[i] = i
            lock.Unlock()
        }(i)
    }
    for i := 0; i <= n; i++ {
        go func(i int) {
            lock.RLock()
            fmt.Printf("第 %d 个元素是%v；", i, s[i])
            lock.RUnlock()
        }(i)
    }
    time.Sleep(time.Second)
}
```

**使用 sync.Map 2并发读写的问题**

```go
func RunWithSyncMap() {
    s := sync.Map{}
    n := 100
    for i := 0; i < n; i++ {
        go func(i int) {
            s.Store(i, i)
        }(i)
    }
    for i := 0; i <= n; i++ {
        go func(i int) {
            v, ok := s.Load(i)
            if ok {
                fmt.Printf("第 %d 个元素是%v；", i, v)
            }
        }(i)
    }
    time.Sleep(time.Second)
}
```

实际上，`sync.Map` 也是通过加锁的方式实现并发安全的

### 30.go中结构体能比较吗

- 不同类型的 struct 之间不能进行比较，编译期就会报错（GoLand 会直接提示）
- 同类型的 struct 也分为两种情况，
  - struct 的所有成员都是可以比较的，则该 strcut 的不同实例可以比较
  - struct 中含有不可比较的成员（如 Slice），则该 struct 不可以比较
    版权声明：本文为CSDN博主「CnPeng」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
    原文链接：https://blog.csdn.net/north1989/article/details/116740656

#### 同类型 struct 比较

```go
import "fmt"

type A struct {
	age  int
	name string
}

func StructCompare1() {
	aObj1 := A{
		age:  13,
		name: "张三",
	}
	aObj2 := A{
		age:  13,
		name: "张三",
	}
	fmt.Println(aObj1 == aObj2) // true

	aObj3 := &A{
		age:  13,
		name: "张三",
	}
	aObj4 := &A{
		age:  13,
		name: "张三",
	}

	fmt.Println(aObj3 == aObj4) // false

	var aObj5 A
	fmt.Println(aObj5) //{0 } ，未明确初始化时，struct 实例的成员取各自的零值
	//fmt.Println( aObj5 == nil)  // 报错，无法将 nil 转换为类型 A

	var aObj6 *A
	fmt.Println(aObj6)        // <nil> ，指针类型数据的零值为 nil
	fmt.Println(aObj6 == nil) //  true，指针类型的数据可以和 nil 比较
}
————————————————
版权声明：本文为CSDN博主「CnPeng」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/north1989/article/details/116740656
```

#### struct 包含不可比较的成员

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210513104656567.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25vcnRoMTk4OQ==,size_16,color_FFFFFF,t_70)

#### 不同类型 struct 不能比较

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210513104708819.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25vcnRoMTk4OQ==,size_16,color_FFFFFF,t_70)

#### 不可比较的类型

#### slice/数组

go 语言中规定 slice 之间不能比较，因此我们不能使用==操作符来判断两个slice是否含有全部相等元素。

但标准库提供了高度优化的 bytes.Equal 函数来判断两个字节型 slice 是否相等( []byte ):

```go
func SliceCompare() {
	slice1 := []byte{1, 2, 3}
	slice2 := []byte{1, 2, 3}
	fmt.Println(bytes.Equal(slice1, slice2)) // true
}
```

对于其他类型的 slice，我们必须自己展开每个元素进行比较，如：

```go
func equal(x, y []string) bool {
    if len(x) != len(y) {
        return false
    }
    for i := range x {
        if x[i] != y[i] {
            return false
        }
    }
    return true 
}
————————————————
版权声明：本文为CSDN博主「CnPeng」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/north1989/article/details/116740656
```

#### map

和 slice 一样，map 之间也不能进行相等比较; 唯一的例外是和 nil 进行比较。

要判断两个 map 是否包含相同的 key 和 value，我们必须通过一个循环实现:

```go
func equal(x, y map[string]int) bool {
    if len(x) != len(y) {
        return false
    }
    for k, xv := range x {
        if yv, ok := y[k]; !ok || yv != xv {
            return false
        }
    }
    return true 
}
————————————————
版权声明：本文为CSDN博主「CnPeng」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/north1989/article/details/116740656
```

上述例子中在判断 xv 和 yv 是否相等时，先通过 ok 判断了 yv 是否存在，这一步判断是必须的，如果简单地用 xv != y[k] 则可能会出现错误的结果，比如下面的例子：

```go
equal(map[string]int{"A": 0}, map[string]int{"B": 42})
```

在比较上面这两个 map 时，如果没有对 ok 进行判断，那么从后面的 map 中取 `y["A"]` 时，由于后面的 map 中不存在 A 这个键，所有会拿到值类型的零值，即0，此时 `x["A"]` 的值恰好也是 0 ，这样就会出现错误的结果。

#### 函数











```go
type Value struct {
    Name   string
    Gender string
}

func main() {
    v1 := Value{Name: "Viper", Gender: "男"}
    v2 := Value{Name: "Viper", Gender: "男"}
    if v1 == v2 {
        fmt.Println("脑子进Viper了")
        return
    }

    fmt.Println("脑子没进Viper")
}

```

我们声明了两个变量，分别是 v1 和 v2。其都是 `Value` 结构体的实例化，是同一个结构体的两个实例。

他们的比较结果是什么呢，是输出 ”脑子进Viper了“，还是 ”脑子没进Viper“？

输出结果：

脑子进Viper了



接下来继续改造上面的例子，我们在原本的结构体中增加了指针类型的引用。

第二个例子如下：

```go
type Value struct {
    Name   string
    Gender *string
}

func main() {
    v1 := Value{Name: "Viper", Gender: new(string)}
    v2 := Value{Name: "Viper", Gender: new(string)}
    if v1 == v2 {
        fmt.Println("脑子进Viper了")
        return
    }

    fmt.Println("脑子没进Viper")
}

```

这段程序输出结果是什么呢，我们猜测一下，变量依然是同一结构体的两个实例，值的赋值方式和内容都是一样的，是否应当输出 “脑子进Viper了”？

答案是：脑子没进Viper。



我们继续不信邪，试试另外的基本类型，看看结果是不是还是相等的。

第三个例子如下：

```go
type Value struct {
    Name   string
    GoodAt []string
}

func main() {
    v1 := Value{Name: "Viper", GoodAt: []string{"炸", "煎", "蒸"}}
    v2 := Value{Name: "Viper", GoodAt: []string{"炸", "煎", "蒸"}}
    if v1 == v2 {
        fmt.Println("脑子进Viper了")
        return
    }

    fmt.Println("脑子没进Viper")
}

```

程序报错

```
# command-line-arguments
./main.go:15:8: invalid operation: v1 == v2 (struct containing []string cannot be compared)
```

那不同结构体，相同的值内容呢，能否进行比较？

第四个例子：

```
type Value1 struct {
    Name string
}

type Value2 struct {
    Name string
}

func main() {
    v1 := Value1{Name: "Viper"}
    v2 := Value2{Name: "Viper"}
    if v1 == v2 {
        fmt.Println("脑子进Viper了")
        return
    }

    fmt.Println("脑子没进Viper")
}

```

程序报错

```
# command-line-arguments
./main.go:18:8: invalid operation: v1 == v2 (mismatched types Value1 and Value2)
```

那是不是就完全没法比较了呢？并不，我们可以借助强制转换来实现：

```
if v1 == Value1(v2) {
  fmt.Println("脑子进Viper了")
  return
 }
```

这样程序就会正常运行，且输出 “脑子进Viper了”。

#### 为什么

为什么 Go 结构体有的比较就是正常，有的就不行，甚至还直接报错了。难道是有什么 “潜规则” 吗？

在 Go 语言中，Go 结构体有时候并不能直接比较，当其基本类型包含：slice、map、function 时，是不能比较的。若强行比较，就会导致出现例子中的直接报错的情况。

而指针引用，其虽然都是 new(string)，从表象来看是一个东西，但其具体返回的地址是不一样的。

因此若要比较，则需改为：

```
func main() {
    gender := new(string)
    v1 := Value{Name: "Viper", Gender: gender}
    v2 := Value{Name: "Viper", Gender: gender}
    ...
}

```

这样就可以保证两者的比较。如果我们被迫无奈，被要求一定要用结构体比较怎么办？

这时候可以使用反射方法 `reflect.DeepEqual`，如下：

```
func main() {
    v1 := Value{Name: "Viper", GoodAt: []string{"炸", "煎", "蒸"}}
    v2 := Value{Name: "Viper", GoodAt: []string{"炸", "煎", "蒸"}}
    if reflect.DeepEqual(v1, v2) {
        fmt.Println("脑子进Viper了")
        return
    }

    fmt.Println("脑子没进Viper")
}

```

这样子就能够正确的比较，输出结果为 “脑子进Viper了”

#### 空结构体的作用

- 与channel组合使用，实现一个信号（空结构体不占内存，通过sizeof打印出来为0，bool为1）

### 31.两个协程怎么实现交替打奇偶数

```GO
package main
 
import (
    "fmt"
    "sync"
)

func Printer(num int) {
    wg := sync.WaitGroup{}
    wg.Add(2)
    // 无buffer 2个g同步发送和接收
    ch := make(chan struct{})
    go func() {
        defer wg.Done()
        for i := 1; i <= num; i++ {
            ch <- struct{}{}
            //奇数
            if i%2 == 1 {
                fmt.Println("g1打印:",i)
            }
        }
    }()
    go func() {
        defer wg.Done()
        for i := 1; i <= num; i++ {
            <- ch
            //偶数
            if i%2 == 0 {
                fmt.Println("g2打印:",i)
            }
        }
    }()
    wg.Wait()
}
 
func main() {
    fmt.Println("start ")
    Printer(50)
    fmt.Println("end ")
    

}
```

### Recover无法捕获的错误都有哪些？

—1、map并发写入，2、goroutine死锁，3、线程限制耗尽，4、超出可用内存，5、堆栈内存耗尽

### 怎么使用recover

panic产生异常 

```go

package main
 
import (
    "fmt"
)
 
func main() {
    GO()
    PHP()
    PYTHON()
}
 
//Go语言追求简洁优雅，所以，Go语言不支持传统的 try…catch…finally 这种异常，因为Go语言的设计者们认为，将异常与控制结构混在一起会很容易使得代码变得混乱。因为开发者很容易滥用异常，甚至一个小小的错误都抛出一个异常。在Go语言中，使用多值返回来返回错误。不要用异常代替错误，更不要用来控制流程。在极个别的情况下，也就是说，遇到真正的异常的情况下（比如除数为0了）。才使用Go中引入的Exception处理：defer, panic, recover。
 
//Go没有异常机制，但有panic/recover模式来处理错误
//Panic可以在任何地方引发，但recover只有在defer调用的函数中有效
func GO() {
    fmt.Println("我是GO，现在没有发生异常，我是正常执行的。")
}
 
func PHP() {
    // panic一般会导致程序挂掉（除非recover）  然后Go运行时会打印出调用栈
    //但是，关键的一点是，即使函数执行的时候panic了，函数不往下走了，运行时并不是立刻向上传递panic，而是到defer那，等defer的东西都跑完了，panic再向上传递。所以这时候 defer 有点类似 try-catch-finally 中的 finally。panic就是这么简单。抛出个真正意义上的异常。
    panic("我是PHP,我要抛出一个异常了，等下defer会通过recover捕获这个异常，然后正常处理，使后续程序正常运行。")
    fmt.Println("我是PHP里panic后面要打印出的内容。")
}
 
func PYTHON() {
    fmt.Println("我是PYTHON，没有defer来recover捕获panic的异常，我是不会被正常执行的。")
}
```

输出：（注意：此时的PYTHON 没有输出打印出内容，后面打印的是GO的调用栈）

我是GO，现在没有异常，我是正常执行的。
panic: 我是PHP,我要抛出一个异常了，等下defer会通过recover捕获这个异常，然后正常处理，使后续程序正常运行。
  goroutine 1 [running]:
  main.PHP()
    E:/Go/sensus_go/src/hello.go:22 +0x40
  main.main()
    E:/Go/sensus_go/src/hello.go:9 +0x2c
  exit status 2
  exit status 1

```go
package main

import (
	"fmt"
)

func main() {
	GO()
	PHP()
	PYTHON()
}

//Go语言追求简洁优雅，所以，Go语言不支持传统的 try…catch…finally 这种异常，因为Go语言的设计者们认为，将异常与控制结构混在一起会很容易使得代码变得混乱。因为开发者很容易滥用异常，甚至一个小小的错误都抛出一个异常。在Go语言中，使用多值返回来返回错误。不要用异常代替错误，更不要用来控制流程。在极个别的情况下，也就是说，遇到真正的异常的情况下（比如除数为0了）。才使用Go中引入的Exception处理：defer, panic, recover。

//Go没有异常机制，但有panic/recover模式来处理错误
//Panic可以在任何地方引发，但recover只有在defer调用的函数中有效
func GO() {
	fmt.Println("我是GO，现在没有发生异常，我是正常执行的。")
}

func PHP() {
	// 必须要先声明defer，否则不能捕获到panic异常,也就是说要先注册函数，后面有异常了，才可以调用
	defer func() {
		if err := recover(); err != nil {
			fmt.Println("终于捕获到了panic产生的异常：", err) // 这里的err其实就是panic传入的内容
			fmt.Println("我是defer里的匿名函数，我捕获到panic的异常了，我要recover，恢复过来了。")
		}
	}() //注意这个()就是调用该匿名函数的，不写会报expression in defer must be function call

	// panic一般会导致程序挂掉（除非recover）  然后Go运行时会打印出调用栈
	//但是，关键的一点是，即使函数执行的时候panic了，函数不往下走了，运行时并不是立刻向上传递panic，而是到defer那，等defer的东西都跑完了，panic再向上传递。所以这时候 defer 有点类似 try-catch-finally 中的 finally。panic就是这么简单。抛出个真正意义上的异常。
	panic("我是PHP,我要抛出一个异常了，等下defer会通过recover捕获这个异常，捕获到我时，在PHP里是不会输出的，会在defer里被捕获输出，然后正常处理，使后续程序正常运行。但是注意的是，在PHP函数里，排在panic后面的代码也不会执行的。")
	fmt.Println("我是PHP里panic后面要打印出的内容。但是我是永远也打印不出来了。因为逻辑并不会恢复到panic那个点去，函数还是会在defer之后返回，也就是说执行到defer后，程序直接返回到main()里，接下来开始执行PYTHON()")
}

func PYTHON() {
	fmt.Println("我是PYTHON，没有defer来recover捕获panic的异常，我是不会被正常执行的。")
}
```

输出：

我是GO，现在没有发生异常，我是正常执行的。
终于捕获到了panic产生的异常： 我是PHP,我要抛出一个异常了，等下defer会通过recover捕获这个异常，捕获到我时，在PHP里是不会输出的，会在defer里被捕获输出，然后正常处理，使后续程序正常运行。但是注意的是，在PHP函数里，排在panic后面的代码也不会执行的。
我是defer里的匿名函数，我捕获到panic的异常了，我要recover，恢复过来了。
我是PYTHON，没有defer来recover捕获panic的异常，我是不会被正常执行的。

#### 直接defer调用也是无效：

```
package main
 
func main() {
	defer recover()
	panic(1)
}
```

会提示

```
defer should not call recover() directly 
```

#### defer调用时多层嵌套依然无效：

```
Package main
 
func main() {
	// 第一层匿名函数
	defer func() {
		// 第二层
		func() {
			recover()
		}()
	}()
	panic(1)
}
```

### defer

#### 1.1. defer基本使用

被 defer 修饰的内容，定义在函数内，在函数将要结束时调用（也就是：先调用没有 defer 修饰的语句，最后调用被 defer 修饰的语句），通常用于释放资源（比如 `defer file.close()`）。

```go
package main

import "fmt"

func main() {
	defer fmt.Println("aaaaaaaa")
	fmt.Println("bbbbbb")
}
```

运行结果：

```
cnpeng$ go run Day1.go 
bbbbbb
aaaaaaaa
```

#### 1.2. 多个defer

函数中存在多个 defer 时，遵循 先进后出 的原则（即栈的进栈和出栈操作）。

函数运行过程中遇见 defer 修饰的内容之后，会把这些语句及其参数暂存到内存中，等其他非 defer 语句执行完毕之后，再按照 先进后出 的顺序依次执行（这其实就是一个进栈和出栈的操作）。

```GO
package main

import "fmt"

func main() {
	defer fmt.Println("aaaaaaaa")
	defer fmt.Println("bbbbbb")
	defer fmt.Println("cccccc")

	fmt.Println("没有被defer修饰的普通语句")
}
```

```
cnpeng$ go run Day1.go 
没有被defer修饰的普通语句
cccccc
bbbbbb
aaaaaaaa
```

如果程序中的某处可能会出现异常，那么定义异常前面的 defer 会被调用。

定义在异常后面的不会被调用，因为定义在异常后面的内容还没有进栈操作，所以不会出栈。

下面的示例代码中，执行 main 函数时，读取到前两个 defer 时会先暂存到栈中，遇到 calc(2,0) 时出现异常，此时 main 函数将要结束，就会按照出栈顺序执行暂存在内存中的 defer。打印错误日志的操作是在函数结束之后。而第三个 defer 没有入栈，所以函数将要结束时并不会调用它。

```
package main
import "fmt"

func main() {
	defer fmt.Println("aaaaaaaa")
	defer fmt.Println("bbbbbb")
	calc(2, 0)
	defer fmt.Println("cccccc")
}

func calc(a, b int) {
	fmt.Println(a / b)
}
```

运行结果

```
cnpeng$ go run Day1.go 
bbbbbb
aaaaaaaa
panic: runtime error: integer divide by zero

goroutine 1 [running]:
main.calc(0x2, 0x0)
        /Users/cnpeng/CnPeng/04_Demos/096_Go/ItCast/Day1.go:13 +0xac
main.main()
        /Users/cnpeng/CnPeng/04_Demos/096_Go/ItCast/Day1.go:8 +0xef

```

#### 1.3. defer和匿名函数

```
package main

import "fmt"

func main() {
	a := 10

	// 读取到这里时 a 的值为10，然后传递给了arg 。暂存到内存时存储了函数及其参数。后面的 a=20 将不会影响到这里
	defer func(arg int) {
		// 外部传入的 a 赋值给 arg.
		fmt.Println("A: arg = ", arg)
	}(a)

	// 读取到这里时，只是暂存函数到内存，还没开始引用 a 。只有执行时才会去引用 a
	defer func() {
		// 直接引用外部的 a
		fmt.Println("B: a = ", a)
	}()

	a = 20
	fmt.Println("C: a = ", a)
}

```

运行结果

```
cnpeng$ go run Day1.go 
C: a =  20
B: a =  20
A: arg =  10
```

#### 1.4. defer与循环

在循环中使用 defer 时需要特别注意，因为只有在函数执行完毕后，这些被延迟的函数才会执行，所以下面的代码极有可能会导致内存泄漏。

因为在 filenames 中的所有文件都被处理之前，没有文件会被关闭，f 对象都被暂存到了内存中，如果 filenames 中的内容特别多时，极有可能会导致内存泄漏/溢出。

```
for _, filename := range filenames {
    f, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer f.Close()

    // 省略对 f 的处理逻辑
}

```

一种解决方法是将循环体中的 defer 语句移至另外一个函数。在每次循环时，调用这个函数。

```
for _, filename := range filenames {
    if err := doFile(filename); err != nil {
        return err
    }
}

func doFile(filename string) error {
    f, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer f.Close()

    // 省略对 f 的处理逻辑
}

```

### init() 函数是什么时候执行的？

**简答**： 在main函数之前执行。

**详细**：init()函数是go初始化的一部分，由runtime初始化每个导入的包，初始化不是按照从上到下的导入顺序，而是按照解析的依赖关系，没有依赖的包最先初始化。

每个包首先初始化包作用域的常量和变量（常量优先于变量），然后执行包的`init()`函数。同一个包，甚至是同一个源文件可以有多个`init()`函数。`init()`函数没有入参和返回值，不能被其他函数调用，同一个包内多个`init()`函数的执行顺序不作保证。

执行顺序：import –> const –> var –>`init()`–>`main()`

一个文件可以有多个`init()`函数！

### mutex有几种模式？

mutex有两种模式：**normal** 和 **starvation**

正常模式

所有goroutine按照FIFO的顺序进行锁获取，被唤醒的goroutine和新请求锁的goroutine同时进行锁获取，通常**新请求锁的goroutine更容易获取锁**(持续占有cpu)，被唤醒的goroutine则不容易获取到锁。公平性：否。

饥饿模式

所有尝试获取锁的goroutine进行等待排队，**新请求锁的goroutine不会进行锁获取**(禁用自旋)，而是加入队列尾部等待获取锁。公平性：是。

### rpc

\- rpc是远程过程调用，就是本地去调用一个远程的函数，而http是通过 url和符合restful风格的数据包去发送和获取数据；
\- rpc的一般使用的编解码协议更加高效，比如grpc使用protobuf编解码。而http的一般使用json进行编解码，数据相比rpc更加直观，但是数据包也更大，效率低下；
\- rpc一般用在服务内部的相互调用，而http则用于和用户交互；

### 实现使用字符串函数名，调用函数。

思路：采用反射的Call方法实现。

```go
package main
import (
	"fmt"
    "reflect"
)

type Animal struct{
    
}

func (a *Animal) Eat(){
    fmt.Println("Eat")
}

func main(){
    a := Animal{}
    reflect.ValueOf(&a).MethodByName("Eat").Call([]reflect.Value{})
    
}
```



### （Goroutine）有三个函数，分别打印"cat", "fish","dog"要求每一个函数都用一个goroutine，按照顺序打印100次。

此题目考察channel，用三个无缓冲channel，如果一个channel收到信号则通知下一个。

```go
package main

import (
	"fmt"
	"time"
)

var dog = make(chan struct{})
var cat = make(chan struct{})
var fish = make(chan struct{})

func Dog() {
	<-fish
	fmt.Println("dog")
	dog <- struct{}{}
}

func Cat() {
	<-dog
	fmt.Println("cat")
	cat <- struct{}{}
}

func Fish() {
	<-cat
	fmt.Println("fish")
	fish <- struct{}{}
}

func main() {
	for i := 0; i < 100; i++ {
		go Dog()
		go Cat()
		go Fish()
	}
	fish <- struct{}{}

	time.Sleep(10 * time.Second)
}
```

### 两个协程交替打印10个字母和数字

思路：采用channel来协调goroutine之间顺序。

主线程一般要waitGroup等待协程退出，这里简化了一下直接sleep。

```text
package main

import (
	"fmt"
	"time"
)

var word = make(chan struct{}, 1)
var num = make(chan struct{}, 1)

func printNums() {
	for i := 0; i < 10; i++ {
		<-word
		fmt.Println(1)
		num <- struct{}{}
	}
}
func printWords() {
	for i := 0; i < 10; i++ {
		<-num
		fmt.Println("a")
		word <- struct{}{}
	}
}

func main() {
	num <- struct{}{}
	go printNums()
	go printWords()
	time.Sleep(time.Second * 1)
}
```

### channel底层数据结构

```go
type hchan struct {
    // chan 里元素数量
    qcount   uint
    // chan 底层循环数组的长度
    dataqsiz uint
    // 指向底层循环数组的指针
    // 只针对有缓冲的 channel
    buf      unsafe.Pointer
    // chan 中元素大小
    elemsize uint16
    // chan 是否被关闭的标志
    closed   uint32
    // chan 中元素类型
    elemtype *_type // element type
    //有缓冲channel内的缓冲数组会被作为一个“环型”来使用。
    //当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置
    sendx    uint   // 向channel发送数据时，下一次发送数据的下标位置
    recvx    uint   // 向channel读取数据时，下一次读取数据的下标位置
    //当循环数组中没有数据时，收到了接收请求，那么接收数据的变量地址将会写入读等待队列
    //当循环数组中数据已满时，收到了发送请求，那么发送数据的变量地址将写入写等待队列
    recvq    waitq  // buf空时，读取的goroutine等待队列
    sendq    waitq  // buf满时，写入的goroutine写等待队列

    // 保护 hchan 中所有字段
    lock mutex
}
```

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220925132544594.png" alt="image-20220925132544594" style="zoom:67%;" />

**总结hchan结构体的主要组成部分有四个：**

- **用来保存goroutine之间传递数据的循环链表。=====> buf。**
- **用来记录此循环链表当前发送或接收数据的下标值。=====> sendx和recvx。**
- **用于保存向该chan发送和从改chan接收数据的goroutine的队列。=====> sendq 和 recvq**
- **保证channel写入和读取数据时线程安全的锁。 =====> lock**



#### 向channel 发送数据

    recvq    waitq  // 读等待队列
    sendq    waitq  // 写等待队列

![image-20221008172530975](/Users/gongwei/Library/Application Support/typora-user-images/image-20221008172530975.png)

![img](https://img-blog.csdnimg.cn/662ff5cebf694ceca8d0e6e645cffeb0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAcl9tYXJ0aWFu,size_20,color_FFFFFF,t_70,g_se,x_16)



#### 从channel接收数据

    recvq    waitq  // 读等待队列
    sendq    waitq  // 写等待队列

![image-20221008172553336](/Users/gongwei/Library/Application Support/typora-user-images/image-20221008172553336.png)

![img](https://img-blog.csdnimg.cn/d7461b708aca426989a9a4e34b006a1f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAcl9tYXJ0aWFu,size_20,color_FFFFFF,t_70,g_se,x_16)





### map底层数据结构

桶的每一个元素是mmap

https://www.bilibili.com/video/BV1Nr4y1w7aa?p=14&vd_source=58acbf449edd771737ee43a78ffdabf4

![hmap](https://img-blog.csdnimg.cn/a746ae948cb74f219f4d659358f6701e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5ZW-5ZW-54yr5ZKq,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

![image-20220919004215114](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919004215114.png)

![image-20220919003858141](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003858141.png)

![image-20220919003954512](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919003954512.png)

负载因子>6.5

![image-20220919004026399](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919004026399.png)

![image-20220919004121080](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919004121080.png)

![image-20220919004305068](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919004305068.png)

![image-20220919004325602](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919004325602.png)

![image-20220919004458250](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919004458250.png)



![image-20220917181255491](/Users/gongwei/Library/Application Support/typora-user-images/image-20220917181255491.png)

### defer panic

![image-20220917232600828](/Users/gongwei/Library/Application Support/typora-user-images/image-20220917232600828.png)



### reflect 反射

李文周博客：https://www.liwenzhou.com/posts/Go/13_reflect/

李文周哔站：https://www.bilibili.com/video/BV1Wt411N72P/?spm_id_from=pageDriver&vd_source=58acbf449edd771737ee43a78ffdabf4

反射是指在程序运行期间对程序本身进行访问和修改的能力

#### reflect.typeof

种类(Kind)指的是对象归属的品种，在reflect包中有如下定义：

```
type Kind uint
const (  
    Invalid Kind = iota  // 非法类型
    Bool                 // 布尔型
    Int                  // 有符号整型
    Int8                 // 有符号8位整型
    Int16                // 有符号16位整型
    Int32                // 有符号32位整型
    Int64                // 有符号64位整型
    Uint                 // 无符号整型
    Uint8                // 无符号8位整型
    Uint16               // 无符号16位整型
    Uint32               // 无符号32位整型
    Uint64               // 无符号64位整型
    Uintptr              // 指针
    Float32              // 单精度浮点数
    Float64              // 双精度浮点数
    Complex64            // 64位复数类型
    Complex128           // 128位复数类型
    Array                // 数组
    Chan                 // 通道
    Func                 // 函数
    Interface            // 接口
    Map                  // 映射
    Ptr                  // 指针
    Slice                // 切片
    String               // 字符串
    Struct               // 结构体
    UnsafePointer        // 底层指针
)
```



```go

package main


import (
   "fmt"
   "reflect"
)


type Turbo struct {
}
func main() {
   // 初始化 struct对象
   var a = &Turbo{}
   // 获取a结构体的类型对象
   types := reflect.TypeOf(a)
   if types.Kind() == reflect.Ptr {
      elem := types.Elem()
      // 获取反射类型对象的名称和种类
      fmt.Println(elem.Name(), elem.Kind())
   }
 }
```



```go

- 第8行：定义一个struct类型对象
- 第12行：实例化Turbo结构体对象
- 第13行：获取a结构体的类型对象types
- 第15行：判断types的种类是否为指针
- 第16行：获取指针所指向的类型元素
- 第18行：获取反射类型对象的名称和种类
```

`reflect.ValueOf()`返回的是`reflect.Value`类型，其中包含了原始值的值信息。`reflect.Value`与原始值之间可以互相转换。

`reflect.Value`类型提供的获取原始值的方法如下：

|           方法           |                             说明                             |
| :----------------------: | :----------------------------------------------------------: |
| Interface() interface {} | 将值以 interface{} 类型返回，可以通过类型断言转换为指定类型  |
|       Int() int64        |     将值以 int 类型返回，所有有符号整型均可以此方式返回      |
|      Uint() uint64       |     将值以 uint 类型返回，所有无符号整型均可以此方式返回     |
|     Float() float64      | 将值以双精度（float64）类型返回，所有浮点数（float32、float64）均可以此方式返回 |
|       Bool() bool        |                     将值以 bool 类型返回                     |
|     Bytes() []bytes      |               将值以字节数组 []bytes 类型返回                |
|     String() string      |                     将值以字符串类型返回                     |

```go
func reflectValue(x interface{}) {
	v := reflect.ValueOf(x)
	k := v.Kind()
	switch k {
	case reflect.Int64:
		// v.Int()从反射中获取整型的原始值，然后通过int64()强制类型转换
		fmt.Printf("type is int64, value is %d\n", int64(v.Int()))
	case reflect.Float32:
		// v.Float()从反射中获取浮点型的原始值，然后通过float32()强制类型转换
		fmt.Printf("type is float32, value is %f\n", float32(v.Float()))
	case reflect.Float64:
		// v.Float()从反射中获取浮点型的原始值，然后通过float64()强制类型转换
		fmt.Printf("type is float64, value is %f\n", float64(v.Float()))
	}
}
func main() {
	var a float32 = 3.14
	var b int64 = 100
	reflectValue(a) // type is float32, value is 3.140000
	reflectValue(b) // type is int64, value is 100
	// 将int类型的原始值转换为reflect.Value类型
	c := reflect.ValueOf(10)
	fmt.Printf("type c :%T\n", c) // type c :reflect.Value
}
```

#### 通过反射设置变量的值

想要在函数中通过反射修改变量的值，需要注意函数参数传递的是值拷贝，必须传递变量地址才能修改变量值。而反射中使用专有的`Elem()`方法来获取指针对应的值。

```go
package main

import (
	"fmt"
	"reflect"
)

func reflectSetValue1(x interface{}) {
	v := reflect.ValueOf(x)
	if v.Kind() == reflect.Int64 {
		v.SetInt(200) //修改的是副本，reflect包会引发panic
	}
}
func reflectSetValue2(x interface{}) {
	v := reflect.ValueOf(x)
	// 反射中使用 Elem()方法获取指针对应的值
	if v.Elem().Kind() == reflect.Int64 {
		v.Elem().SetInt(200)
	}
}
func main() {
	var a int64 = 100
	// reflectSetValue1(a) //panic: reflect: reflect.Value.SetInt using unaddressable value
	reflectSetValue2(&a)
	fmt.Println(a)
}
```

#### isNil()和isValid()

`IsNil()`常被用于判断指针是否为空；`IsValid()`常被用于判定返回值是否有效

```go
func main() {
	// *int类型空指针
	var a *int
	fmt.Println("var a *int IsNil:", reflect.ValueOf(a).IsNil())
	// nil值
	fmt.Println("nil IsValid:", reflect.ValueOf(nil).IsValid())
	// 实例化一个匿名结构体
	b := struct{}{}
	// 尝试从结构体中查找"abc"字段
	fmt.Println("不存在的结构体成员:", reflect.ValueOf(b).FieldByName("abc").IsValid())
	// 尝试从结构体中查找"abc"方法
	fmt.Println("不存在的结构体方法:", reflect.ValueOf(b).MethodByName("abc").IsValid())
	// map
	c := map[string]int{}
	// 尝试从map中查找一个不存在的键
	fmt.Println("map中不存在的键：", reflect.ValueOf(c).MapIndex(reflect.ValueOf("娜扎")).IsValid())
}
```

#### 结构体标签方法

|                            方法                             |                             说明                             |
| :---------------------------------------------------------: | :----------------------------------------------------------: |
|                  Field(i int) StructField                   |          根据索引，返回索引对应的结构体字段的信息。          |
|                       NumField() int                        |                   返回结构体成员字段数量。                   |
|        FieldByName(name string) (StructField, bool)         |       根据给定字符串返回字符串对应的结构体字段的信息。       |
|            FieldByIndex(index []int) StructField            | 多层成员访问时，根据 []int 提供的每个结构体的字段索引，返回字段的信息。 |
| FieldByNameFunc(match func(string) bool) (StructField,bool) |              根据传入的匹配函数匹配需要的字段。              |
|                       NumMethod() int                       |                返回该类型的方法集中方法的数目                |
|                     Method(int) Method                      |                返回该类型方法集中的第i个方法                 |
|             MethodByName(string)(Method, bool)              |              根据方法名返回该类型方法集中的方法              |

`StructField`类型用来描述结构体中的一个字段的信息。

`StructField`的定义如下：

```go
type StructField struct {
    // Name是字段的名字。PkgPath是非导出字段的包路径，对导出字段该字段为""。
    // 参见http://golang.org/ref/spec#Uniqueness_of_identifiers
    Name    string
    PkgPath string
    Type      Type      // 字段的类型
    Tag       StructTag // 字段的标签
    Offset    uintptr   // 字段在结构体中的字节偏移量
    Index     []int     // 用于Type.FieldByIndex时的索引切片
    Anonymous bool      // 是否匿名字段
}
```

```go
type student struct {
	Name  string `json:"name"`
	Score int    `json:"score"`
}

func main() {
	stu1 := student{
		Name:  "小王子",
		Score: 90,
	}

	t := reflect.TypeOf(stu1)
	fmt.Println(t.Name(), t.Kind()) // student struct
	// 通过for循环遍历结构体的所有字段信息
	for i := 0; i < t.NumField(); i++ {
		field := t.Field(i)
		fmt.Printf("name:%s index:%d type:%v json tag:%v\n", field.Name, field.Index, field.Type, field.Tag.Get("json"))
	}

	// 通过字段名获取指定结构体字段信息
	if scoreField, ok := t.FieldByName("Score"); ok {
		fmt.Printf("name:%s index:%d type:%v json tag:%v\n", scoreField.Name, scoreField.Index, scoreField.Type, scoreField.Tag.Get("json"))
	}
}
```

Go语言提供了两种方式来获取某个字段的Tag，一个可以根据Tag中的键获取对应的值，另一个是根据Tag中的键，查询值是否存在。

- **`func (tag StructTag) Get(key string) string`** ：根据 Tag 中的键获取对应的值，例如`key1:"value1" key2:"value2"`的 Tag 中，可以传入“key1”获得“value1”。
- **`func (tag StructTag) Lookup(key string) (value string, ok bool)`** ：根据 Tag 中的键，查询值是否存在。

```go
package main
import (
   "fmt"
   "reflect"
)
type Turbo struct {
   Name string `json:"name"`
   Age  int    `json:"age"`
}
func main() {
   var turbo = &Turbo{
      Name: "迈莫coding",
      Age:  1,
   }
   types := reflect.TypeOf(turbo)
   // 判断是否为指针类型对象
   if types.Kind() == reflect.Ptr {
      // 通过elem()方法获取指针所指对象
      types = types.Elem()
   }
   for i := 0; i < types.NumField(); i++ {
      tf := types.Field(i)
      if tag, ok := tf.Tag.Lookup("json"); ok {
         fmt.Printf("字段名称:%v，他的额外约束条件:%v\n", tf.Name, tag)
      }
   }
   for i := 0; i < types.NumField(); i++ {
      if tf, ok := types.FieldByName("Name"); ok {
         tag := tf.Tag.Get("json")
         fmt.Printf("字段名称:%v，他的额外约束条件:%v\n", tf.Name, tag)
      }
   }
} 
```



```go

字段名称:Name，他的额外约束条件:name
字段名称:Age，他的额外约束条件:age
字段名称:Name，他的额外约束条件:name
字段名称:Name，他的额外约束条件:name
```



#### 执行函数

```go
// 给student添加两个方法 Study和Sleep(注意首字母大写)
func (s student) Study() string {
	msg := "好好学习，天天向上。"
	fmt.Println(msg)
	return msg
}

func (s student) Sleep() string {
	msg := "好好睡觉，快快长大。"
	fmt.Println(msg)
	return msg
}

func printMethod(x interface{}) {
	t := reflect.TypeOf(x)
	v := reflect.ValueOf(x)

	fmt.Println(t.NumMethod())
	for i := 0; i < v.NumMethod(); i++ {
		methodType := v.Method(i).Type()
		fmt.Printf("method name:%s\n", t.Method(i).Name)
		fmt.Printf("method:%s\n", methodType)
		// 通过反射调用方法传递的参数必须是 []reflect.Value 类型
		var args = []reflect.Value{}
		v.Method(i).Call(args)
	}
}
```

#### reflect.valueof

```go

package main

import (
  "fmt"
  "reflect"
)

func main() {
  var a int = 56
  value := reflect.ValueOf(a)
  fmt.Println(value.Interface())
  fmt.Println(value.Interface().(int))
}
```



```go

- 第9行：定义变量a并赋值为56
- 第10行：通过reflect.ValueOf函数获取值对象
- 第11行：获取值对象的原型值
- 第12行：通过断言获取原型值
```



#### 结构体值的非导出字段不能通过反射来修改

```go

package main

import (
  "fmt"
  "reflect"
)

type Turbo struct {
   Name interface{}
   age  interface{}
}
func main() {
   vs := reflect.ValueOf(&Turbo{})
   vs = reflect.Indirect(vs)
   vx, vy := vs.Field(0), vs.Field(1)
   fmt.Println(vx.CanSet(), vx.CanAddr())
   fmt.Println(vy.CanSet(), vy.CanAddr())
   vb := reflect.ValueOf(123)
   vx.Set(vb)
   vy.Set(vb)  // 会造成恐慌，因为vy代表的值是不可修改的。
   fmt.Println(vx.IsNil(), vy.IsNil())
 }
```



```go

true true
false true
panic: reflect: reflect.Value.Set using value obtained using unexported field
false true
```



```

- 第8行：定义一个结构体类型Turbo
- 第14行：如果vs代表着一个指针，下一行等价于"vs := vs.Elem()"
- 第15行：分别取出结构体对象中的字段属性值
- 第17行：vy为是地址类型但不可被修改
- 第19行：判断vx,vy是否为空值
- 第20行：vx代表的值是可修改的，可暴露的字段
- 第21行：vy代表的值是不可修改的，会Panic异常
```

### interface 接口

博文：https://www.yuque.com/aceld/golang/uh0124

七米哔站：https://www.bilibili.com/video/BV1Gt411F7uE/?spm_id_from=333.788&vd_source=58acbf449edd771737ee43a78ffdabf4

七米博文：https://www.liwenzhou.com/posts/Go/12_interface/

接口中没有定义任何需要实现的方法时，该接口就是一个空接口

任意类型都实现了空接口，空接口变量可以存储任意值

![image-20221006012339561](/Users/gongwei/Library/Application Support/typora-user-images/image-20221006012339561.png)

![image-20221006012408191](/Users/gongwei/Library/Application Support/typora-user-images/image-20221006012408191.png)

### GC

#### GC历程

博文：https://www.yuque.com/aceld/golang/zhzanb

哔站：https://www.bilibili.com/video/BV1wz4y1y7Kd?p=14&vd_source=58acbf449edd771737ee43a78ffdabf4

1. Go 1.0版本：mark and sweep操作都需要STW，比较浪费时间

   ![53-STW1.png](https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787936233-9002040d-220b-4af6-8e51-75d7887569b4.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_69%2Ctext_5YiY5Li55YawQWNlbGQ%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

2. Go 1.3版本：将STW的步骤提前，减少STW暂停的时间，停顿在几百ms

   ![54-STW2.png](https://cdn.nlark.com/yuque/0/2022/png/26269664/1650788071197-26a29703-0fb5-43f4-afc5-87a35fc78a4b.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_69%2Ctext_5YiY5Li55YawQWNlbGQ%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

3. Go 1.5版本：引入三色标记法、堆空间启动插入写屏障，全部扫描之后，还需要重新扫描一次栈空间（STW），停顿时间在100ms以内

   单纯的三色标记法，如果不启动stw，则会出现对象误删的情况（对象3）

   过程：

   **第一步** , 每次新创建的对象，默认的颜色都是标记为“白色”，如图所示。

   **第二步**, 每次GC回收开始, 会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合如图所示。

   **第三步**, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合，如图所示。

   **第四步**, 重复**第三步**, 直到灰色中无任何对象，如图所示。

   **第五步**: 回收所有的白色标记表的对象. 也就是回收垃圾，如图所示。

   

   下列两种情况如果同时出现，则会出现误删的情况

   - 白色对象被挂在黑色对象下（条件1）
   - 灰色对象丢失了白色对象（条件2）

   ![56-三色标记问题2.jpeg](https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036029588-29e317e6-8f92-41ca-a28e-65153913d227.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_55%2Ctext_5YiY5Li55YawQWNlbGQ%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_750%2Climit_0)

   因此我们还是需要stw来保护全部过程，这时候我们考虑使用破坏条件1和条件2，我们用强三色不变式破坏条件1，用弱三色不变式破坏条件2

   

   `栈`和`堆`. 栈空间的特点是容量小,但是要求响应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在**栈空间的对象操作中不使用**. 而仅仅使用在堆空间对象的操作中.

   

   插入屏障：满足强三色不变式

   删除屏障：满足弱三色不变式

   强三色不变式：不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色

   弱三色不变式：黑色对象可以引用白色对象，但是这个白色对象到灰色对象的路径不会断

   ![60-三色标记问题6.jpeg](https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036383192-cb6b9fe9-4946-47da-bb9a-643f0c38a654.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_55%2Ctext_5YiY5Li55YawQWNlbGQ%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_750%2Climit_0)

   ![61-三色标记问题7.jpeg](https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036404003-e0ea569e-7a8a-4d9f-a08f-4bb9ed5c64ed.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_55%2Ctext_5YiY5Li55YawQWNlbGQ%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_750%2Climit_0)

   4. 插入写屏障和删除写屏障的短板：

      

      -  插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活； 
      -  删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。 

      

      Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。

      

   5. Go 1.8版本：三色标记法，混合写屏障机制，栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高

      1、GC开始将栈上的可达对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW);
      2、GC期间，任何在栈上创建的新对象，均为黑色;
      3、堆上被删除的对象标记为灰色;
      4、堆上被添加的对象标记为灰色;

### GM和GMP![img](https://img-blog.csdnimg.cn/img_convert/95510bbe09bcc08c4e162ef929152f6c.png)

#### P的作用

调度存在的问题：
1.全局队列的锁竞争，当 M 从全局队列中添加或者获取 G 的时候，都需要获取队列锁，导致激烈的锁竞争
2.M 转移 G 增加额外开销，当 M1 在执行 G1 的时候， M1 创建了 G2，为了继续执行 G1，需要把 G2 保存到全局队列中，无法保证G2是被M1处理。因为 M1 原本就保存了 G2 的信息，所以 G2 最好是在 M1 上执行，这样的话也不需要转移G到全局队列和线程上下文切换
3.线程使用效率不能最大化，没有work-stealing 和hand-off 机制

### 什么时候协程放在全局队列, 什么时候放在本地队列

新建一个协程G会优先放到本队队列P中，如果本地队列P满了，则会把本地队列的一半转移到全局队列中，本地队列为空的时候，就会从全局队列中去取。如果全局队列为空的话就会重其他本地队列拿一半协程G放到自己本地队列P中。如果中途协程阻塞了,本队队列P会在其他的内核线程上运行。

### GMP阻塞

#### 用户态阻塞/唤醒

当goroutine因为channel操作或者network I/O而阻塞时（实际上golang已经用netpoller实现了goroutine网络I/O阻塞不会导致M被阻塞，仅阻塞G，这里仅仅是举个栗子），对应的G会被放置到某个wait队列(如channel的waitq)，该G的状态由`_Gruning`变为`_Gwaitting`，而M会跳过该G尝试获取并执行下一个G，如果此时没有runnable的G供M运行，那么M将解绑P，并进入sleep状态；当阻塞的G被另一端的G2唤醒时（比如channel的可读/写通知），G被标记为runnable，尝试加入G2所在P的runnext，然后再是P的Local队列和Global队列。

#### 系统调用阻塞

**hand off机制**

  当本线程M0因为G0进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。进而某个空闲的M1获取P，继续执行P队列中剩下的G。而M0由于陷入系统调用而进被阻塞，M1接替M0的工作，只要P不空闲，就可以保证充分利用CPU。M1的来源有可能是M的缓存池，也可能是新建的。当G0系统调用结束后，根据M0是否能获取到P，将会将G0做不同的处理：

如果有空闲的P，则获取一个P，继续执行G0。

如果没有空闲的P，则将G0放入全局队列，等待被其他的P调度。然后M0将进入缓存池睡眠。



### Go传参到底是值传递还是引用传递

Go中所有的参数传递都是**值传递**，拷贝的都是一个副本。但是，这里分两种情况讨论，**引用类型** 和 **非引用类型**。

- 非引用类型（值类型）：int，string，float，bool，数组和struct；
  - 特点：值类型变量声明后，变量存的是值，内存通常在栈上分配，栈在函数调用后会被释放。

- 引用类型：指针，slice，map，channel，接口，函数等。
  - 特点：变量存放的是一个内存地址值，这个地址值指向的空间存的才是最终的值。内存通常在堆中分配，当没有任务变量引用这个地址时，该地址对应的数据空间就成为一个垃圾，通过GC回收。

![image-20221006212121814](/Users/gongwei/Library/Application Support/typora-user-images/image-20221006212121814.png)



slice、map，chan初始化时返回一个有初始值(非零)的T类型。可以通过某个变量类型本身的指针（如map，chan）或者该变量类型内部的元素的指针（如slice的第一个元素的指针）修改该变量类型的值。
**因此slice也跟chan与map一样，属于值传递，传递的是第一个元素的指针的副本。**

**总结**：Go语言中只存在**值传递**（*要么是该值的副本，要么是指针的副本*），不存在引用传递。之所以对于引用类型的传递可以修改原内容数据，是因为在底层默认使用该引用类型的指针进行传递，但是也是使用指针的副本，依旧是值传递。

### context作用

树形结构

- [1.值传递](https://blog.csdn.net/qq_49723651/article/details/122674790#1_5)
- [2.超时控制](https://blog.csdn.net/qq_49723651/article/details/122674790#2_45)
- [3.取消控制](https://blog.csdn.net/qq_49723651/article/details/122674790#3_135)

https://blog.csdn.net/qq_49723651/article/details/122674790

### 读写一个已经关闭的channel会发生什么

- 如果在关闭前，通道内部有元素，会正确读到元素的值；
- 如果关闭前通道无元素，则会读取到通道内元素类型对应的零值。

## 计算机网络

### DNS什么协议

通俗地讲，就是DNS服务器之间传输时使用TCP，而客户端与DNS服务器之间传输时用的是UDP

### 1.TCP和UDP之间的区别

TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的通信协议，数据在传输前要建立连接，传输完毕后还要断开连接。

UDP是一种无连接的，不可靠的、基于报文的传输协议



1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接

2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付

3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的

UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）

4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信

5、TCP首部开销20字节;UDP的首部开销小，只有8个字节

### 2.TCP三次握手和四次挥手

#### TCP三次握手

![img](https://img-blog.csdn.net/20180717202520531?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTUwMzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

一开始，双方都处于close状态，先是接收端监听某个端口，进入listen状态

第一次握手：发送syn包时，希望向接收端建立连接，并初始化序列号。此时发送端进入syn_sent状态
第二次握手：接收端接受到了syn包，发送ack+syn包，并初始化序列号，并将发送的序列号+1放入确认应答号中。此时接收端进入syn_rcvd状态
第三次握手：发送ack包，给确认应答号+1，表示收到了接收端的报文，进入establelisten状态
服务端收到了客户端的报文后，也进入了establelisten状态、

#### 为什么不能是两次握手？

不能，因为有可能在TCP客户端发送的请求连接报文段没有被服务端接收，滞留在网络中。然后超时重传一个客户端TCP请求连接报文段，该报文段被正确接收了，此时服务器已经进入了连接状态，并给客户端发送一个确认报文段，客户端接收到后就进入了已连接状态，并开始传输数据，直到释放连接之后，之前停留在网络中的客户端发送的TCP请求连接报文段被服务器正确接收到了，进入连接状态，等待客户端传输数据，但是此时客户端已经关闭了，但是服务端并不知道，一直在等待，这就造成了大量资源的浪费。

#### TCP四次挥手

![img](https://img-blog.csdn.net/20180717204202563?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTUwMzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

1）客户端进程发出连接释放报文，并且停止发送数据。
2）服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。
4）服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，
5）客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，进入TIME_WAIT状态。

#### 为什么连接的时候是三次握手，关闭的时候却是四次握手？

答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的（请求建立连接）。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

#### 2MSL等待是否有必要？

它是任何报文在网络上存在的最长的最长时间，超过这个时间报文将被丢弃。

假如客户端最后发送的对服务器的确认报文段在网络中丢失了，服务器并没有收到来自客户端的确认报文段，因此也就不能进入close状态。所以为了真正断开连接，进入close状态，服务端会继续向和客户端发送释放连接报文段，但此时如果客户端已经关闭了，不在接收报文段，这就会导致服务器一直处于最后确认状态而不能关闭。而客服端发送ACK到服务端和服务端发送FIN断开连接请求报文刚好是2MSL，所以客服端需要等待2MSL才能关闭

![img](https://img-blog.csdnimg.cn/20211001093820291.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQOi3r-WPow==,size_20,color_FFFFFF,t_70,g_se,x_16)



### 3.流量控制和拥塞控制

**拥塞窗口和收到的窗口取较小值作为实际发送的窗口**

[链接](https://blog.csdn.net/weixin_47750287/article/details/123789861)

如果不进行流量控制，看视频就容易丢帧；如果不进行拥塞控制，看视频就容易卡顿

#### 流量控制

防止发送方发的太快，接收方来不及处理，那么就会有分组丢失，为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。

##### 做法

主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。、



（5）接收端一旦发现自己的缓冲区快满了，就会将窗口大小设置成一个更小的值通知给发送端，发送端收到这个值后，就会减慢自己的发送速度
（6）如果接收端发现自己的缓冲区满了，就会将窗口的大小设置为0，此时发送端将不再发送数据，但是需要定期发送一个窗口探测数据段，使接收端把窗口大小告诉发送端
ps：在TCP的首部中，有一个16为窗口字段，此字段就是用来存放窗口大小信息的



#### 拥塞控制

防止发送方发的太快，使得网络来不及处理，避免出现网络负载过大，从而导致网络拥塞

##### 做法：

慢启动、拥塞避免、快重传和快恢复

![快重传和快恢复](https://img-blog.csdnimg.cn/img_convert/49df0293def6c72d61deb4ee64e1dd62.png)

1）慢启动（慢开始）

在开始发送的时候设置cwnd = 1（cwnd指的是拥塞窗口）

思路：开始的时候不要发送大量数据，而是先测试一下网络的拥塞程度，由小到大增加拥塞窗口的大小。

为了防止cwnd增长过大引起网络拥塞，设置一个**慢开始门限**(ssthresh 状态变量)

此时拥塞窗口增长方式为指数增长（随着传输轮次的增加），直到达到慢开始

当cnwd < ssthresh，使用慢开始算法
当cnwd = ssthresh，既可使用慢开始算法，也可以使用拥塞避免算法
当cnwd > ssthresh，使用拥塞避免算法

2）拥塞避免

拥塞避免未必能够完全避免拥塞，是说在拥塞避免阶段将拥塞窗口控制为按线性增长，使网络不容易出现阻塞。
思路： 让拥塞窗口cwnd缓慢的增大，即每经过一个返回时间RTT就把发送方的拥塞控制窗口加一

3）快速重传

快重传要求接收方在收到一个失序的报文段后就立即发出重复确认(为的是使发送方及早知道有报文段没有到达对方)。**发送方只要连续收到三个重复确认就立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。**
由于不需要等待设置的重传计时器到期，能尽早重传未被确认的报文段，能提高整个网络的吞吐量。**（2）快速恢复**

4）快恢复

当发送方连续收到**三个重复确认**时，就执行“乘法减小”算法，**把ssthresh门限减半**。接下来执行拥塞避免算法

### 4.TCP如何保证可靠性的

TCP主要通过校验和、确认应答序列号、超时重传、连接管理、流量控制、拥塞控制这6个方面来保证数据的可靠传输的。

1、检验和：数据收发方在进行数据传输时，都会先计算校验和，如果不一致，就说明数据传输有误。

2、确认应答，序列号：TCP在进行数据传输时都是进行编号的，每次接收方返回ACK时都有确认序列号。

3、超时重传：如果发送方发送数据一段时间后没有收到ACK，那么就重新发送数据。

4、连接管理：TCP通过三次握手建立连接，四次挥手断开连接。

5、流量控制：根据接收端的能力进行数据发送
TCP协议报头包含16位的窗口大小，接收方会在返回数据时，将自己的即时窗口大小填入，发送方就会根据报文中窗口的大小控制发送速度。

6、拥塞控制：会像探路一样，先发送小数据，防止拥塞
刚开始发送数据的时候，拥塞窗口是1，以后每次收到ACK，则拥塞窗口+1，**然后将拥塞窗口和收到的窗口取较小值作为实际发送的窗口**，如果发生超时重传，拥塞窗口重置为1。这样做的目的就是为了保证传输过程的高效性和可靠性。

## HTTP

### HTTP content-type格式

- application/json： JSON数据格式
- application/octet-stream ： 二进制流数据（如常见的文件下载）
- application/x-www-form-urlencoded ： <form encType=””>中默认的encType，form表单数据被编码为key/value格式发送到服务器（表单默认的提交数据的格式）

另外一种常见的媒体格式是上传文件之时使用的：

- multipart/form-data ： 需要在表单中进行文件上传时，就需要使用该格式



### UDP如何实现可靠传输

- 传输层无法保证数据的可靠传输，**只能通过应用层来实现了**。实现的方式可以参照 tcp 可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。
- 

### 1.在浏览器输入 URL 回车之后发生了什么

1. URL 解析
2. DNS 查询
3. TCP 连接
4. 处理请求
5. 接受响应
6. 渲染页面

先解析url地址是否合法

DNS解析：

**（1）查看浏览器缓存**

当用户通过浏览器访问某域名时，浏览器首先会在自己的缓存中查找是否有该域名对应的 IP 地址（若曾经访问过该域名且没有清空缓存便存在）。

**（2）查看系统缓存**

当浏览器缓存中无域名对应 IP 则会自动检查用户计算机系统 Hosts 文件 DNS 缓存是否有该域名对应 IP。

**（3）查看路由器缓存**

当浏览器及系统缓存中均无域名对应 IP 则进入路由器缓存中检查，以上三步均为客服端的 DNS 缓存。

**（4）** 迭代查询根域名服务器、顶级域名服务器、权限域名服务器

### 2.HTTP1.0和2.0区别

http1.0：（无连接,无状态,一次请求一个tcp连接）每次请求都需要重新建立tcp连接，请求完后立即断开与服务器连接，这很大程度造成了性能上的缺陷，http1.0被抱怨最多的就是连接无法复用。

http1.1：引入了长连接（keep-alive），相较于1.0减少了连接和关闭的延迟，提高了效率，但是若干个请求还是需要串行排队处理，如果一旦某个请求超时，后面的就会被阻塞，也就是常说的线头阻塞。

http2主要特点是

1.新的二进制格式传输：二进制即0和1的组合，实现方便健壮，而1.x版本是基于文本，解析存在缺陷

2.多路复用：一个连接可以有多个请求，且可以混杂在一起根据requestid来区分不同的请求，提高了连接的利用率，降低了延迟

3.header头部压缩：通讯两方各自缓存了一份 header请求头表，避免了重复的header传输，且缩小了包的体积大

4.服务端推送功能：可以服务端主动向客户端push消息

https://www.bilibili.com/video/BV1qF411G743/?spm_id_from=pageDriver&vd_source=58acbf449edd771737ee43a78ffdabf4

#### 长链接和短链接

http长链接其实指的是tcp长链接，通过一次tcp连接，发起多次http请求，就是长链接，可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间

#### 如何设置长链接

请求头里面设置connection设置keep-alive，http1.1默认长链接

可以在请求头里面设置长链接超时时间





### 3.HTTP和HTTPS有什么区别

https://www.bilibili.com/video/BV1qF411G743/?spm_id_from=pageDriver&vd_source=58acbf449edd771737ee43a78ffdabf4

http1.0时无连接，无状态的（`无状态`：无状态可以减轻服务器负担，但进行关联操作时繁琐，Cookie正好可以解决这个问题），http1.1通过在请求首部字段中的Connection: keep-alive即为表明使用了持久连接

1. 端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443
2. http是明文传输，https是基于ssl的加密传输
3. http不需要证书认证，https需要证书认证

### 4.HTTPS采用什么加密方式

##### 证书验证过程：

非对称加密

​	加密和解密使用不同的密钥，即公钥和私钥，公钥加密，私钥解密

RSA



##### 数据内容传输：

对称加密：

​	加密和解密使用同一密钥，优点是运算速度快

DES, AES

#### 为什么数据传输是用对称加密的？

首先：非对称加密的加解密效率是非常低的，而 http 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的。

#### 为什么对称加密算法比非对称加密算法快


这是因为对称加密主要的运算是**位运算**，速度非常快，如果使用硬件计算，速度会更快。以 AES 算法为例，如下图所示，其运算本质上来说就是位移和替换。

但是非对称加密计算一般都比较复杂，比如 RSA，它里面涉及到大数乘法、大数模等等运算。其加解密可以用下面的公式来表示：

我们知道，幂运算的本质是乘法，乘法的基础单位是加法，也就是我们最常见的整数加。学过数字逻辑电路的同学想必都知道，在电路上实现“加法”比异或（XOR）要麻烦的多，况且后面还有一个模运算。因此非对称加密的速度自然而然是比不过对称加密的。

#### HTTPS加密流程

https://www.bilibili.com/video/BV1M44y1175D/?spm_id_from=333.788.recommend_more_video.-1&vd_source=58acbf449edd771737ee43a78ffdabf4

```
   1.客户端请求服务端，获取公钥。
   
   2.服务端生成公私钥，自己保存私钥（SK），将公钥（PK）发给客户端。
   	返回数字证书，里面含有公钥
   	然后进行证书验证，验证通过后，取出公钥

   3.客户端生成随机字符串key，通过公钥(PK)加密后发送给服务端。

   4.服务端拿到加密后的内容后，用自己的私钥(SK)进行解密，得到key,后续的过程都是通过密钥(key)来进行对称加密来传输。

   从以上的步骤可以看出，传输对称加密的密钥使用的是非对称加密，而传输实际内容使用的是对称加密
```



#### 数字签名和数字证书

![https 证书是如何验证的_客户端](https://s2.51cto.com/images/blog/202205/28012508_629109746dc8e11455.jpg?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

CA 签发证书的过程，如上图左边部分：

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

客户端校验服务端的数字证书的过程，如上图右边部分：

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

https 证书是如何验证的
https://blog.51cto.com/u_15351164/5358082



![image-20220918233853130](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918233853130.png)





![image-20220918232947434](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918232947434.png)

#### 公钥和私钥都可用于加密和解密

公钥和私钥都可以用于加解密操作，用公钥加密的数据只能由对应的私钥解密，反之亦然。虽说两者都可用于加密，但是不同场景使用不同的密钥来加密，规则如下：

##### 1、私钥用于签名、公钥用于验签

签名和加密作用不同，签名并不是为了保密，而是为了保证这个签名是由特定的某个人签名的，而不是被其它人伪造的签名，所以私钥的私有性就适合用在签名用途上。

私钥签名后，只能由对应的公钥解密，公钥又是公开的（很多人可持有），所以这些人拿着公钥来解密，解密成功后就能判断出是持有私钥的人做的签名，验证了身份合法性。

##### 2、公钥用于加密、私钥用于解密，这才能起到加密作用

因为公钥是公开的，很多人可以持有公钥。若用私钥加密，那所有持有公钥的人都可以进行解密，这是不安全的！

若用公钥加密，那只能由私钥解密，而私钥是私有不公开的，只能由特定的私钥持有人解密，保证的数据的安全性。

————————————————
版权声明：本文为CSDN博主「hllyzms」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_37989267/article/details/126641628

RSA算法可以总结为四句话：**公钥加密、私钥解密、私钥签名、公钥验签**。加密是防止信息泄露，而签名是为了防止信息被篡改。





### 5.get和post的区别

1. GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
2. GET请求在URL中传送的参数是有长度限制的（2k），而POST没有。还是需要看浏览器怎么支持
3. **数据（参数）会显示在地址栏**，而Post不会，所以，Post比Get更加安全。但是如果被抓包了，也就没有安全性之说了
4. **Post请求的参数存放到了请求实体中**，而Get没有请求实体，Get是存储在请求头中。
5. **GET**产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
   **POST**产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。
6. get请求是幂等的，post不是幂等

### 6.常见的HTTP的状态码

#### 2xx : 代表服务端已经成功接收并处理了该请求

200:服务端成功接收了该请求并进行了处理,请求所需要的数据应该伴随这次请求对应的响应返回给客户端
202:服务端已经成功接收了请求,但是并未进行处理

#### 3xx : 通常代表客户端需要进行进一步请求用,常用来进行重定向的状态码

301: 客户端请求的资源已经永久移动到别的位置,服务端会自动将该请求重定向到新的位置

#### 4xx : 通常表示客户端请求有问题

401 : 需要用户进行登录，权限不够
403 : 服务端收到请求,但是拒绝进行处理
404 : 访问的资源不存在

#### 5xx : 通常表示服务端内部错误

500 : 服务端代码出错
502 : 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应
503:  服务器正在维护或者访问过载,过一段时间可能恢复正常
504 : 作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应 

### 7.Cookie和Session的区别

#### cookie原理

cookie的执行原理：就是当客户端访问服务器的时候（服务器运用了cookie），服务器会生成一份cookie传输给客户端，客户端会自动把cookie保存起来，以后客户端每次访问服务器，都会自动的携带着这份cookie。

简单来说，就是当客户端访问服务器时，服务器会生成一个票据给客户端，当客户端收到票据的之后就保存起来，以后再访问服务器就会自动带着票据。
![img](https://img-blog.csdnimg.cn/1f96b5e6172c4296a864c19d66916573.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6YKj5YWUMQ==,size_20,color_FFFFFF,t_70,g_se,x_16)

#### session原理

当客户端第一次请求服务器的时候，服务器生成一份session保存在服务端，将该数据(session)的id以cookie的形式传递给客户端；以后的每次请求，浏览器都会自动的携带cookie来访问服务器(session数据id)。

![img](https://img-blog.csdnimg.cn/e0ba6d258d26461d952d546fe35161e5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6YKj5YWUMQ==,size_20,color_FFFFFF,t_70,g_se,x_16)

- cookies数据保存在客户端，session数据保存在服务器端；
- cookies可以减轻服务器压力，但是不安全，容易进行cookies欺骗；
- session较安全，但占用服务器资源，**服务器性能**：session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie。
- **数据大小**：单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。



### 8.跨域问题

#### 同源策略（可以让网页从别的域名（网站）那获取资料，即跨域读取数据。）

浏览器限定只有协议、域名、端口号相同的网站才能相互访问。目的是为了防止XSS、CSRF攻击

**跨域并不是请求发不出去，请求能发出去，服务端能收到请求并正常返回结果，只是结果被浏览器拦截了**

#### CORS（Cross-Origin Resource Sharing）的全称叫 **跨域资源共享**

浏览器不是有同源策略呐，这东西好是好，但是对于开发人员来说就不怎么友好了，因为我们可能经常需要发起一个 **跨域 HTTP 请求**。我们之前说过，跨域的请求其实是发出去了的，只不过被浏览器给拦截了，因为不安全，说直白点儿就是，**你想要从服务器哪儿拿个东西，但是没有经过人家允许啊**。所以怎么样才安全 ？服务器允许了不就安全了，这就是 CORS 实现的原理：**使用额外的 HTTP 头来告诉浏览器，让运行在某一个 origin 上的 Web 应用允许访问来自不同源服务器上的指定的资源**。

服务器接受到请求后，会返回一个响应，响应头中会包含一个叫 **Access-Control-Allow-Origin** 的字段，它的值**要么包含由 Origin 首部字段所指明的域名，要么是一个 "\*"**，表示接受任意域名的请求。如果响应头中没有这个字段，就说明当前源不在服务器的许可范围内，浏览器就会报错:

#### JSONP

主要就是利用了 script 标签的src没有跨域限制来完成的。

### 9.XSS和CSRF攻击

XSS攻击（跨站脚本攻击）

CSRF，英文全称Cross-site request forgery，跨站请求伪造

## Linux

### 1.lsof -i:端口号

获取端口号对应的进程信息（进程号）

然后使用kill -9杀死进程

### 2.nohup

**nohup** 英文全称 no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行，但是按Crtl+C会终止程序运行。

&，按Crtl+C不会终止程序运行，退出终端会中断程序运行

#### 示例

我们用python代码loop_hello.py做示例，代码的作用是循环输出循环次数和hello world!，每次输出后sleep 1秒

示例代码如下：

```python
import time

def main():
    i = 0 
    while True:
        i += 1
        print('%d:  hello world!' %(i))
        time.sleep(1)

if '__main__' == __name__:
    main()
```

运行loop_hello.py，输出结果如下：

![img](https://pic2.zhimg.com/80/v2-ea6521c7254d1c761711c920cf0b4c15_1440w.jpg)

程序每隔一秒会在终端输出一个字符串，此时如果键入Ctrl+C ，程序会收到一个SIGINT信号，如果不做特殊处理，程序的默认行为是终止（如上图）。

#### nohup

1、使用nohup python loop_hello.py，效果如下：

![img](https://pic1.zhimg.com/80/v2-56e5604c5a481f70d93028a1017d8808_1440w.jpg)

1）前台没有出现进程号

2）有一个“忽略输入并把输出追加到"nohup.out"”的提示

3）hello的输出也没有出现在前台

2、如果关掉session，程序会不会关闭呢？

1）**使用ps aux | grep loop_hello查看进程号**

2）关掉session，程序会收到一个SIGHUP信号

3）再次使用ps aux | grep loop_hello，发现进程仍然存在

4）kill掉进程

3、测试一下Ctrl +C

使用nohup启动loop_hello.py，如果键入Ctrl+C ，程序收到SIGINT信号后，直接关闭了

#### &

使用 python loop_hello.py &，效果如下所示：

![img](https://pic4.zhimg.com/80/v2-ecfd64fa7a2cf2875cbe120f2be8b78b_1440w.jpg)

- 首先会在终端显示进程号是2367
- 键入Ctrl + C，发出SIGINT信号，程序会继续运行
- 关掉session，程序会收到一个SIGHUP信号，通过ps aux | grep loop_hello.py可以看到，进程2367也关闭了

#### &和nohup同时使用

1、使用nohup python loop_hello.py &运行程序，效果如下：

![img](https://pic2.zhimg.com/80/v2-acd21dd65165f9ec1bae1ffca23f4689_1440w.jpg)

2、键入Ctrl + C，发送SIGINT信号 使用ps aux查看，进程仍然存在

3、关闭session，发送SIGHUP信号 使用ps aux查看，进程依然存在

4、如果想要终止进程的话，只能使用kill了

如果要停止运行，你需要使用以下命令查找到 nohup 运行脚本到 PID，然后使用 kill 命令来删除：

```
ps -aux | grep "runoob.sh" 
```



#### 总结

1、使用&后台运行程序：

1）结果会输出到终端

2）使用Ctrl + C发送SIGINT信号，程序免疫（**放在前台执行）**

3）关闭session发送SIGHUP信号，程序关闭

2、使用nohup运行程序：

1）结果默认会输出到nohup.out

2）使用Ctrl + C发送SIGINT信号，程序关闭

3）关闭session发送SIGHUP信号，程序免疫**（放在后台执行）**

3、平日线上经常使用nohup和&配合来启动程序：

同时免疫SIGINT和SIGHUP信号



#### nohup java -jar app.jar >log 2>&1 &

将标准错误输出重定向到标准输出，然后输入到log文件中



### tail -f

实时查看文件

#### 满足任意一个条件：

```
tail -f catalina.out | grep --line-buffer -E "发送邮件|接收到"
```

#### 同时满足多个条件：

```
tail -f catalina.out | grep --line-buffer "发送邮件"  | grep --line-buffer "异常报警"
```

## 操作系统

### 协程切换的时候保存什么

当前的函数栈状态、和寄存器值

### avl树和红黑树的主要区别

AVL 树比红黑树更加平衡，但AVL树在插入和删除的时候也会存在大量的旋转操作。所以当你的应用涉及到频繁的插入和删除操作，切记放弃AVL树，选择性能更好的红黑树；当然，如果你的应用中涉及的插入和删除操作并不频繁，而是查找操作相对更频繁，那么就优先选择 AVL 树进行实现



### IO多路复用

一个线程能处理多个TCP链接



### 同一进程下线程共享什么资源

共享的有堆，全局变量，静态变量等

### 1.进程间通信方式

管道、消息队列、共享内存、信号量、信号、Socket 

匿名管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。

套接字（socket）：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。

#### 线程间的通信方式

共享变量

[链接](https://blog.csdn.net/GMLGDJ/article/details/124627224)

### 2.线程和进程间的区别

   (1)  调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位

（2）系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。

## 项目

### 1.项目中遇到的坑

1. goroutine需要defer，recover进行每个协程的异常捕获

### 2.项目中有没有出现死锁，怎么解决的

[死锁](https://blog.csdn.net/m0_56501550/article/details/125110905)

#### 1.事务

事务（Transaction）指一个操作，由多个步骤组成，要么全部成功，要么全部失败。

比如我们常用的转账功能，假设A账户向B账号转账，那么涉及两个操作：
（1）从A账户扣钱；
（2）往B账户加入等量的钱。

因为是独立的两个操作，所以可能有一个成功，一个失败的情况。但是因为在这种场景下，必须要保证事务，即要么同时成功，要么同时失败（一个失败需要回滚），不能存在从A账户扣钱成功，往B账户加入等量钱失败这种情况。



对于单条SQL语句，数据库系统自动将其作为一个事务执行，这种事务被称为隐式事务。

要手动把多条SQL语句作为一个事务执行，使用BEGIN开启一个事务，使用COMMIT提交一个事务，这种事务被称为显式事务，例如，把上述的转账操作作为一个显式事务：

```
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
COMMIT;
```

很显然多条SQL语句要想作为一个事务执行，就必须使用显式事务。

COMMIT是指提交事务，即试图把事务内的所有SQL所做的修改永久保存。如果COMMIT语句执行失败了，整个事务也会失败。

有些时候，我们希望主动让事务失败，这时，可以用ROLLBACK回滚事务，整个事务会失败：

```
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
ROLLBACK;
```

数据库事务是由数据库系统保证的，我们只需要根据业务逻辑使用它就可以。

##### 事务的四大特性

- 原子性: 
  - 事务中所有操作是不可再分割的原子单位。事务中所有操作要么全部执行成功，要么全部执行失败。一个事务内的操作要么全部成功要么全部失败.

- 一致性: 
  - 事务执行后，数据库状态与其它业务规则保持一致。其他特性都是为了给一致性服务的. 例如买东西,张三买李四的东西, 买卖前和买卖后张三和李四的所有钱数之和是保持不变的.

- 隔离性: 
  - 当多个事务并发执行时，数据库管理系统应保证一个事务的执行结果不受其他事务的干扰，事务并发执行的结果与这些事务串行执行的结果一样，这一特性被称为事务的隔离性

- 持久性: 
  - 一旦事务提交成功，事务中所有的数据操作都必须被持久化到数据库中，即使提交事务后，数据库马上崩溃，在数据库重启时，也必须能保证通过某种机制将数据恢复到提交后的状态。 举例: 一般的数据操作只是在事务中记录需要进行这样的操作, 即使看到了表中的数据发生了改变, 实际上表中的数据也没有发生改变只是在事务中记录需要进行这样的操作, 真正提交了事务才去表中改变表中的数据.



#### 2.事务并发

​		数据库和操作系统一样，是一个**多用户使用的共享资源**。当多个用户并发地存取数据 时，在数据库中就会产生多个事务同时存取同一数据的情况。**若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性**。加锁是实现数据库并发控制的一个非常重要的技术。在实际应用中经常会遇到的与锁相关的异常情况，当多个事务并发执行时候，加锁有可能会产生阻塞或死锁。

死锁报错日志

```
Lock wait timeout exceeded; try restarting transaction
```

1、【治标方法】innodb_lock_wait_timeout 锁定等待时间改大
        修改超时时间将 #innodb_lock_wait_timeout = 50 修改为 innodb_lock_wait_timeout = 500。

        缺点：全局更改，影响也是全局的，等待时间加长，容易使等待事务增多导致堆积问题。
#### 3.排它锁（Exclusive Locks，即X锁）和共享锁（Share Locks，即S锁）

在数据库中有两种基本的锁类型：排它锁（Exclusive Locks，即X锁）和共享锁（Share Locks，即S锁）。

当数据对象被加上排它锁时，其他的事务不能对它读取和修改。加了共享锁的数据对象可以被其他事务读取，但不能修改。数据库利用这两种基本的锁类型来对数据库的事务进行并发控制。

```
select * from … for update // 锁的释放并不是该语句执行完就完，而是事物提交后，才释放锁
update …
insert …
delete …
均为写锁
select * from … for share mode
为读锁
```

#### 4.死锁案例

##### 死锁的第一种情况

​		一个用户A 访问表A(锁住了表A),然后又访问表B；另一个用户B 访问表B(锁住了表B)，然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了。

| **T1**       | **T2**        |
| ------------ | ------------- |
| **XLock　A** |               |
|              | **XLock　B**  |
| **XLock　B** |               |
| **等待**     |               |
| **等待**     | **XLock   A** |
| **等待**     | **等待**      |
| **等待**     | **等待**      |

##### 解决方法：

​		这种死锁比较常见，是由于程序的BUG产生的，除了调整的程序的逻辑没有其它的办法。仔细分析程序的逻辑，对于数据库的多表操作时，尽量按照相同的顺序进行处理，尽量避免同时锁定两个资源，如操作A和B两张表时，总是按先A后B的顺序处理， 必须同时锁定两个资源时，要保证在任何时刻都应该按照相同的顺序来锁定资源。

##### 死锁的第二种情况

​		用户A查询一条纪录，然后修改该条纪录；这时用户B也查询该条记录，并修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A 有共享锁存在所以必须等A释放掉共享锁，因此B也无法上升共享锁到独占锁。于是出现了死锁。

​		这种死锁比较隐蔽，但在稍大点的项目中经常发生。如在某项目中，页面上的按钮点击后，没有使按钮立刻失效，使得用户会多次快速点击同一按钮，这样同一段代码对数据库同一条记录进行多次操作，很容易就出现这种死锁的情况。

##### 解决办法

1. 对于按钮等控件，点击后使其立刻失效，不让用户重复点击，避免对同时对同一条记录操作。
2. 使用乐观锁进行控制
3. 使用悲观锁进行控制
   - 但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受，**此时如果事务很大**，因为会在事务提交后才会释放锁，所以并发度会很低

##### 死锁的第三种情况

​		如果在事务中执行了一条不满足条件的update语句，则执行全表扫描，把行级锁上升为表级锁，多个这样的事务执行后，就很容易产生死锁和阻塞。类似的情况还有当表中的数据量非常庞大而索引建的过少或不合适的时候，使得经常发生全表扫描，最终应用系统会越来越慢，最终发生阻塞或死锁。

##### 解决方法：

- SQL语句中不要使用太复杂的关联多表的查询；

- 使用“执行计划”对SQL语句进行分析，对于有全表扫描的SQL语句，建立相应的索引进行优化。

- 有时候列加了索引，还是会走全表扫描，因此需要在测试环境执行explain计划，看看是不是走索引。如果不是，则需要手动加force index强制指定索引。

  - update全表扫描时候，会锁全表，其他增删改操作都会阻塞

  - 如何解决

    - 我们可以将 MySQL 里的 `sql_safe_updates` 参数设置为 1，开启安全更新模式。

    - 大致的意思是，当 sql_safe_updates 设置为 1 时。

      update 语句必须满足如下条件之一才能执行成功：

      - 使用 where，并且 where 条件中必须有索引列；
      - 使用 limit；
      - 同时使用 where 和 limit，此时 where 条件中可以没有索引列；

      delete 语句必须满足如下条件之一才能执行成功：

      - 使用 where，并且 where 条件中必须有索引列；
      - 同时使用 where 和 limit，此时 where 条件中可以没有索引列；

      如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 `force index([index_name])` 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。

- 大事务拆小。大事务如果没有走索引，查了全表，锁了全表。那么其他操作将会被阻塞。如果业务允许，将大事务拆小。

- 为表添加合理的索引。如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。

#### 5.间隙锁[链接](https://zhuanlan.zhihu.com/p/450210913)

## Python

### 1.中间件

```python
# 中间件就是一个类，继承父类MiddlewareMixin，重写最多的5个方法
# 就是你可以重写一个或者多个方法
import re

from django.http import HttpResponse
from django.utils.deprecation import MiddlewareMixin


# 中间件就是一个类，继承父类MiddlewareMixin，重写最多的5个方法
# 就是你可以重写一个或者多个方法
class IpMiddleware(MiddlewareMixin):
    visit_times = {}

    def process_request(self, request):
        # 执行路由之前被调用，返回None就是通过，返回HttpResponse  就是拦截成功
        print("执行路由之前被调用")

        # 获取远程客户端的ip地址
        IPAddr = request.META['REMOTE_ADDR']
        # 获取请求的路由的地址
        pathinfo = request.path_info
        print(IPAddr)  # 127.0.0.1
        print(pathinfo)  # /test/

        # if not re.match('^/88888',pathinfo):
        #     #  如果没有匹配到
        #     return
        # # 拿到现在的访问次数
        # times = self.visit_times.get(IPAddr,0)
        #
        # self.visit_times[IPAddr] = times+1
        #
        # if times<5:
        #     return
        # return HttpResponse("您已经访问了"+str(times)+"次，访问被禁止")



    def process_view(self, request, view_func, view_func_args, view_func_kwargs):
        # 调用视图函数之前被调用，返回None就是通过，返回HttpResponse  就是拦截成功
        print("调用视图函数之前被调用")
        return None

    def process_response(self, request, response):
        # 所有的响应返回给浏览器之前被调用,返回HttpResponse
        # 一定会走这个逻辑，即使view里面代码错了，先走错的，再走这个

        # 执行路由之前被调用
        # 调用视图函数之前被调用
        # 我出错了
        # 返回给浏览器之前，调用我了
        print("返回给浏览器之前，调用我了")
        return response
    #
    # def process_template_response(self, request, response):
    #     # 很少用
    #     # 只有我们的视图里面返回了render渲染的，才会走这个
    #     print("我走了render函数了")
    #     return None


    def process_exception(self, request, exception):
        # 视图里面出错了，就会自动到这个里面执行，返回HttpResponse
        # 抓异常，发邮件
        print("我出错了")
        return None

```





## 股票

### 8月10日复盘

#### 买盘：

- 弘业期货：001236
  - 3.94
  - 4万、1.5万
- 东旭蓝天：000040
  - 4.80
  - 7万、2.5万
- 魅视科技：001229
  - 41.61
  - 5.4万
- 奥维通信：002231
  - 10.68
  - 3.2万
- 宇通客车：600066
  - 9.09
  - 2.3万
- 新坐标：603040
  - 24.08
  - 3万
- 浙江建投：002761
  - 27.30
  - 3.5万
  - 出现利好消息
- 苏州固AI：002079
  - 19.56
  - 8k、1.8w

#### 经验与教训：

1. 反弹股票，卖盘时候需要继续观察

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220810204924331.png" alt="image-20220810204924331" style="zoom:50%;" />

2. 走势较好的股票，低点才是买点

   <img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220810205135087.png" alt="image-20220810205135087" style="zoom:50%;" />

3. 盈利情况下，观察趋势不对，要及时止盈

   <img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220810205645572.png" alt="image-20220810205645572" style="zoom:50%;" />

   

4. 出现阴线后，有两种走势，如果两个阳线，则会继续上涨，如果出现阴线，及时止跌

   <img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20220810205757663.png" alt="image-20220810205757663" style="zoom:50%;" />

### 8月11日复盘

#### 买盘

- 日出东方：603366
  - 11.25
  - 3k
- 弘业期货
  - 4.33
  - 5万
- 东旭蓝天
  - 5.28
  - 2万

#### 经验与教训

- 要知道伟隆股份的痛
- 只要获利就考虑出局
  - 中通客车
  - 伟隆股份

家里面买房，全款，自己工作两年挣了30万

出去旅游，散散心

自己有能力能找到工作



## 面试

### map怎么保证并发安全

1. 写操作时候加锁
2. 使用sync.map

### HTTP请求头里面有什么

![img](https://img-blog.csdnimg.cn/946716699ae645afa431c970dba13313.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2g55qE5bCP5LyZ5Ly05ZWK,size_20,color_FFFFFF,t_70,g_se,x_16)

### Channel底层



### 协程，线程，进程区别

功能：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位

开销：每个进程都有独立的内存空间，存放代码和数据段等，程序之间的切换会有较大的开销；线程可以看做轻量级的进程，共享内存空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。

协程不是被操作系统内核所管理，而完全是由程序所控制(也就是在用户态执行)。

### HTTPS非对称加密算法

       1.客户端请求服务端，获取公钥。
       
       2.服务端生成公私钥，自己保存私钥（SK），将公钥（PK）发给客户端。
    
       3.客户端生成随机字符串key，通过公钥(PK)加密后发送给服务端。
    
       4.服务端拿到加密后的内容后，用自己的私钥(SK)进行解密，得到key,后续的过程都是通过密钥(key)来进行对称加密来传输。
    
       从以上的步骤可以看出，传输对称加密的密钥使用的是非对称加密，而传输实际内容使用的是对称加密


### 为什么有协程泄露(Goroutine Leak)？

协程泄漏是指协程创建之后没有得到释放。主要原因有：

1. 缺少接收器，导致发送阻塞
2. 缺少发送器，导致接收阻塞
3. 死锁。多个协程由于竞争资源导致死锁。
4. WaitGroup Add()和Done()不相等，前者更大。
4. 创建的协程没有回收

```
func solution(brackets string) bool {
  // 请在在这⾥书写你的代码
  if not brackets:
    return True
  if brackets[0] in ["}",")","]"]:
    return False
  
  res = []
  for i in brackets:
    if not res:
      res.append(i)
      continue
  
    temp = res[-1]
    if i == "}":
      if temp == "{":
        res.pop(-1)
      else:
        res.append(i)
    elif i == "]":
      if temp == "[":
        res.pop(-1)
      else:
        res.append(i)
    elif i == ")":
      if temp == "(":
        res.pop(-1)
      else:
        res.append(i)
    return len(res) == 0
}
```



1. go map怎么解决并发安全

   不知道，

2. 求栈的最小元素

   https://blog.csdn.net/Sunshine_love520/article/details/70214477

3. 知道玩家的id、分数，玩家数在不断增大，怎么获取前10的玩家

4. 用Redis实现玩家名字不重复，怎么优化

5. 布隆过滤器

6. http请求头里面有哪些

7. gin框架路由匹配规则（正则匹配）

8. TCP如何保证可靠传输

9. Linux怎么查可用磁盘大小

9. 金额怎么操作（代码和数据库）

10. 为什么要重构go

11. 加密算法有哪些

12. 用户信息储存在redis中有什么问题

    不用redis怎么处理

13. 判断用户ip是否可以访问（给定ip地址段）转化为int数字

14. 小堆有什么特性，函数（什么数据结构实现堆）

15. 单列索引和多列索引

    https://blog.csdn.net/varyall/article/details/82803127

16. redis 集合怎么实现key不过期，value过期

17. http转为https需要做什么，证书申请的流程

18. 502、404、403，怎么排查

19. 切片扩容源码

20. docker学习一下

21. 零拷贝、僵尸进程

22. 哪个接口出问题了，哪台服务器出问题了，反向代理，怎么排查定位问题，（先自己postman跑跑，是不是服务挂了）

展现出学习能力

我承担了什么工作，担任什么角色，而不是不想不答，遇到什么问题，怎么解决的，学到了什么

：=，=

23. for range

    https://blog.csdn.net/qq_23587709/article/details/123219195

    与 for 不同的是，`range` 对每个迭代值都创建了一个拷贝。因此如果每次迭代的值内存占用很小的情况下，for 和 range 的性能几乎没有差异，但是如果每个迭代值内存占用很大，这种情况下差距就非常明显了。我们可以用以下例子来证明range迭代时返回的是拷贝，而并非元素本身。

    ```
    persons := []struct{ no int }{{no: 1}, {no: 2}, {no: 3}}
    for _, s := range persons {
        s.no += 10
    }
    for i := 0; i < len(persons); i++ {
        persons[i].no += 100
    }
    fmt.Println(persons) 
    ```

    

    用key比value性能更好

    修改原有内存

    map用value

24. make预先评估长度

25. Gc怎么优化内存，合理复用

26. 业务上怎么解决这个问题

27. 为什么用go

    学了go可以看docker源码

    转go的学习成本更低

### 协程和线程的关系类型

#### N:1关系：N个协程绑定1个线程

优点：**协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速**。

缺点：无法利用多核加速能力；协程阻塞会造成其他协程都无法执行，没有并发能力。

#### 1:1关系：1个协程绑定1个线程

优点：协程的调度都由CPU完成，不存在N:1缺点，

缺点：协程的创建、删除和切换的代价都由CPU完成，切换协程代价过大

#### M:N关系：M个协程绑定1个线程

优点：能够利用多核

缺点：过于依赖协程调度器的优化和算法





订单出单，加分布式锁，

定时任务加锁



令牌桶算法

分区

typeof和valueof有什么区别

go动态代码生成

Mysql分页两种方法

LIMIT后面跟一个参数，表示要提取的数量。
如 ：select* from test LIMIT 3 指提取前三条数据，类似sqlServer的top语法。
LIMIT后面跟两个参数时，第一个参数是指第几行，第二个参数是取几条数据。
如： select * from test limit 2,3; 这个SQL是指从第二行的下一行开始向下取3条数据。(即取：3，4，5行的三条数据)

partition的作用

两张表两个条件（join、子查询）

restful风格

缓存击穿、缓存穿透

### 限流算法

https://www.bilibili.com/video/BV1AT4y167iA?spm_id_from=333.337.search-card.all.click&vd_source=58acbf449edd771737ee43a78ffdabf4

#### 基于计数器的限流

![image-20220919001928119](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919001928119.png)

![image-20220919002017585](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919002017585.png)

![image-20220919002038140](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919002038140.png)

![image-20220919002213411](/Users/gongwei/Library/Application Support/typora-user-images/image-20220919002213411.png)





### 布隆过滤器

https://www.bilibili.com/video/BV1eU4y1J7GY?spm_id_from=333.337.search-card.all.click&vd_source=58acbf449edd771737ee43a78ffdabf4

![image-20220918165751656](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918165751656.png)

### ![image-20220918165913148](/Users/gongwei/Library/Application Support/typora-user-images/image-20220918165913148.png)设计一个短链系统

#### 短链有啥好处，用长链不香吗

来看下以下别人给我发的营销短信，点击下方蓝色的链接（短链）

![如何设计一个高性能短链系统？_mysql_02](https://s2.51cto.com/images/blog/202108/10/7ddd6c3e0430fe3789d9c9e35ec9036a.jpeg?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

浏览器的地址栏上最终会显示一条如下的长链。

![如何设计一个高性能短链系统？_布隆过滤器_03](https://s2.51cto.com/images/blog/202108/10/53d13c45fadfb10a670fac51fa793f2d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)


那么为啥要用短链表示，直接用长链不行吗，用短链的话有如下好外

1. 链接变短，在对内容长度有限制的平台发文，可编辑的文字就变多了

​	最典型的就是微博，限定了只能发 140 个字，如果一串长链直接怼上去，其他可编辑的内容就所剩无几了，用短链的话，链接长度大大减少，自然可编辑的文字多了不少。

​	再比如一般短信发文有长度限度，如果用长链，一条短信很可能要拆分成两三条发，本来一条一毛的短信费变成了两三毛，何苦呢。另外用短链在内容排版上也更美观。

2. 我们经常需要将链接转成二维码的形式分享给他人，如果是长链的话二维码密集难识别，短链就不存在这个问题了,如图示

![如何设计一个高性能短链系统？_自增_04](https://s2.51cto.com/images/blog/202108/10/d452cc34892b63001a2a760a0b726c55.jpeg?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

3. 美观

#### 短链跳转的基本原理

从上文可知，短链好处多多，那么它是如何工作的呢。我们在浏览器抓下包看看

![如何设计一个高性能短链系统？_redis_06](https://s2.51cto.com/images/blog/202108/10/06ac4d2a5ca2198271d5fca279c51871.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

可以看到请求后，返回了状态码 302（重定向）与 location 值为长链的响应，然后浏览器会再请求这个长链以得到最终的响应,整个交互流程图如下

![如何设计一个高性能短链系统？_mysql_07](https://s2.51cto.com/images/blog/202108/10/d63eb11d84f3907da0abc959f03e0578.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

主要步骤就是访问短网址后重定向访问 B，那么问题来了，301 和 302 都是重定向，到底该用哪个，这里需要注意一下 301 和 302 的区别

- 301，代表 永久重定向，也就是说第一次请求拿到长链接后，下次浏览器再去请求短链的话，不会向短网址服务器请求了，而是直接从浏览器的缓存里拿，这样在 server 层面就无法获取到短网址的点击数了，如果这个链接刚好是某个活动的链接，也就无法分析此活动的效果。所以我们一般不采用 301。

- 302，代表 临时重定向，也就是说每次去请求短链都会去请求短网址服务器（除非响应中用 Cache-Control 或 Expired 暗示浏览器缓存）,这样就便于 server 统计点击数，所以虽然用 302 会给 server 增加一点压力，但在数据异常重要的今天，这点代码是值得的，所以推荐使用 302！

#### 短链生成的几种方法

##### 1、哈希算法

怎样才能生成短链，仔细观察上例中的短链，显然它是由固定短链域名 + 长链映射成的一串字母组成，那么长链怎么才能映射成一串字母呢，哈希函数不就用来干这事的吗，于是我们有了以下设计思路

![如何设计一个高性能短链系统？_mysql_08](https://s2.51cto.com/images/blog/202108/10/ff0ce70d832dc331abd1f061ea0155ae.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)



MurmurHash 提供了两种长度的哈希值，32 bit，128 bit，为了让网址尽可通地短，我们选择 32 bit 的哈希值，32 bit 能表示的最大值近 43 亿，对于中小型公司的业务而言绰绰有余。对上文提到的极客长链做 MurmurHash 计算，得到的哈希值为 3002604296，于是我们现在得到的短链为 固定短链域名+哈希值 = http://gk.link/a/3002604296

##### 如何缩短域名？

有人说人这个域名还是有点长，还有一招，3002604296 得到的这个哈希值是十进制的，那我们把它转为 62 进制可缩短它的长度，10 进制转 62 进制如下：

![如何设计一个高性能短链系统？_布隆过滤器_09](https://s2.51cto.com/images/blog/202108/10/1bb5adf872d93e24e5dc086e9752b99b.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

于是我们有 (3002604296)10 = (3hcCxy)10，一下从 10 位缩短到了 6 位！于是现在得到了我们的短链为 http://gk.link/a/3hcCxy

#### 如何解决哈希冲突的问题？

既然是哈希函数，不可避免地会产生哈希冲突（尽管概率很低），该怎么解决呢。

我们知道既然访问访问短链能跳转到长链，那么两者之前这种映射关系一定是要保存起来的，可以用 Redis 或 Mysql 等，这里我们选择用 Mysql 来存储。表结构应该如下所示

```mysql
CREATE TABLE `short_url_map` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `lurl` varchar(160) DEFAULT NULL COMMENT '长地址',
  `surl` varchar(10) DEFAULT NULL COMMENT '短地址',
  `gmt_create` int(11) DEFAULT NULL COMMENT '创建时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
-----------------------------------
如何设计一个高性能短链系统？
https://blog.51cto.com/u_13294304/3355321
```

于是我们有了以下设计思路。

1. 将长链（lurl）经过 MurmurHash 后得到短链。
2. 再根据短链去 short_url_map 表中查找看是否存在相关记录，如果不存在，将长链与短链对应关系插入数据库中，存储。
3. 如果存在，说明已经有相关记录了，此时在长串上拼接一个自定义好的字段，比如「DUPLICATE」，然后再对接接的字段串「lurl + DUPLICATE」做第一步操作，如果最后还是重复呢，再拼一个字段串啊，只要到时根据短链取出长链的时候把这些自定义好的字符串移除即是原来的长链。

以上步骤显然是要优化的，插入一条记录居然要经过两次 sql 查询（根据短链查记录，将长短链对应关系插入数据库中），如果在高并发下，显然会成为瓶颈。

**画外音：一般数据库和应用服务（只做计算不做存储）会部署在两台不同的 server 上，执行两条 sql 就需要两次网络通信，这两次网络通信与两次 sql 执行是整个短链系统的性能瓶颈所在！**

所以该怎么优化呢

1. 首先我们需要给短链字段 surl 加上唯一索引

2. 当长链经过 MurmurHash 得到短链后，直接将长短链对应关系插入 db 中，如果 db 里不含有此短链的记录，则插入，如果包含了，说明违反了唯一性索引，此时只要给长链再加上我们上文说的自定义字段「DUPLICATE」,重新 hash 再插入即可，看起来在违反唯一性索引的情况下是多执行了步骤，但我们要知道 MurmurHash 发生冲突的概率是非常低的，基本上不太可能发生，所以这种方案是可以接受的。

   

当然如果在数据量很大的情况下，冲突的概率会增大，此时我们可以加布隆过滤器来进行优化。

用所有生成的短网址构建布隆过滤器，当一个新的长链生成短链后，先将此短链在布隆过滤器中进行查找，如果不存在，说明 db 里不存在此短网址，可以插入！

画外音：布隆过滤器是一种非常省内存的数据结构，长度为 10 亿的布隆过滤器，只需要 125 M 的内存空间。

![如何设计一个高性能短链系统？_mysql_10](https://s2.51cto.com/images/blog/202108/10/16e835f18b289aa8aa2f110ad8337404.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)



#### 2、自增序列算法

我们可以维护一个 ID 自增生成器，比如 1，2，3 这样的整数递增 ID，当收到一个长链转短链的请求时，ID 生成器为其分配一个 ID，再将其转化为 62 进制，拼接到短链域名后面就得到了最终的短网址，那么这样的 ID 自增生成器该如何设计呢。如果在低峰期发号还好，高并发下，ID 自增生成器的的 ID 生成可能会系统瓶颈，所以它的设计就显得尤为重要。





如何设计一个高性能短链系统？
https://blog.51cto.com/u_13294304/3355321

https://www.bilibili.com/video/BV1yT4y1a7tD/?spm_id_from=333.788&vd_source=58acbf449edd771737ee43a78ffdabf4



### CPU的调度算法

时间片轮转算法（RR Round Robin）

先来先服务算法（FCFS: First Come，First Served）

短进程优先算法（SPN：Shortest Process Next ）

### Linux通过什么命令查找关键字

1、grep “关键字” 文件

2、vim：输入斜杠，然后输入要查找的字符

​	/string，string为要查找的字符。

### 逃逸分析

**如果函数外部没有引用，则优先放到栈中**

**如果函数外部存在引用，则必定放到堆中**

![image-20220926113658419](/Users/gongwei/Library/Application Support/typora-user-images/image-20220926113658419.png)

### go uint相减

```go
func main(){
  var a uint = 1
  var b uint = 2
  fmt.Println(a-b)
  // 如果操作系统是 32 位就是 2 的 32 次方 -1， 64位操作系统就是 2 的 64 次方 -1
  // Go 是强类型语言，相当于uint 0-1，在计算机uint计算都是加法运算，相当于 0 + -1
  // 负数的计算方式都会转成补码，-1的补码就是所有位都是1，最终计算结果出来都是1的二进制
  // uint识别的话就是当前当前位数的最大值
}
```



## 知识点：



showbug：https://www.bilibili.com/video/BV12p4y1W7Dz/?spm_id_from=333.788.recommend_more_video.-1&vd_source=58acbf449edd771737ee43a78ffdabf4

1. 进程和线程区别
2. 进程和线程通信方式
3. TCP和UDP区别
4. TCP怎么保证可靠性
5. 计算机7层网络模型
6. 事务的隔离级别有哪些
7. MySQL是什么隔离级别
8. MySQL怎么解决幻读的
9. B+树和B树区别
10. 项目中使用redis原因
11. 缓存一致性
12. 擅长什么
13. 项目亮点，难点
14. TCP的3次握手和4次挥手
15. CPU的调度算法有哪些
16. TCP拥塞控制
17. 输入URL到浏览器展示过程
18. https整个过程
19. SQL优化
20. 乐观锁和悲观锁区别
21. LRU算法
22. 日志文件中，用什么命令找关键字（linux）
23. 怎么设计分布式id生成器
24. 业务流程详细描述
25. 数据库有做分库分表？怎么做的
26. redis基本数据结构
27. redis list数据结构
28. innodb是行锁还是表锁
29. gmp原理
30. 主协程如何等待子协程完成呢
31. go结构体能比较吗
32. sync.mutex几种模式
33. 无缓存channel和有缓存channel区别
34. go defer原理
35. select干什么用的
36. slice如何扩容
37. go中逃逸分析
38. 如何查看端口对应进程号
39. time-wait作用
40. 5亿整数大文件如何排序
41. 分布式如何实现的
42. 这个项目你学到了什么
43. 平时如何学习go语言的
44. 通过ip地址如何找到目标地址
    1. arp
45. go中的uint无符号整型是否可以相减？
46. go的数组和切片区别
47. go中如何切片删除元素
48. map数据根据key进行排序
49. go的反射
50. git命令 merge和rebase的区别
51. 僵尸进程是什么
52. go内存管理
53. 传入结构体参数是值传递还是引用传递
54. linux中线程有几种模型
55. goroutine什么时候会阻塞，阻塞时候调度器会怎么做？ hand off模式
56. 线程和协程占用内存
57. 一个goroutine一直占用资源怎么办
58. 项目中怎么定位bug
59. 一个goroutine发生oom会怎么样，怎么排查和解决
60. 项目中的错误怎么处理
61. 项目中有统一的错误处理吗
62. 一个goroutine发生panic会怎么样
63. defer可以跨级捕获异常吗
64. gin框架是什么
65. gin框架怎么做参数校验
66. 中间件有了解？做过什么中间件
67. go 反射
68. 项目中用到过reflect吗（参数校验，结构体拷贝）
69. 通过反射方式调用函数
70. go中mutex了解吗，有几种模式，讲一讲
71. 项目中什么地方用到锁，map使用sync.RWmutex
72. channel用过吗，channel需要注意的地方，不能在close之后继续发送数据
73. 数据库中锁了解吗，行锁表锁
74. 分布式锁
75. redis集群模式（不是哨兵模式）和主从模式
76. redis持久化
77. 负载均衡算法
78. 编程题：3个函数分别打印cat、dog、fish，要求每个函数都要起一个goroutine，按照cat、dog、fish顺序打印在屏幕上100次。
79. channel有缓存和无缓存区别
80. channel底层实现，channel是否是线程安全
81. mutex是悲观锁
82. go中坑有哪些
83. go内存逃逸
84. channel是分配到堆上，什么变量分配到栈上，什么堆上
85. MySQL是什么索引
86. 项目中redis做什么
87. redis内存淘汰策略
88. 缓存一致性-延迟双删
89. go-线上部署后，发现内存泄露
90. mutex是悲观锁还是乐观锁，RWmutex用过没有
91. go结构体能不能进行比较
92. 空结构体的用途
93. cpu缓存一致性，mesi
94. gc讲一讲
95. 三次握手、四次挥手
96. time-wait和
97. 流量控制
98. http1.0和2.0区别
99. LRU算法
100. 选择go的理由，职责写的具体点，项目中遇到什么难点，怎么解决
100. groutine发生IO阻塞时候，调度器怎么做
100. 快照读的情况下，MVCC如何解决幻读
100. explain字段
100. 你们如何解决线程安全的
100. 复合索引和单列索引的区别
100. rabbitmq和kafka如何选择
100. 布隆过滤器
100. redis持久化怎么触发
100. 日期需不需要加索引
100. 间隙锁
100. 深分页如何解决
100. 



select name from User where id in (select o.user_id from Order o left join Product p on p.id =o.product_id where p.name = "螺丝")



图森未来：

```
面试日期：2022年10月10日 星期一
面试时间：14:00
面试时长：1小时（可能视面试情况缩减或延长，请预留一定缓冲时间）
面试形式：电脑视频面试
面试地址：https://interview.nowcoder.com/interview/16111611/interviewee?code=Z1EVFtoN
```



梦门：

```
10.10, 下午3.30

https://www.showmebug.com/pads/RHKQNN-候选人链接 请复制面试链接到PC端浏览器（推荐谷歌）打开，请确保网络及音视频设备（麦克风与摄像头）正常可用。非常感谢您对公司的关注，真诚邀约您参与此次面试，届时请准时参加，预祝沟通愉快！
```



字节跳动：

```
面试形式：视频面试​

面试时间：2022-10-10 20:00(GMT+08:00) China Standard Time - Beijing​

面试链接：https://t.zijieimg.com/6mGombq/
```



哔哩哔哩：

```
【面试职位】：OTT3Golang高级研发工程师(TV)

【面试时间】：2022-10-11 14:00

【面试形式】：视频面试（建议您提前5分钟进行设备调试，使用Chrome浏览器打开）

【面试地址】：https://ms6.co/r68nY
```



集致：

```
会议主题：golang远程初试 龚伟
会议时间：2022/10/11 15:30-2022/10/11 16:30

点击链接直接加入会议：https://work.weixin.qq.com/webapp/tm/08psgGPQK04

#企业微信会议：916 855 565

```



成都星合互娱：

```
沟通时间：2022.10.11 17:00
沟通职位：golang web开发
面试形式：视频面试

会议号：870 719 167
```





作业帮：

```
•  面试日期：2022年10月12日 星期三
•  面试时间：14:00
•  视频面试链接：https://v.hina.com/interview/simple/interviewee/2/csecn8sqq5vffvs
```



四维创智:

```
会议主题：四维创智面试-golang-龚伟
会议时间：2022/10/12 15:30-16:30 (GMT+08:00) 中国标准时间 - 北京

点击链接入会，或添加至会议列表：
https://meeting.tencent.com/dm/mA739sOIxabT

#腾讯会议：559-486-179

```



集度汽车：

```
面试日期：2022年10月12日 星期三
面试时间：17:00
面试形式：视频面试
面试地址：https://interview.nowcoder.com/interview/32279238/interviewee?code=giMTVuy7
```



希望学：

```
面试职位: 后端开发工程师 

面试地址: 腾讯会议：346-618-7246

面试时间：2022-10-12 18:30

面试形式: 腾讯会议
```



肯斯爪特：

```
面试日期：2022年10月12日 星期三
面试时间：20:00
面试时长：30分钟（可能视面试情况缩减或延长，请预留一定缓冲时间）
面试形式：视频面试
面试地址：https://meeting.tencent.com/dm/3t3oXUi5R0cM（会议号: 939986736）
```





minimax：

```
面试形式：视频面试​

面试时间：2022-10-13 14:00 (GMT+08:00) 中国标准时间 - 北京​

面试链接：https://vrfi1sk8a0.feishu.cn/hire/short_url/MYkH8hS​
```



伊对：

```
面试形式：视频面试​

面试时间：2022-10-13 15:30 (GMT+08:00) China Standard Time - Beijing​

面试链接：https://yidui-me.feishu.cn/hire/short_url/MYBYSmy（飞书）​

视频面试开始前，请先下载对应视频软件，下载链接 https://www.feishu.cn/download
```



字节跳动：

```
【面试信息】​

面试形式：视频面试​

面试时间：2022-10-14 15:30(GMT+08:00) China Standard Time - Beijing​

面试链接：https://t.zijieimg.com/MYSVNxJ/
```



希望学：

```
您好，老师，您好邀请您于2022年10月14日 17时00分参加后端开发工程师面试，面试形式：腾讯会议，地址：腾讯会议：346-618-7246，
```







- redis高可用方案
- go中怎么退出goroutine
- go中使用断言有什么注意点
- 数组和切片什么区别（切片有什么坑，扩容）
- map删除一个key
- go中拼接字符方法
- 502排查过程



![image-20221012115042380](/Users/gongwei/Library/Application Support/typora-user-images/image-20221012115042380.png)

![image-20221012115054885](/Users/gongwei/Library/Application Support/typora-user-images/image-20221012115054885.png)

![image-20221012115104969](/Users/gongwei/Library/Application Support/typora-user-images/image-20221012115104969.png)



## 设计题：

### 如何解决超卖：

![image-20221017234831146](/Users/gongwei/Library/Application Support/typora-user-images/image-20221017234831146.png)

### 如何解决少卖：

![image-20221017234912288](/Users/gongwei/Library/Application Support/typora-user-images/image-20221017234912288.png)

### mysql count（*）count（1）谁快

count（列名）会扫描全表

![image-20221017235223828](/Users/gongwei/Library/Application Support/typora-user-images/image-20221017235223828.png)

### Http和RPC区别：

### 20亿用户，快速统计哪些用户正在登录：

![image-20221018114718641](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018114718641.png)

![image-20221018114733221](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018114733221.png)

![image-20221018114805301](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018114805301.png)



### 如何从1000w记录中，找出最热门的10个记录？

![image-20221018114905361](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018114905361.png)

![image-20221018114956269](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018114956269.png)

![image-20221018115115310](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018115115310.png)

### 缓存一致性：

![image-20221018120904699](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018120904699.png)

![image-20221018121021038](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018121021038.png)

![image-20221018121149634](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018121149634.png)



### MySQL主从同步延迟解决方案：

### Redis大key：

![image-20221018133028977](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018133028977.png)

![image-20221018133044515](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018133044515.png)

![image-20221018133114945](/Users/gongwei/Library/Application Support/typora-user-images/image-20221018133114945.png)

### 线上服务Cpu飙升如何定位到代码？：

### 两个50亿的url找出相同url?这可能？







### go语言优势

1、学习曲线容易

2、效率：快速的编译时间，开发效率和运行效率高

3、简单的并发



字节：

```
面试形式：视频面试​

面试时间：2022-10-17 15:00(GMT+08:00) China Standard Time - Beijing​

面试链接：https://t.zijieimg.com/MMDuRC6/
```



得到：

```
面试形式：视频面试​

面试时间：2022-10-17 16:30 (GMT+08:00) China Standard Time - Beijing​

面试链接：https://dedao.feishu.cn/hire/short_url/MMqEaVy
```



哔站：

```
【面试职位】：OTT3Golang高级研发工程师(TV)

【面试时间】：2022-10-18 15:00

【面试形式】：视频面试（建议您提前5分钟进行设备调试，使用Chrome浏览器打开）

【面试地址】：https://ms6.co/CSUkx
```



肯斯抓特：

```
面试日期：2022年10月18日 星期二
面试时间：19:00
面试时长：30分钟（可能视面试情况缩减或延长，请预留一定缓冲时间）
面试形式：视频面试
面试地址：https://meeting.tencent.com/dm/Vfteyu4H2l9i（会议号: 755730171）
温馨提示：请务必使用电脑面试
```



集度：

```
面试日期：2022年10月19日 星期三
面试时间：15:00
面试形式：视频面试
面试地址：https://interview.nowcoder.com/interview/32279238/interviewee?code=giMTVuy7
联系人：徐春悦
联系电话：15846124953
```



得到：

```
面试形式：视频面试​

面试时间：2022-10-19 17:00 (GMT+08:00) China Standard Time - Beijing​

面试链接：https://dedao.feishu.cn/hire/short_url/MDyMsPW（飞书）​

视频面试开始前，请先下载对应视频软件，下载链接 https://www.feishu.cn/download​
```



伊对：

```
```



清枫（北京）科技有限公司

```
面试时间：2022-10-20 17:00 亚洲/北京(UTC+8:00)

面试职位：后端开发工程师

面试方式：远程视频

面试链接：https://interview.nowcoder.com/interview/26733417/interviewee?code=HDLcgugy（你的专属链接，请勿转发）
```



集度汽车：

```
面试日期：2022年10月21日 星期五
面试时间：17:00
面试形式：视频面试
面试地址：https://interview.nowcoder.com/interview/32279238/interviewee?code=giMTVuy7
联系人：徐春悦
联系电话：15846124953
```



恺望:

```
恺望邀请你加入飞书视频会议
会议时间：10月24日 (今天) 16:00
会议 ID：463 615 106
会议链接：https://vc.feishu.cn/j/463615106

手机拨号一键入会
+862122504720,,463615106(中国大陆)
4009200399,,463615106(中国大陆)

根据所在地拨打号码
+86 21 2250 4720(中国大陆)
400 920 0399(中国大陆)
+852 2245 3212(中国香港)
+44 20 3433 3816(英国)
```





胖球：

```
10-24 18:00
```



滴滴

```
龚伟同学，您好！
感谢您关注滴滴出行，您的工作经历和职业背景很符合我公司相关岗位的需求，现诚邀您来参加我公司的面试。 (此邮件为系统发送，请勿回复)

应聘职位:
高级研发工程师

面试时间:
2022-10-25 15:00

面试地点/链接:
https://z.didi.cn/bck03Pd

面试形式:
视频面试 （请提前下载umeet app或者客户端，届时直接点击会议链接进入即可）

HR联系人:
韩少杰(hanshaojie_v@didiglobal.com)，联系电话：18818279461 （咨询职位、修改面试时间）
```



电信天翼云：

```
周二下午5点

龚伟，您好！

恭喜你的简历已通过我司的初步审核，现邀请您前来我司进行面谈，具体事宜通知如下：

1、应聘职位：中高级后端开发工程师（Golang）1966；

2、面试时间：2022-10-25 17:00~2022-10-25 18:00；

3、面试地点：远程面试（具体面试链接请查收邮件内容）；




Mr.He 邀请您参加腾讯会议

会议主题：龚先生-广州golang-一面

会议时间：2022/10/25 17:00-18:00 (GMT+08:00) 中国标准时间 - 北京



点击链接入会，或添加至会议列表：

https://meeting.tencent.com/dm/g3E3AMkMteLj



#腾讯会议：176-985-830
```



金果科技：

```
周二下午6点
```



伊对：周四

```
龚伟：​

你好，伊对诚邀你参加Go后端开发工程师（一组）职位的面试。​

【面试信息】​

面试形式：视频面试​

面试时间：2022-10-27 11:00 (GMT+08:00) China Standard Time - Beijing​

面试链接：https://yidui-me.feishu.cn/hire/short_url/Mx1WE5P（飞书）​

视频面试开始前，请先下载对应视频软件，下载链接 https://www.feishu.cn/download

```



滴滴：周五

```
，周五下午4点吧，稍后我来发面邀

龚伟同学，您好！
感谢您关注滴滴出行，您的工作经历和职业背景很符合我公司相关岗位的需求，现诚邀您来参加我公司的面试。 (此邮件为系统发送，请勿回复)

应聘职位:
高级研发工程师

面试时间:
2022-10-28 16:00

面试地点/链接:
https://z.didi.cn/aWK1OVt

面试形式:
视频面试 （请提前下载umeet app或者客户端，届时直接点击会议链接进入即可）

HR联系人:
韩少杰(hanshaojie_v@didiglobal.com)，联系电话：18818279461 （咨询职位、修改面试时间）
```



cobo：

```
面试日期：2022年10月28日 星期五
面试时间：18:00
面试时长：1小时（可能视面试情况缩减或延长，请预留一定缓冲时间）
面试形式：视频面试
面试地址：gao 邀请您参加预先安排的 Zoom 会议。  主题：面试-go-龚伟 时间：2022年10月28日 06:00 下午 北京，上海  加入 Zoom 会议 https://us06web.zoom.us/j/88403827756?pwd=UFVjL2xPYWZ0TVNiS2ZJNnRRTFJodz09  会议号：884 0382 7756 密码：529198 手机一键拨号 +13126266799,,88403827756#,,,,*529198# 美国 (Chicago) +13462487799,
```



合合信息：

```
7点
```





字节跳动，下周1

```
龚伟​

你好，字节跳动诚邀你参加商业生态安全后端开发工程师职位的面试。​

【面试信息】​

面试形式：视频面试​

面试时间：2022-10-31 16:00(GMT+08:00) China Standard Time - Beijing​

面试链接：https://t.zijieimg.com/Mx52gKY/​

如何进入面试页面？ 
```



集度：下周1,7点

```
 	
龚伟，您好

感谢关注集度！很高兴邀请您参加车联网服务端工程师（地图服务 方向）的面试，具体面试安排如下：

面试日期：2022年10月31日 星期一
面试时间：19:00
面试形式：视频面试
面试地址：https://interview.nowcoder.com/interview/33874607/interviewee?code=r1vei9RX
联系人：霍佳明
联系电话：18310111524
```





pdd,下周星期2

```
龚伟:
您好！

拼多多诚邀您参加java研发工程师-快团团方向职位的远程面试。

【面试信息】
面试时间：2022-11-01 16:00

【温馨提示】
1、收到本邮件后，请联系HR文朱迪确认是否能按时参加本次面试，如需修改面试时间，请提前1天与HR文朱迪联系，邮箱：wenzhudi@pinduoduo.com；
2、远程面试的链接为https://job.pinduoduo.com/interview/livecode/TOCjVE7203361897，该链接需使用电脑接入，请提前进行设备调试；
3、请提前找好较为安静的环境，以免对您的面试效果产生影响；
4、此邮件无需回复，如有任何问题，请联系HR。
```



bud下周星期二：

```
龚伟，您好

感谢关注BUD！很高兴收到您的简历，想和您就后端开发工程师职位安排一次面试。
面试日期：2022年11月1日 星期二
面试时间：17:30
面试时长：30分钟（可能视面试情况缩减或延长，请预留一定缓冲时间）
面试形式：视频面试
面试地址：https://meeting.tencent.com/dm/wT5MNG5j4Ypg（会议号: 988341313）
联系人：郭聪
联系电话：13071250946
联系邮箱：guocong@budcreate.io
```



集度：下周2,7点

```
 	
 	
龚伟，您好

感谢关注集度！很高兴邀请您参加车联网服务端工程师（地图服务 方向）的面试，具体面试安排如下：

面试日期：2022年11月1日 星期二
面试时间：19:00
面试形式：视频面试
面试地址：https://interview.nowcoder.com/interview/33874607/interviewee?code=r1vei9RX
联系人：霍佳明
联系电话：18310111524
```



星期三：下午4点，cobo：

```
面试日期：2022年11月2日 星期三
面试时间：16:00
面试时长：1小时（可能视面试情况缩减或延长，请预留一定缓冲时间）
面试形式：视频面试
面试地址：gao 邀请您参加预先安排的 Zoom 会议。  主题：面试-go-龚伟 时间：2022年11月2日 04:00 下午 北京，上海  加入 Zoom 会议 https://us06web.zoom.us/j/82494165464?pwd=Z2ZROEVtZ2QyQ3g2VEgxYS9rK29KZz09  会议号：824 9416 5464 密码：040667 手机一键拨号 +13017158592,,82494165464#,,,,*040667# 美国 (Washington DC) +1309205
```



星期三，下午5.30：合合信息

```
邀请您参加腾讯会议
会议主题：龚伟的复试
会议时间：2022/11/02 17:30-18:30 (GMT+08:00) 中国标准时间 - 北京

点击链接入会，或添加至会议列表：
https://meeting.tencent.com/dm/G86F6AHuFimc

#腾讯会议：580-707-757

复制该信息，打开手机腾讯会议即可参与
```





#### 基础语法

01 = 和 := 的区别？
02 指针的作用
03 Go 允许多个返回值吗？
04 Go 有异常类型吗？
05 什么是协程（Goroutine）
06 如何高效地拼接字符串
07 什么是 rune 类型
08 如何判断 map 中是否包含某个 key ？
09 Go 支持默认参数或可选参数吗？
10 defer 的执行顺序
11 如何交换 2 个变量的值？
12 Go 语言 tag 的用处？
13 如何判断 2 个字符串切片（slice) 是相等的？
14 字符串打印时，%v 和 %+v 的区别
15 Go 语言中如何表示枚举值(enums)？
16 空 struct{} 的用途

#### 实现原理

01 init() 函数是什么时候执行的？
02 Go 语言的局部变量分配在栈上还是堆上？
03 2 个 interface 可以比较吗 ？
04 2 个 nil 可能不相等吗？
05 简述 Go 语言GC(垃圾回收)的工作原理
06 函数返回局部变量的指针是否安全？
07 非接口非接口的任意类型 T() 都能够调用 *T 的方法吗？反过来呢？

#### 并发编程

01 无缓冲的 channel 和有缓冲的 channel 的区别？
02 什么是协程泄露(Goroutine Leak)？
03 Go 可以限制运行时操作系统线程的数量吗？

代码输出
变量与常量
作用域
defer 延迟调用
————————————————
版权声明：本文为CSDN博主「峰子2012」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/Z451835239/article/details/120488968





1. jwt鉴权原理

2. `go func(){}` 具体流程。

   [Golang-Internal-Notes/Go 协程调度--基本原理与初始化.md at master · LeoYang90/Golang-Internal-Notes](https://github.com/LeoYang90/Golang-Internal-Notes/blob/master/Go 协程调度——基本原理与初始化.md)

   我们通过 go func()来创建一个goroutine；

   - 有两个存储goroutine的队列，一个是局部调度器P的local queue、一个是全局调度器数据模型schedt的global queue。
   - 新创建的goroutine会先保存在local queue，如果local queue已经满了就会保存在全局的global queue；
   - 创建 G 之后，发现有闲置的 P 就会尝试唤醒物理线程。
   - 当 G 执行了非阻塞调用或者网络调用之后，调度程序会将 G 保存上下文并切出 M，M 会运行下一个 runable 的 G
   - 当 M 执行某一个 goroutine 时候如果发生了 syscall 或则其余阻塞操作。这种操作并不像非阻塞调用一样可以暂停 G，因为 M 物理线程大概率已经沉入内核，没有办法运行下一个 G，这个系统调用只能占用一个物理线程。但是这个时候 M 实际上可能只是等待内核的 IO 数据等等，并不会占用 CPU。
   - 这时候，sysmon 线程会检测到 M 已经阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)，尝试让操作系统调度这个新的物理线程来占用这个 CPU，保障并发



## 问题总结：

## 桃园店（1）

### 1.一个接口平时响应正常，现在响应耗时很高，怎么排查

1. 检查网络是否正常
2. 检查此时刻是否有慢查询，如果有，explain sql，看能不能优化
3. 是否使用上了索引，是否全表扫描
4. 此时是否有大表变更，拖慢sql服务器性能
5. 缓存是否失效，造成了缓存穿透
6. 第三方服务是否正常
7. 检查该时间节点是否有过量爬虫等非法请求，拖慢服务器性能
8. 检查该时刻的CPU利用率，是否存在内存泄漏等情况
9. 检查此时请求量是不是很大，遭到了dos攻击

### 2.请您介绍一下过往项目和经历

### 3.为什么使用go语言重构

### 4.项目中的难点

### 5.转发服务在详细了解一下，了解一下代码

### 6.为什么写协程池，它的意义是什么，再认真看一下代码，讲清楚流程，用select去改一下代码，这个协程池更像是协程队列，而不能自动扩容缩容，和直接go有什么区别，有没有超时机制

### 7.沟通应该更流畅

### 8.go和python有什么不同点，优劣势，说话过程中不要停顿

### 9.Python的并发是真正并发？

### 10.linux下的文件管理，chmod 777

## 桃源店2

### 11.go init什么执行时机，const var是在init之前执行

### 12.逃逸分析，如何知道一个对象分配在栈上还是堆上，如何判断是否发生逃逸

​	go build -gcflags '-m' 可以显示变量逃逸分析；

### 13.有缓存通道和无缓存通道区别，回答不上了，就说差不多了

### 14.go三色标记法

### 15.go什么时候会发生阻塞，主要是channel阻塞，如果channel发生阻塞，调度器会发生什么

### 16.IO阻塞时候，调度器会发生什么

### 17.mysql的隔离级别

### 18.快照读和当前读

### 19.在快照读情况下，mvcc如何解决幻读

- 快照读：所有普通的select语句都算快照读，它并不会给表中任何记录做加锁操作，其他事务可以对表中记录做任何改动

- 当前读：加锁的操作都叫当前读，分为s锁，x锁

  - 共享锁：S锁。在事务要读取一条记录时，需要先获取该记录的S锁
    - select … lock in share mode

  - 独享锁（排他锁）：X锁。事务要改动一条记录时，需要先获取X锁
    - select … for update、insert、update、delete
    - S锁与S锁是兼容的；S锁与X锁是不兼容；X锁与X锁也是不兼容。
      

1. 在快照读的情况下，会通过mvcc来避免幻读
   - InnoDB实现mvcc 是通过 readview+undolog 来实现
2. 在当前读的情况下，会通过next-key来避免幻读



- 在READ COMMITTED隔离级别下，一个事务执行过程中每次执行SELECT操作都会生成一个ReadView，ReadView本身就保证了事务不可以读取到未提交的事务做出的修改，也就避免了脏读现象
- 在REPETABLE READ隔离级别下，一个事务执行过程中只有第一次执行SELECT操作时才会生成一个ReadView，之后的SELECT操作都是复用这个ReadView，这也就避免了不可重复度和幻读

![image-20221105000138204](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105000138204.png)

![image-20221104235834536](/Users/gongwei/Library/Application Support/typora-user-images/image-20221104235834536.png)

![image-20221105000953097](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105000953097.png)

![image-20221105000856669](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105000856669.png)

### 20.sql执行计划比较关心哪些字段，rows和filtered是什么意思

### 21.分析执行计划后，怎么优化（不是调整索引顺序）

### 22.联合索引和多个单列索引区别

https://blog.csdn.net/xu7065/article/details/106410028?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-106410028-blog-47100619.pc_relevant_layerdownloadsortv1&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-106410028-blog-47100619.pc_relevant_layerdownloadsortv1&utm_relevant_index=2

1. 建立单列索引，当查询是a =x and b=x and c=x时候，索引优化器有可能只选择了a索引列，所以回表次数比建立多列索引要多
2. 建立多个单列索引，磁盘开销更大

### 23.最左前缀匹配，要注意范围查询后不起作用

### 24.索引覆盖

### 25.深分页：select * from table where a > 1 limit 1000000,20如何优化，为什么要这么优化

https://www.bilibili.com/video/BV1UY4y1j7Ji/?spm_id_from=333.337.search-card.all.click&vd_source=58acbf449edd771737ee43a78ffdabf4

不能用select * from table where a >1 and id > #{id} limit 20

这有个局限，id必须是连续自增的，不能而且前端不能跳页

有两种结局办法：（id不用回表查询，所以很快）

1. select * from table where id >= (select id from table where a>1 limit 10000000, 1) limit 20
2. select * from table where id in (select id from table where a>1 limit 10000000, 20)

### 26.MySQL执行顺序

mysql执行顺序如下：

1. from 阶段

2. where 阶段

3. group by 阶段

4. having 阶段

5. select 阶段

6. order by 阶段

7. limit 阶段

按照以上书写顺序，完整的执行顺序应该是这样：

1、from子句识别查询表的数据；

2、where子句基于指定的条件对记录进行筛选；

3、group by 子句将数据划分成多个组别，如按性别男、女分组；

4、有聚合函数时，要使用聚集函数进行数据计算；

5、Having子句筛选满足第二条件的数据；

6、执行select语句进行字段筛选

7、筛选重复数据；

8、对数据进行排序；

9、执行limit进行结果限定

### 27.用Redis干什么

分布式锁，缓存

### 28.Redis过期策略

### 29.Redis分布式锁面试问题

### 30.redlock

### 31.redis续期时间如何执行

### 32.RDB和AOF

### 33.算法题：[1,2,3]的全排列



## 桃园店（3、4、5）

### 1.为什么选用gin框架、gorm框架

### 2.踩坑点

![image-20221105010206674](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105010206674.png)

![image-20221105010222046](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105010222046.png)

### 3.restful 是什么

资源为中心的一种软件风格

- restful: 给用户一个url，根据method不同在后端做不同的处理，比如：post 创建数据、get获取数据、put和patch修改数据、delete删除数据。
- no rest: 给调用者很多url，每个url代表一个功能，比如：add_user/delte_user/edit_user/



```
若要在服务器上创建资源，应该使用 POST 方法。

若要检索某个资源，应该使用 GET 方法。

若要更改资源状态或对其进行更新，应该使用 PUT 方法。

若要删除某个资源，应该使用 DELETE 方法。

经过这样的一番扩展，我们对一个资源的 CRUD 操作就可以通过同一个 URI 完成了：

读取） [GET] http://www.example.com/photo/logo

仍然保持为 [GET] http://www.example.com/photo/logo

（创建）http://www.example.com/photo/logo/create

改为 [POST] http://www.example.com/photo/logo

（更新）http://www.example.com/photo/logo/update

改为 [PUT] http://www.example.com/photo/logo

（删除）http://www.example.com/photo/logo/delete

改为 [DELETE] http://www.example.com/photo/logo
```



### 4.三次握手和四次挥手

### 5.如何与三方团队交流

### 6.工作中压力最大的时间

​	刚进入公司，业务需求不太理解

### 7.如何防止表单重复提交

1. 数据库设置用户名、邮箱号或者其他字段为唯一索引

2. 使用javascript来禁用重复提交，当提交一次后，禁用提交按钮

   <img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20221105131822970.png" alt="image-20221105131822970" style="zoom:50%;" />

3. 在表单里面添加一个隐藏标签，传输的值为uuid，当我们第一次提交时候，后台会进行逻辑校验，校验规则如下，会取该标签的值和session中的token字段进行对比，如果不一样，给session设置上token，token值就是隐藏标签对应的值，然后进行后续业务处理，如果一样，则说明是重复提交，则拒绝处理该请求![image-20221105132517496](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105132517496.png)



## 桃园店（6，7）

### 1.认真看项目，项目介绍得更加流畅（透传、jwt封装数据、log模块再看看）

​	log数据表数据量大？需要分库分表？

​	如果需要分库分表，怎么分，log查询场景是什么

​	自增id和时间戳id有什么优缺点

​	怎么拿到innodb中最大的id

### 2.基础组建功能库的搭建（比如set，比如结构体拷贝）

### 3.channel底层原理

### 4.算法题：合并n个有序链表，最小堆时间复杂度和空间复杂度

### 5.导出进度怎么完成的，细粒度导出进度怎么完成

### 6.redis用到什么功能

 1. 分布式锁（redlock）

 2. 缓存（hash）

 3. 有序集合（底层实现）

    压缩列表和跳表

    跳表的时间复杂度：插入，删除，查找时间复杂度都是logn

    ![image-20221105175939301](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105175939301.png)

 4. geohash（底层实现）

    底层是zset，

    所以我们发现这个结构其实和redis的zset结构其实挺像的，唯一的区别可能在于zset只有一个score，而GEO有经度和纬度，所以我们只需要解决能用一个score来保存经度和纬度就可以解决问题了。其实redis的确也是这么做的，而且GEO的底层其实就是在zset的结果上做了一层封装

### 7.大key大value标准，如何避免大key大value

#### 如何查找大key

`--bigkeys` 是 redis 自带的命令，对整个 Key 进行扫描，统计 string，list，set，zset，hash 这几个常见数据类型中每种类型里的最大的 key。

–-bigkeys 其实就是找出类型中最大的 key，最大的 key 不一定是大 key，最大的 key 都不超过 10kb 的话，说明不存在大 key。

但某种类型如果存在较多的大key (>10kb)，只会统计 top1 的那个 key，如果要统计所有大于 10kb 的 key，需要用第三方工具扫描 rdb 持久化文件。


一般来说，string 类型控制在 10KB 以内，[hash](https://so.csdn.net/so/search?q=hash&spm=1001.2101.3001.7020)、list、set、zset 元素个数不要超过 5000。

#### 大key出现的问题：

1. 客服端阻塞
2. 阻塞工作线程

#### 防止大key出现：

##### 字符串类型：

只存储必要的字段，删除无用字段

##### hash等

以 hash 为例，原先的正常存取流程是

```
hget(hashKey, field); 
hset(hashKey, field, value)
```

现在，固定一个桶的数量，比如 10000，每次存取的时候，先在本地计算 field 的 hash 值，模除 10000，确定该 field 落在哪个 key 上，核心思想就是将 value 打散，每次只 get 你需要的。

```java
newHashKey = hashKey + (hash(field) % 10000); 
hset(newHashKey, field, value); 
hget(newHashKey, field)
```

#### 如何删除大key

1. 现对key进行改名，进行逻辑删除，使客服端无法使用原key，在进行批量删除

![image-20221105184937466](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105184937466.png)



```
字符串：
直接删除

有序集合：
伪代码
ZREMRANGEBYRANK key 0 10


集合：
# 伪代码
SRANDMEMBER key 10
SREM key fields

hash：
# 伪代码
HSCAN key 0 COUNT 100
HDEL key fields

list：
pop
```

### 8.消息中间件的选择

#### kafka

- 性能卓越，单机写入TPS约在百万条/秒，最大的优点，就是吞吐量高；
- 可用性非常高，kafka是分布式的，一个数据多个副本，某个节点宕机，Kafka 集群能够正常工作；
- 持久性、可靠性： Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储；
- 优秀的第三方Kafka Web管理界面Kafka-Manager；
- 在日志领域比较成熟，被多家公司和多个开源项目使用；
- 主要是用来进行实时数据计算的以及日志收集，现在的项目里面很少用它做消息中间件。

**kafka高吞吐率的实现：**

1. 顺序读写：kafka将消息读写写入到了分区partition中，而分区消息是顺序读写的。顺序读写要远快于随机读写
2. 零拷贝：生产者、消费者对于kafka中消息的操作都是采用零拷贝实现的
3. 批量发送：kafka允许采用批量消息发送模式
4. 消息压缩：kafka允许对消息集合进行压缩



之所以选择kafka，是因为rocketmq不支持go语言，没选择rabbitmq是因为并发度不高



## 桃园店（8）

### 1.自我介绍需要再丰富一些

### 2.技术栈需要深入介绍一下，不要说完然后，又没下文

### 3.简历项目时间节点需要重新调整

### 4.导出任务需要仔细梳理，handler需要着重介绍，handler有什么方法，如何新增一个导出类型

### 5.为什么使用kafka，请说出kafka优点

### 6.说话不要停顿，要流畅

### 7.kafka如何保证消息不丢失

- 确保消息消费完成再提交。`Consumer`端有个参数`enable.auto.commit`，最好设置成`false`，并自己来处理`offset`的提交更新

### 8.零拷贝是什么意思

### 9.kafka如何避免重复消费

### 10.导出文件这是怎么做的，

- 是先处理程序，再提交offset，处理程序过程时候判断status是不是success，如果是，则不进行导出

### 11.项目亮点有什么，导出失败重试怎么做的



## 桃园店（9）

听不见



## 桃园店（10）字节跳动

### 1.new和make的区别

### 2.协程和线程的区别，不要说暂时就这么多

### 3.redis里面有什么数据结构

### 4.redis用作分布式缓存，过期策略

### 5.Redis的持久化机制，RDB和AOF，优缺点

### 6.缓存雪崩、穿透、击穿，以及解决方案

### 7.Redis怎么做的高可用

- 哨兵模式

  ![image-20221105223509767](/Users/gongwei/Library/Application Support/typora-user-images/image-20221105223509767.png)

### 8.innodb和mysaim引擎区别

### 9.innodb索引结构

### 10.回答时候不要加上吧，3层树存多少数据

### 11.覆盖索引和回表查询

### 12.建立索引时候需要考虑什么

### 13.场景题，1亿个用户查询游戏分数topN的人，查询自己的排名，选型

1亿个用户，每个用户都有一个游戏分数，
1.查询topN分数对应的用户
2.查询自己的排名

请输出技术方案包括选型等



## 桃园店（11）哔哩哔哩

### 1.make和new区别

### 2.channel底层数据结构，发送和接收过层，lock锁在什么起作用

​	channel 是线程安全的，channel的底层实现中，hchan结构体中采用Mutex锁来保证数据读写安全。在对循环数组buf中的数据进行入队和出队操作时，必须先获取互斥锁，才能操作channel数据

### 3.协程和线程区别

### 4.go和python不同点，适用场景

### 5.MySQL事务隔离级别，默认隔离级别，怎么解决幻读

### 6.MySQL为什么用B+树

### 7.浏览器输入url经历了什么

### 8.算法：二叉树的中序遍历



## 桃园店（12）

### 1.心跳检测机制

### 2.kafka多少分区

### 3.channel怎么只关闭一次

### 4.go slice

### 5.MySQL引擎



## 桃园店（13）

### 1.hr面



## 桃园店（14）

### 1.协程池

### 2.看一下导出框架，导出限制多少条数据

### 3.retrytasktab去看一下

### 4.Innodb什么情况下表锁

### 5.B+树和B树有什么区别

### 6.MySQL有哪些锁

基于锁的属性分类:**共享锁（读锁）、排他锁（写锁）**。
基于锁的粒度分类:**行级锁（(innodb )、表级锁（ innodb、myisam)、页级锁（ innodb引擎)、记录锁、间隙锁、临键锁**。

### 7.间隙锁什么情况下会触发

https://zhuanlan.zhihu.com/p/48269420

### 8.不要加xx的吧，如不是并发安全的吧

### 9.go http请求没close，会有什么影响？



## 桃园店（15）和hina聊天

### 1.GMP为什么要有全局队列

### 2.context有什么作用

1. 值传递
2. 超时控制
3. goroutine之间协作控制

### 3.time-wait close-wait

### 4.2MSL需要吗

### 5.https请求过程

### 6.go中都是值传递

### 7.go 中oom怎么排查



## 桃园店（16）

### 1.一个接口响应耗时比较长，但是MySQL已经用上了索引，还有什么方面可能导致响应变慢

### 2.接口幂等

### 3.如何避免死锁

### 4.有什么限流算法，分别适用什么场景

### 5.slice底层结构，还有长度和cap元素

### 6.for-range循环，读取已关闭channel，nil比较

- https://www.elecfans.com/d/1878802.html



## 桃园店（17）哔哩哔哩二面，没兴趣

### 1.kafka怎么解决乱序，指定key

### 2.算法题：连续子数组和为n

### 3.数据库分库分表，怎么查询某个人的订单

### 4.数据库事务原理，acid是如何解决的

### 5.redis用来做什么，分布式锁

### 6.自趋力



## 桃园店（18）

### 1.MySQL调优方案

### 2.数据库为什么要设置not null

1. 查询时候，is null or is not null 不会走索引

2. count（name）时候只会统计非null行

3. distinct 和 group by来说，所有的null值被视为相等，order by来说升序null会排在前面

   ![image-20221106170427163](/Users/gongwei/Library/Application Support/typora-user-images/image-20221106170427163.png)

4. 表中只有一条有名字的记录，此时查询名字!=a预期的结果应该是想查出来剩余的两条记录，会发现与预期结果不匹配。

    ![image-20221106170642743](/Users/gongwei/Library/Application Support/typora-user-images/image-20221106170642743.png)

### 3.算法题：比较版本号大小

### 4.go 踩坑点

### 

## 桃园店（19）集度汽车

### 1.kill容器时候，怎么保证任务执行完

### 2.channel读写过程

### 3.map的数据结构，什么时候会扩容

### 4.算法题：当前时间转换成角度



## 桃园店（20）

### 1.算法题：单链表反转

### 2.算法题：二叉树中序遍历

### 3.慢查询，explain，字段的解释

### 4.a = x and b > x order by c怎么建立索引

- where a=x and b=x order by c desc;  会用到索引（a,b,c）
- where a=x order by b desc,c desc;  会用到索引（a,b,c）

- http://t.zoukankan.com/smallzhen-p-12702491.html

### 5.缓存一致性怎么保证

### 6.redis删除策略



## 桃园店（21）

### 1.请求很慢怎么排查，trace id

### 

## 桃园店（22）

### 1.sync.map怎么实现的



## 桃园店（23）

### 1.工作经历

1. log模块需要展开啊
2. channel设计goroutine

### 2.go中内存泄漏什么造成的，怎么解决

### 3.结合gmp分析，channel阻塞后的唤醒机制（25分钟）

### 4.Redis用作什么

### 5.Redis主从同步策略

### 6.redis热点数据过期

### 7.503排查

### 8.TCP握手过程中丢包

![在这里插入图片描述](https://img-blog.csdnimg.cn/a6a31e474c6541ea8f714c7ff56df13d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6YW46I-c44CC,size_20,color_FFFFFF,t_70,g_se,x_16)

问题一：
A会周期性超时重传第一个包。直到收到B发送的第二个包的确认。

问题二：
B会周期性超时重传第二个包。直到收到A发送的第三个包的确认。

问题三：
此时A应该已经建立连接，即参与连接状态，但是B没有收到最后一个ack包，所以它还没有处于连接状态。
情况1：
假设双方没有数据发送，那么B会一直周期性发送第二个包，直到B收到最后一个包，收到以后，A和B两边的状态即处于连接状态，后面A和B可以发送数据。
情况2:
如果A发送了ACK+DATA的数据包，那么B会切换他的状态为已连接状态，并且接收data数据，需要说明的是，最后一个包是可以携带数据的。
情况3：
如果B现在要发送数据，那么会不成功，B会一直发送第二个包给A，直到收到最后一个包。

### 9.time-wait为什么需要等待2msl

### 10.MySQL查询的处理过程

1. 连接层
2. 服务层
3. 引擎层
4. 存储层



## 桃园店（24）声音很小

### 

## 桃园店（25）

### 1.回表

### 2.前缀索引

### 3.怎么判断字段的区分度

### 4.redis用到什么地方

### 5.bitmap布隆过滤器，解决什么问题（缓存穿透）



## 桃园店（26）

### 1.go和python优缺点

### 2.如何保证kafka不重复消费

### 3.kafka为什么把zookeeper转到offest topic

### 4.秒杀系统

	1. 抗住高并发
	1. 不能出现超卖
	1. 数据库需要单独建立一个数据库

### 5.哔站收藏夹

### 6.缓存穿透

### 7.算法题：字符串无重复最长子串



## 桃园店（27）

### 1.算法题，找和为target的数组

### 2.算法题，合并区间



## 桃园店（28）集度汽车

### 1.读一个关闭的channel和写一个关闭的channel

### 2.slice不是协成安全的

### 3.slice和array区别

### 4.GMP调度模型

### 5.TCP可靠性有什么（超时重传，快重传）

### 6.客服端向服务端发送消息，服务端在没有收到1这个报文时候，会回复2,3报文吗



## 桃园店（29）

### 1.go中泛型

### 2.线程、协程区别，2kb里面具体存的是什么















字节：

```
龚伟​

你好，字节跳动诚邀你参加商业生态安全后端开发工程师职位的面试。​

【面试信息】​

面试形式：视频面试​

面试时间：2022-11-07 16:00(GMT+08:00) China Standard Time - Beijing​

面试链接：https://t.zijieimg.com/M7Yww7a/​

如何进入面试页面？ ​


```



牵手：星期1:

```
日期: 2022-11-07 周一

时间: 18:00

面试方式: 视频面试

会议信息

您可以通过如下方式参与视频面试

面试地址：https://meeting.tencent.com/dm/QkT9ccqlSIpg

腾讯会议ID：103538466
```



星期二上午11：

```
https://meeting.tencent.com/dm/Cm9JBD8i9OFC 这是面试的会议链接
```



心光流美：星期二

```
面试形式：视频面试​

面试时间：2022-11-08 15:00 (GMT+08:00) 中国标准时间 - 北京​

面试链接：https://flowgame.feishu.cn/hire/short_url/M3gRkpv​

视频面试开始前，请先下载对应视频软件，下载链接 https://www.feishu.cn/download
```



阅友科技：下午5点，boss直聘

```
https://vc.feishu.cn/j/181813249
```



周三，下午5.6点

```
【人才招聘】龚伟，您好
现邀请您于2022-11-0917:00，参加致美生活（北京）科技有限公司公司中台服务组GO开发工程师职位的面试
面试地点：#腾讯会议：843-317-010
联系人：段兴文
电话：15333186083
```



周四：上午11点,钉钉会议

```
```



云账户：星期四，下午四点

```
面试形式：视频面试​

面试时间：2022-11-08 17:00 (GMT+08:00) China Standard Time - Beijing​

面试链接：https://miheukbff2.feishu.cn/hire/short_url/MoR2yg1（飞书）
```



周四。下午6点，牵手

```
面试信息发生变化，面试信息更新如下。

面试日期：2022-11-10 周四

面试时间：18:00~19:00

面试方式：现场面试

面试地点： 光华路soho2c座(浦发银行旁边）1601 
联系人：滕晓曼

联系电话：15542365019
```





周五下午三点。联影智能

```
邀请您参加腾讯会议
会议主题：龚伟-联影智能面试
会议时间：2022/11/11 15:00-16:00 (GMT+08:00) 中国标准时间 - 北京

点击链接入会，或添加至会议列表：
https://meeting.tencent.com/dm/arb81sbb6wvK

#腾讯会议：917-187-790

复制该信息，打开手机腾讯会议即可参与
```



### 事务原理

#### 1.原子性

 Undo log

#### 2.持久性

记录操作到redo log
