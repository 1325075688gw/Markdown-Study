[TOC]

### 面试已知点

1. go channel的底层实现了解吗

2. goroutine什么情况下会阻塞

3. map slice底层实现

4. 线程和协程的区别，要求我同时把GMP模型说一下；

5. Channel的用法，有缓存无缓存；

6. slice和map是线程安全的吗？

7. Golang的设计模式有用过吗？

8. linux常用命令

9. 事务的隔离级别 

10. cookie session 区别是什么 为了解决什么问题  token 呢 有什么区别

11. DNS走的哪个端口号 

    1. 53

12. golang的协程的优势是什么  进程 线程 协程区别

13. 浏览器访问请求的时候 如果响应的很慢 一般怎么排查

14. 如果一个服务器程序宕机了 怎么才能快速发现 可能是什么原因引起的等结果 

15. goroutine什么情况下会阻塞

16. 怎么解决哈希冲突

17. go 内存逃逸分析

18. 一个进程在fork()的时候会复制什么信息

19. gin那路由是怎么做的呢？

20. 为什么会想到goroutine加channel的方式实现消息通知

21. 如果goroutine之间传递信息，除了channel还可以用什么？

22. kubernetes Pod创建流程

23. 使用[redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)需要注意什么问题（简单说了缓存击穿和雪崩、[数据](https://www.nowcoder.com/jump/super-jump/word?word=数据)一致性问题）

24. [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)性能出现问题可能是什么原因？

25. select的作用

26. 进程、线程和协程的区别

27. 内存泄露如何排查

28. 为什么不能是两次握手，就两次握手会怎么样

29. 如何保证可靠tcp链接

30. 说下网址输入到渲染全过程

31. DNS说的细一点具体怎么实现的

32. 网址输入到渲染过程中使用的协议？

33. http和https的区别

34. 细说下https实现过程

35. udp怎么实现堪比tcp的数据传输，能做到吗

36. 孤儿进程和僵尸进程简单介绍一下

37. 孤儿进程和僵尸线程怎么去避免呢

    1、[僵尸进程](https://so.csdn.net/so/search?q=僵尸进程&spm=1001.2101.3001.7020)

    子进程退出，父进程运行，父进程没有调用 wait 或者 waitpid 函数，那么子进程就处于僵尸状态（Z）。

    2、孤儿进程

    子进程运行，父进程退出，孤儿进程由 init 进程收养，此时子进程就变成了孤儿进程。

    

    1、僵尸进程

    有很大危害。因为僵尸进程已经挺尸了，对系统没有什么作用，但是依然在进程表占了位置，如果 os 有大量的僵尸进程，那么进程号就会被大量无故占用，严重的话再次 fork 进程可能失败。

    僵尸进程会占用系统资源，如果很多，则会严重影响服务器的性能；

    2、孤儿进程

    孤儿进程不会占用系统资源，最终是由init进程托管，由init进程来释放；

    

    如何防止僵尸进程

    (1) 让僵尸进程成为孤儿进程，由init进程回收；(手动杀死父进程)

    ​	ps -A -ostat,ppid,pid,cmd | grep -e '^[Zz]'

    (2) 调用fork()两次；

    (3) 捕捉SIGCHLD信号，并在信号处理函数中调用wait函数；

38. 线程之间是怎么同步的，一般有哪些方式

    1. 串行化
    2. 互斥锁、读写锁

39. 从输入www.baidu.com开始发生了什么

40. OSI七层模型有哪些？

    1. [应用层](https://so.csdn.net/so/search?q=应用层&spm=1001.2101.3001.7020)、表示层、会话层、传输层、网络层、数据链路层、物理层
    2. TCP是传输层
    3. DNS是应用层

41. tcp的超时重传机制

    1. 超时重传指的是在发送数据报文段后开始计时，到等待确认应答到来的那个时间间隔。如果超过这个时间间隔，仍未收到确认应答，发送端将进行数据重传。这个等待时间称为RTO(Retransmission Time-Out，超时重传时间)。

42. 什么时候用线程，什么时候用协程

    1. ***计算密集型***：多进程，可以最大限度发挥CPU运算能力。
    2. ***IO 密集型***：推荐优先使用协程，内存开销少，执行效率高；其次是多线程，虽然不如协程高效，但同样能极大提升程序运行效率。
    3. ***CPU 密集和 IO 密集***：多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

43. 红黑树和B+树的区别

    1. 红黑树放弃了追求完全平衡，追求大致平衡，它可以在O(log n)时间内做查找，插入和删除
    2. B+树是多路树，树更低

44. redis删除key的时候为什么会阻塞，具体到redis内存管理

45. 为啥使用JWT呢，JWT有什么优点呢

46. 100w条数据选择出Top50个最大的 讲的是节点数为50的小根堆(优先级队列)去实现；

47. time-wait和close-wait

    1. 在socket的TIME_WAIT状态结束之前，该socket所占用的本地端口号将一直无法释放
    2. 在高并发（每秒几万qps）并且采用短连接方式进行交互的系统中运行一段时间后，系统中就会存在大量的time_wait状态，如果time_wait状态把系统所有可用端口 都占完了且尚未被系统回收时，就会出现无法向服务端创建新的socket连接的情况。此时系统几乎停转，任何链接都不能建立
    3. 大量的time_wait状态也会系统一定的fd，内存和cpu资源，当然这个量一般比较小，并不是主要危害

    4. ```
       net.ipv4.tcp_syncookies = 1　　　　　　#开启SYN Cookies 当出现SYN等待队列溢出时启用 可防范少量SYN攻击
       net.ipv4.tcp_tw_reuse = 1　　　　　　　#开启重用 允许TIME-WAIT sockets重新用于新的TCP连接
       net.ipv4.tcp_tw_recycle = 1　　　　　　#开启TCP连接中TIME-WAIT sockets的快速回收
       net.ipv4.tcp_fin_timeout = 30　　　　 #修改系统默认的TIMEOUT时间 单位/秒
       ```

    5.  简单来说，就是打开系统的TIMEWAIT重用和快速回收。

48. 怎么优雅关闭channel

    1. defer revocer
    2. once.do
    3. sync.mutex

49. 什么情况下会发生panic

    1. map并发读写
    2. 数组越界
    3. 读写channel = nil
    4. 关闭已经关闭的channel

50. 互斥锁，读写锁

51. make new区别

52. golang的map是并发安全的吗 其他的map怎么解决

53. 长连接和短连接的区别

    1. http1.0短链接
    2. Http1.1长链接

54. redis过期key如何删除 淘汰策略

55. git merge git rebase区别

56. linux 进程通信方式

57. map是安全的吗  怎么保证安全

58. 两个goroutine怎么通信

    channel

59. 有哪些情况会导致内存泄漏

    1. for select 中使用time.after
       1. 该用time.newtimer或者time.newticker

    2. sync.waitgroup add done wait数量不一致
    3. 程序死锁
    4. I/O连接未设置超时时间，导致goroutine一直在等待，代码会一直阻塞。
    5. channel读写阻塞

60. 不同情况的内存泄漏怎么解决

    

61. Gin的源码读过没有

62. channel要加锁吗  两个协程同时写或者读  怎么保证数据安全

    本来就是线程安全的，只是读取数据没有顺序

63. sync. WaitGroup的底层是怎么样实现的

    1. 计数器，
    2. 当计数器为0时候，唤醒阻塞的goroutine

64. go build 和 go run的区别？

    1. go run 编译并运行
    2. go build编译一个exe文件，并检查编译过程中的错误

65. python和golang的区别（不是语法层面）？

    1. 静态语言、动态语言
    2. 编译性语言、解释性语言
    3. Python有强大的三房库，还有机器学习库
    4. Python靠缩进来指示代码块、Go靠打开和关闭括号
    5. Python不支持并发、Go支持

66. mysql的事务讲一下

    

67. 协程的通信有哪些方式

    chanel

68. UDP可以实现可靠吗？如何实现

    在应用层模仿TCP可靠性传输

    1. 添加ACK/seq机制

    2. 在发送端和接受端添加缓存区
    3. 添加超时重传机制

69. 如何删除slice中的元素

    append进行删除元素



### 开放题

1. 2000w请求同时访问服务器，要考虑哪些因素
2. 







### 算法题

1. 连续子数组的最大和
2. 两个goroutine奇偶交替打印1-100
3. 删除链表重复元素，重复元素不保留
4. 无重复字符的最长子串
5. 链表输出倒数第k个节点
6. 判断环形链表以及找到入环节点
7. 判断两个二叉树是否相等。

### 面试未知点（已解决）

### 面试未知点（未解决）

1. 怎么保证线程安全



### 知识点：

#### 1.goroutine什么情况下会阻塞

1. blocking syscall (for example opening a file) // 系统调用
2. network input // 网络IO
3. channel operations
4. primitives in the sync package // 锁



### 常问知识点：

#### 1.Redis和MySQL如何保证数据一致性

​	缓存可以提高性能，减轻数据库的压力，但是在高并发场景下，缓存和数据库会有一致性问题

##### 1.延迟双删

我们可以先删除缓存，在更新数据库，然后休眠一段时间，这个时间大于一次读请求所消耗的时间，然后在执行一次删除，这个虽然能保证数据一致性，但是在高并发场景下不是很友好，我们每一个请求都需要多等待几秒才能返回

##### 2.这时候就看我们业务场景了，我们业务场景如果只需要保证最终一致性

我们可以通过MQ进行异步删除，就是我们先更新数据库，然后删除缓存，如果缓存删除失败，我们发送一条MQ消息，让MQ帮我们执行删除操作，同时消费侧可以不断进行失败重试

但是这种方式，耦合度比较高，代码侵入比较大

##### 3.使用canal订阅binlog，当监听到binlog修改时候，进行redis删除



另外：设置缓存的过期时间是保证数据保持一致性的关键操作，需要结合业务进行合理的设置。



#### 2.谈谈你对MVCC理解

读读并发，不会产生任何问题

读写并发，有线程安全问题，会产生脏读，不可重复读，幻读

写写并发，有线程安全问题，可能会存在更新丢失等情况



mvcc是用来解决读写时候的线程安全问题的，是在rc和rr隔离级别下使用的无锁并发控制技术

借助undo log 和readview来实现

##### mvcc如何实现RC和RR的隔离级别

（1）**RC**的隔离级别下，每个**快照读**都会**生成并获取最新的readview**。

（2）**RR**的隔离级别下，只有在**同一个事务**的**第一个快照读**才会**创建readview**，之后的每次快照读都**使用的同一个readview**，所以每次的**查询结果都是一样的**。

![image-20220417154721232](https://img-blog.csdnimg.cn/img_convert/09036ef6a02c422b54b365930810ceef.png)

##### 对readview中的参数做一些解释

m_ids：活跃的事务就是指还没有commit的事务。

max_trx_id：例如m_ids中的事务id为（1，2，3），那么下一个应该分配的事务id就是4，max_trx_id就是4。

creator_trx_id：执行select读这个操作的事务的id。
![image-20220417160003011](https://img-blog.csdnimg.cn/img_convert/bc9ce42e33df050243df97fe53ff3404.png)

##### trx_id表示要读取的事务id

（1）如果要读取的事务id等于进行读操作的事务id，说明是我读取我自己创建的记录，那么为什么不可以呢。

（2）如果要读取的事务id小于最小的活跃事务id，说明要读取的事务已经提交，那么可以读取。

（3）max_trx_id表示生成readview时，分配给下一个事务的id，如果要读取的事务id大于max_trx_id，说明该id已经不在该readview版本链中了，故无法访问。

（4）m_ids中存储的是活跃事务的id，如果要读取的事务id不在活跃列表，那么就可以读取，反之不行。




#### 3.MySQL事务底层原理

1. 隔离性：

   写写操作，通过锁机制，保证当前只能有一个事务来操作某个数据。

   写读操作，mvcc实现

2. 持久性：

   主要依靠redo.log日志实现。首先，mysql持久化通过缓存来提高效率，即在select时先查缓存，再查磁盘；在update时先更新缓冲，再更新磁盘。以减少磁盘io次数，提高效率。但由于缓存断电就没了，所以需要redo.log日志。在执行修改操作时，sql会先写入到redo.log日志，再写入缓存中。这样即使断电，也能保证数据不丢失，达到持久性

   <img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20221120230502871.png" alt="image-20221120230502871" style="zoom:80%;" />

   为什么加入Redo log比直接写入到buffer中快呢？

   ​    1.因为buffer中的数据持久化是随机写的IO，每次修改的数据位置随机。Redo log是属于追加模式的，在文件尾部去追加，它是属于一种顺序IO的操作，kafka就是采用这种追加模式。

   ​    2.MySQL数据页大小默认是16k,每执行一个小小的修改，都要把整页的数据重新写入。而Redo log只需要写入真正需要的部分就可以了，无效的IO就大大减少了。所以Redo log要比buffer同步数据快很多。

3. 原子性：

   事务是一个不可分割的单位，是一个最小的操作单元；这个单元的操作要么全部成功，要么全部不成功。如果某一个SQL语句执行失败了，那么之前执行的SQL语句要执行回滚操作。实现原理：基于**Undo log**。Undo log会记录所有操作，一旦发生回滚，数据库就会按照Undo log做相反的操作，比如记录的是插入，那么数据库便会进行删除操作。

4. 一致性：

   

#### 4.redis全量复制和增量复制

##### 全量复制：

​	全量复制发生在主从复制的初始化阶段，从节点会主动向主节点发起一个同步请求，主节点收到之后，会生成一份当前数据的快照，发送给从节点，从节点收到后，会加载数据，完成全量复制

##### 增量复制：

​	增量复制发送在master数据发送变化时候，都会将变化的增量数据同步给从节点，同时维护一个复制偏移量



#### 5.redis持久化策略

RDB：当前时间节点的一个数据快照保存到磁盘上

优点：

	1. 体积小，
	1. 恢复速度比较快

缺点：

1. 会丢掉一部分数据
2. 通过bgsave进行数据备份时候，需要fork一个子进程，频繁执行会有成本开销

AOF：

优点：

 	1. 基本做到数据不丢失

缺点：

1. 文件体积大，aof文件大小比rdb大
2. 恢复速度慢
3. <img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20221120222822257.png" alt="image-20221120222822257" style="zoom:80%;" />

混合持久化：

在开启混合持久化的情况下，AOF 重写时会把 Redis 的持久化数据，以 RDB 的格式写入到 AOF 文件的开头，之后的数据再以 AOF 的格式化追加的文件的末尾。

如何配置：

在 Redis 的根路径下找到 redis.conf 文件，把配置文件中的 `aof-use-rdb-preamble no` 改为 `aof-use-rdb-preamble yes` 如下图所示：



#### 6.MySQL索引失效的底层原理 

a、b两个字段建立联合索引

只有a相等的情况下，b才有序，所以 a>1 and b=1 用不到索引

like同理



#### 7.如何解决死锁

##### 1、什么是死锁

所谓死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。

##### 举个例子

2线程就是两个孩子，2锁其中一个是电池，另一个是电动汽车，a孩子拿着电池，b孩子拿着电动汽车，a想要b的车,b想要a的电池，谁也不肯退，所以谁也玩不上，都僵在那里就是死锁
解决方法，1、一次申请所有资源就是把玩具和电池放一起，只让一个孩子拿到2、主动释放就是有个孩子比较懂事，先让出自己的玩具部分3、玩具给幼儿园老师看着，只有拿到车的才发电池。

两个线程需要两个资源才能进行下去，一线程有一资源，二线程有二资源，一二线程要想进行下去都需要同时拥有两个资源。而双方都不会把手中已经得到的资源放出去，所以双方都不会凑齐两个资源，线程也就不会完成，只会一直等待对方放开资源，形成死锁。

或者说我要去药店买口罩，而进药店需要我带着口罩，这是就僵在这里。除非有外力因素否则不会打破这个情况。

##### 2、死锁产生的4个必要条件？

产生死锁的必要条件：

- 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
- 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
- 环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链，线程t1等待线程t2占有的资源，线程t2等待线程t1占有的资源，形成循环等待。

##### 3、解决死锁的基本方法

##### 预防死锁：

- 互斥条件是资源本身的特性，无法破坏

- 资源一次性分配：一次性分配所有资源（破坏请保持条件）
- 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
- 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破循环等待条件

##### 解决死锁：

- 重启服务，或者杀死代价最小的进程



#### 8.为什么索引能提高查找效率

索引底层使用的数据结构是多路平衡查找树：B+树

千万级别数据，树的高度也能控制在3层，IO次数等于树的高度，所以IO次数很少的情况下就能查找到数据，提高查询效率，同时B+树的每个节点数据是有序的，这也就方便我们对每个节点数据使用二分查找



#### 9.谈谈你对redis的理解

1. 内存存储、key-value、非关系型数据库
2. 一般情况下，我们是将redis和mysql进行混合使用，提高查询效率。同时redis提供多种数据结构，我们可以借助这些数据结构完成很多事情，比如topN，查找好友公共关注列表，设置布隆过滤器，
3. 但是我们在使用redis作为存储结构时候，需要考虑到缓存时间的设置，需要考虑数据一致性问题



#### 10.什么是链路追踪

我们现在使用的链路追踪系统是cat

1. 我们可以使用链路追踪系统快速定位故障点
2. 可以通过链路系统取分析各个阶段的响应耗时，便于我们优化系统
3. 依赖优化，对于各个系统的依赖进行分析优化
4. 数据分析，我们可以得到用户的行为数据，方便我们后续改进基础组件的容量，部署方式等



#### 11.限流算法

限制请求流量峰值，防止系统被打垮

##### 固定窗口限流算法：

首先维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接收请求的次数。

- 当次数少于限流阀值，就允许访问，并且计数器+1
- 当次数大于限流阀值，就拒绝访问。
- 当前的时间窗口过去之后，计数器清零。



1. **一段时间内（不超过时间窗口）系统服务不可用**。比如窗口大小为1s，限流大小为100，然后恰好在某个窗口的第1ms来了100个请求，然后第2ms-999ms的请求就都会被拒绝，这段时间用户会感觉系统服务不可用。

2. **窗口切换时可能会产生两倍于阈值流量的请求。**假设限流阀值为5个请求，单位时间窗口是1s,如果我们在单位时间内的前0.8-1s和1-1.2s，分别并发5个请求。虽然都没有超过阀值，但是如果算0.8-1.2s,则并发数高达10，已经超过单位时间1s不超过5阀值的定义啦，通过的请求达到了阈值的两倍。



##### 滑动窗口限流：

滑动窗口限流解决固定窗口临界值的问题，可以保证在任意时间窗口内都不会超过阈值。



##### 漏桶算法：

- 流入的水滴，可以看作是访问系统的请求，这个流入速率是不确定的。

- 桶的容量一般表示系统所能处理的请求数。

- 如果桶的容量满了，就达到限流的阀值，就会丢弃水滴（拒绝请求）

- 流出的水滴，是恒定过滤的，对应服务按照固定的速率处理请求

  <img src="https://img-blog.csdnimg.cn/247cdae809aa421a9e9edccd46d3e764.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAYmlsbGdhdGVzX3dhbmJpbg==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:60%;" />



- 一恒定速率处理请求，既是缺点又是优点，优点是，面对普通请求，我们可以按照固定速率处理请求，保证系统稳定性，缺点是，面对突发请求，服务的处理速度和平时是一样的，这其实不是我们想要的，在面对突发流量我们希望在系统平稳的同时，提升用户体验即能更快的处理请求。



##### 令牌桶算法：

- 有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。

- 如果令牌数量满了，超过令牌桶容量的限制，那就丢弃。

- 系统在接受到一个用户请求时，都会先去令牌桶要一个令牌。如果拿到令牌，那么就处理这个请求的业务逻辑；

- 如果拿不到令牌，就直接拒绝这个请求。

  <img src="https://img-blog.csdnimg.cn/4be9c063c75a4fde97fff157678972ba.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAYmlsbGdhdGVzX3dhbmJpbg==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:80%;" />

- 可以看出令牌桶在应对突发流量的时候，桶内假如有 100 个令牌，那么这 100 个令牌可以马上被取走，而不像漏桶那样匀速的消费。所以在**应对突发流量的时候令牌桶表现的更佳**。



#### 12.HTTP协议和RPC协议区别

1. http是应用层上的一个超文本传输协议，主要服务于客服端和服务端之前
2. rpc是一个远程过程调用协议，屏蔽了通信的底层复杂度，让我们开发者像调用本地方法一样调用远程服务，一般用于公司内部不同服务之间的调用，性能开销低，传输效率高，服务治理方便



#### 13.Redis缓存淘汰策略

##### redis提供了8种内存淘汰策略

- noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键。
- allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键。
- volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键。
- allkeys-random：加入键的时候如果过限，从所有key随机删除。
- volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐。
- volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键。
- volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键。
- allkeys-lfu：从所有键中驱逐使用频率最少的键。



##### 具体可以可以5种

- 第一种，采用LRU策略，移除最久没有使用的键
- 第二种，采用LFU策略，移除使用频率最少的键
- 第三种，随机淘汰策略
- 第四种，从配置了过期时间的键中驱逐马上就要过期的键。
- 第五种，直接报错



默认是noeviction。对于写请求不再提供服务，直接返回错误



#### 14.如何生成分布式ID

#### 15.一致性hash

##### 普通hash

​		假设我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为 0号、1号、2号，现在有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务器上，以便它们能够分摊缓存的压力。也就是说，我们希望每台服务器能够缓存1万张左右的图片，那么我们应该怎样做呢？常见的做法是对缓存项的键进行哈希，将hash后的结果对缓存服务器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上

<img src="https://img-blog.csdnimg.cn/42ba360b8045498391e1dac6f84aae53.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5byg57u06bmP,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

##### 普通 hash 算法的缺陷：

​        上述HASH算法时，会出现一些缺陷：如果服务器已经不能满足缓存需求，就需要增加服务器数量，假设我们增加了一台缓存服务器，此时如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在的服务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，最终导致所有缓存的位置都要发生改变，也就是说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据；同理，假设突然有一台缓存服务器出现了故障，那么我们则需要将故障机器移除，那么缓存服务器数量从3台变为2台，同样会导致大量缓存在同一时间失效，造成了缓存的雪崩，后端服务器将会承受巨大的压力，整个系统很有可能被压垮。为了解决这种情况，就有了一致性哈希算法。

##### 什么是一致性 hash 算法：

​        一致性哈希算法也是使用取模的方法，但是取模算法是对服务器的数量进行取模，而一致性哈希算法是对 2^32 取模，具体步骤如下：

- 步骤一：一致性哈希算法将整个哈希值空间按照顺时针方向组织成一个虚拟的圆环，称为 Hash 环；
- 步骤二：接着将各个服务器使用 Hash 函数进行哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，从而确定每台机器在哈希环上的位置
- 步骤三：最后使用算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针寻找，第一台遇到的服务器就是其应该定位到的服务器

<img src="https://img-blog.csdnimg.cn/ef28878058814e8e9008fff3cc73066a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5byg57u06bmP,size_16,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:70%;" />

一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，**只有部分缓存会失效**，不至于将所有压力都在同一时间集中到后端服务器上，具有较好的容错性和可扩展性。



##### hash 环的倾斜与虚拟节点：

​    一致性哈希算法在服务节点太少的情况下，容易因为节点分部不均匀而造成数据倾斜问题，也就是被缓存的对象大部分集中缓存在某一台服务器上，从而出现数据分布不均匀的情况，这种情况就称为 hash 环的倾斜。如下图所示：

<img src="https://img-blog.csdnimg.cn/5deec5a0b1324817a798e23b2b8e624e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5byg57u06bmP,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:97%;" />

​		hash 环的倾斜在极端情况下，仍然有可能引起系统的崩溃，**为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希**，每个计算结果位置都放置一个此服务节点，称为虚拟节点，一个实际物理节点可以对应多个虚拟节点，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大，hash环倾斜所带来的影响就越小，同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。具体做法可以在服务器ip或主机名的后面增加编号来实现，加入虚拟节点以后的hash环如下：

<img src="https://img-blog.csdnimg.cn/25643de7ac134712886e82638fda93e1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5byg57u06bmP,size_15,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />

#### 16.怎么理解线程安全

#### 17.kafka如何保证消息不丢失

producer->broker->comsumer三部分构成，我们主要关心这三部分

##### producer：

1. 将异步发送改为同步发送，如果发送失败就可以重新发送
2. 添加异步函数，监听异步回调函数的结果，如果发送失败，可以重新发送
3. 将retry = max， ack= -1设置好，同步副本数大于1

##### broker：

kafka是异步刷盘，没有提供同步刷盘的机制，按照一定的消息量和时间间隔去刷盘，如果刷盘之前系统崩溃了，就会导致数据丢失

##### consumer：

先消费消息，后提交offset



#### 18.hash如何解冲突

- 链地址法
- 再[哈希](https://so.csdn.net/so/search?q=哈希&spm=1001.2101.3001.7020)法
  - 提供多个哈希函数，如果第一个哈希函数计算出来的key的哈希值冲突了，则使用第二个哈希函数计算key的哈希值。
- 建立公共溢出区
- 开放地址法



#### 19.CPU飙高系统反应慢怎么排查？

CPU最小执行单元是线程，同一时刻，一个核心只能运行一个线程，如果CPU利用率过高，可能有以下原因

1. 可能是多个线程要去执行，CPU只能通过上下文切换的方式来调度执行不同的线程，上下文切换需要做两个事情，第一个是保存运行线程的执行状态，第二个是让处于等待的线程恢复执行，如果较多的上下文切换，那么CPU的利用率就会升高
2. 可能是某个线程死循环，死锁，造成线程无法回收，占用大量CPU

- 我们可以通过top找到CPU占用率较高的进程
- 查看该进程的线程， top -p <pid>



#### 20.innodb怎么解决幻读

1. 在快照读的情况下，会通过mvcc来避免幻读
   - InnoDB实现mvcc 是通过 readview+undolog 来实现
2. 在当前读的情况下，会通过next-key来避免幻读



#### 21.kafk零拷贝机制

磁盘的东西发送到远程服务器上

<img src="/Users/gongwei/Library/Application Support/typora-user-images/image-20221122130729505.png" alt="image-20221122130729505" style="zoom:50%;" />

由于用户空间的切换会导致上下文下幻，这也是对CPU性能的一种损耗



#### 22.如何保证数据库的高可用性

##### 1.为什么需要做高可用‘



#### 23.MySQL优化

1. 主从集群
2. 读写分离
3. 分库分表
4. 热点缓存redis
5. select优化
6. 建立索引



#### 24.分布式事务



#### 25.如何保证消息幂等

1. 使用数据库的唯一索引，实现幂等，比如创建订单号，由于订单号肯定是唯一的，所以多次调用会触发唯一索引异常，避免重复创建多个订单
2. 可以使用redis的setNX命令，可以在接收到消息后，把这个消息写到setNX里面，如果被写入过，就不会再被消费
3. 可以使用状态机来实现幂等，因为状态只能向后变更，不能向前变更，所以可以过滤掉无效状态扭转



#### 26.kafka如何避免重复消费

kafka自动提交里面有一个默认提交规则，也就是间隔5秒，提交一次offset，当我们提交offset时候，可能会宕机了，造成重复消费问题

还有一个就是reblance机制，如果在5分钟内，无法处理完一批消息，就会触发reblance机制，可能会造成offset提交未成功

还有kafka的手动提交种，提交时候宕机了，也会造成重复消费问题



1. 我们可以避免reblance，比如减少一次从borker上拉去数据的条数
2. 使用数据库的唯一索引，实现幂等，比如创建订单号，由于订单号肯定是唯一的，所以多次调用会触发唯一索引异常，避免重复创建多个订单
3. 针对消息生产md5然后保存到数据库或者redis里面
4. 可以使用状态机来实现幂等，因为状态只能向后变更，不能向前变更，所以可以过滤掉无效状态扭转



#### 27.awd、sed、grep区别

https://www.bilibili.com/video/BV1Tz4y1f7jq/?spm_id_from=333.337.search-card.all.click&vd_source=58acbf449edd771737ee43a78ffdabf4

##### sed：

对每一行进行流式处理，主要用去字符的替换、删除、格式化，比如将文件中的逗号替换为空格，删除每一行中的空格

##### awd：

主要是取出文件多少行，多少列的元素

##### grep：

是对文件进行正则匹配







### 面试中不知道的点：

1. select原理
2. gmp模型
3. gmp p作用
4. map时间复杂度



#### 优维科技：

1. 线程和协程为什么差别这么大



欢姐，您好：

我是龚伟，我应聘了一份工作，需要背调

1. 我请假时回去装修房子
2. 绩效C，可以都说成B吗

绩效这块，麻烦您这边帮衬一下



25k

9:00 9:30 6:30 7：00

13xing

2300·

深海互动



where a = xxx and b = xxx and c = xxx
where a > xxx and b = xxx
where a = xxx order by b



gc内联、逃逸分析

为什么分配到堆

分布式事务

怎么让多台机器运行

锁的底层实现

超线程技术

并发并行

用户态线程

gc root是什么

channel怎么保证线程安全

线程安全是什么概念

